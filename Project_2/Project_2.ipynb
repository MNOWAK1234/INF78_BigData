{"cells": [{"cell_type": "markdown", "id": "861b6d4a-0de6-42ba-97a5-beef1f82f292", "metadata": {}, "source": "# Projekt Apache Spark"}, {"cell_type": "markdown", "id": "7b301ae8-ceff-4dbf-8d04-75bb4eb52480", "metadata": {}, "source": "# Wprowadzenie\n\nWykorzystuj\u0105c ten notatnik jako szablon zrealizuj projekt Apache Spark zgodnie z przydzielonym zestawem. \n\nKilka uwag:\n\n* Nie modyfikuj ani nie usuwaj paragraf\u00f3w *markdown* w tym notatniku, chyba \u017ce wynika to jednoznacznie z instrukcji. \n* Istniej\u0105ce paragrafy zawieraj\u0105ce *kod* uzupe\u0142nij w razie potrzeby zgodnie z instrukcjami\n    - nie usuwaj ich\n    - nie usuwaj zawartych w nich instrukcji oraz kodu\n    - nie modyfikuj ich, je\u015bli instrukcje jawnie tego nie nakazuj\u0105\n* Mo\u017cesz dodawa\u0107 nowe paragrafy zar\u00f3wno zawieraj\u0105ce kod jak i komentarze dotycz\u0105ce tego kodu (markdown)"}, {"cell_type": "markdown", "id": "adfc4ff6-4d43-49ed-a0d1-8b6988eaec16", "metadata": {}, "source": "# Zestaw 6 \u2013 fifa-players\n\n## Misja g\u0142\u00f3wna\n\n### Cel przetwarzania\n\nDla nast\u0119puj\u0105cych kategorii: \n- narodowo\u015b\u0107 (opartej na `nationality_name`)\n- klub (opartej na `club_name`)\n- liga (opartej na `league_name`)\n\nnale\u017cy wyznaczy\u0107 trzy warto\u015bci (nazw\u0119 narodowo\u015bci/klubu/ligi) z pi\u0142karzami o najwi\u0119kszych \u015brednich zarobkach. \n\nW analizach nie uwzgl\u0119dniamy pi\u0142karzy graj\u0105cych w ligach, w kt\u00f3rych liczba graj\u0105cych zespo\u0142\u00f3w maj\u0105cych co najmniej 11 pi\u0142karzy jest mniejsza ni\u017c 10. \n\nWynik przetwarzania powinien zawiera\u0107 nast\u0119puj\u0105ce atrybuty: \n- `category` \u2013 nazwa kategorii (`nationality`, `club`, `league`)\n- `name` \u2013 nazwa narodowo\u015bci/klubu/ligi\n- `sum_value_eur` \u2013 sumaryczna warto\u015b\u0107 pi\u0142karzy\n- `avg_wage_eur` \u2013 \u015brednie zarobki pi\u0142karzy \n- `avg_age` \u2013 \u015bredni wiek pi\u0142karzy w lidze obliczony na podstawie warto\u015bci kolumny age \n(nie korzystamy z `dob`)\n- `count_players` \u2013 liczba zawodnik\u00f3w \n- `player_positions` \u2013 lista skr\u00f3t\u00f3w nazw pozycji, na kt\u00f3rych graj\u0105 pi\u0142karze \n\nSugerowany schemat wyniku:\n```\nroot\n |-- category: string (nullable = false)\n |-- name: string (nullable = true)\n |-- sum_value_eur: double (nullable = true)\n |-- avg_wage_eur: double (nullable = true)\n |-- avg_age: double (nullable = true)\n |-- count_players: long (nullable = false)\n |-- player_positions: array (nullable = true)\n |    |-- element: string (containsNull = true)\n ```\n\nUwagi:\n- lista skr\u00f3t\u00f3w nazw pozycji, na kt\u00f3rych graj\u0105 pi\u0142karze nie mo\u017ce zawiera\u0107 duplikat\u00f3w \n- oryginalne warto\u015bci kolumny player_positions mog\u0105 zawiera\u0107 wiele skr\u00f3t\u00f3w nazw pozycji, nale\u017cy je traktowa\u0107 jako zbi\u00f3r\n- warto\u015bci liczbowe maj\u0105 by\u0107 zaokr\u0105glone do jedno\u015bci"}, {"cell_type": "markdown", "id": "5e128e43-6cce-4ffa-9609-9fae4b164ae9", "metadata": {}, "source": "# Dzia\u0142ania wst\u0119pne \n\nUruchom poni\u017cszy paragraf, aby utworzy\u0107 obiekty kontekstu Sparka. Je\u015bli jest taka potrzeba dostosuj te polecenia. Pami\u0119taj o potrzebnych bibliotekach."}, {"cell_type": "code", "execution_count": 1, "id": "26fb1050-386f-4398-ba5a-b45f5065d87b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/12/29 15:19:23 INFO SparkEnv: Registering MapOutputTracker\n24/12/29 15:19:23 INFO SparkEnv: Registering BlockManagerMaster\n24/12/29 15:19:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n24/12/29 15:19:23 INFO SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession\nimport os\n\n# Spark session & context\nspark = SparkSession.builder.appName(\"FifaPlayers\").getOrCreate()\nsc = spark.sparkContext  # Tworzymy alias dla SparkContext"}, {"cell_type": "markdown", "id": "8695a354-52bc-4bba-8222-7121bf07ae90", "metadata": {}, "source": "W poni\u017cszym paragrafie uzupe\u0142nij polecenia definiuj\u0105ce poszczeg\u00f3lne zmienne. \n\nPami\u0119taj aby\u015b:\n\n* w p\u00f3\u017aniejszym kodzie, dla wszystkich cze\u015bci projektu, korzysta\u0142 z tych zdefiniowanych zmiennych. Wykorzystuj je analogicznie jak parametry\n* przed ostateczn\u0105 rejestracj\u0105 projektu usun\u0105\u0142 ich warto\u015bci, tak aby nie pozostawia\u0107 w notatniku niczego co mog\u0142oby identyfikowa\u0107 Ciebie jako jego autora"}, {"cell_type": "code", "execution_count": 2, "id": "e883af01-7117-4faa-a840-7ff807a195d9", "metadata": {}, "outputs": [], "source": "# pe\u0142na \u015bcie\u017cka do katalogu w zasobniku zawieraj\u0105cego podkatalogi `datasource1` i `datasource4` \n# z danymi \u017ar\u00f3d\u0142owymi\ninput_dir = \"gs://pdb-24-mn/project1/input\""}, {"cell_type": "markdown", "id": "4601cc7a-3ed5-47e2-994f-ebec642049b5", "metadata": {}, "source": "Nie modyfikuj poni\u017cszych paragraf\u00f3w. Wykonaj je i u\u017cywaj zdefniowanych poni\u017cej zmiennych jak parametr\u00f3w Twojego programu."}, {"cell_type": "code", "execution_count": 3, "id": "6167e297-01ed-463e-bb81-9104d7cf7093", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\n# \u015bcie\u017cki dla danych \u017ar\u00f3d\u0142owych \ndatasource1_dir = input_dir + \"/datasource1\"\ndatasource4_dir = input_dir + \"/datasource4\"\n\n# nazwy i \u015bcie\u017cki dla wynik\u00f3w dla misji g\u0142\u00f3wnej \n# cz\u0119\u015b\u0107 1 (Spark Core - RDD) \nrdd_result_dir = \"/tmp/output1\"\n\n# cz\u0119\u015b\u0107 2 (Spark SQL - DataFrame)\ndf_result_table = \"output2\"\n\n# cz\u0119\u015b\u0107 3 (Pandas API on Spark)\nps_result_file = \"/tmp/output3.json\""}, {"cell_type": "code", "execution_count": 4, "id": "e36e0314-a4ac-4096-9e4b-23fd4a73e0a9", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\nimport os\ndef remove_file(file):\n    if os.path.exists(file):\n        os.remove(file)\n\nremove_file(\"metric_functions.py\")\nremove_file(\"tools_functions.py\")"}, {"cell_type": "code", "execution_count": 5, "id": "1b4b8e00-10ae-47dc-b623-d1dacbe9c86b", "metadata": {}, "outputs": [{"data": {"text/plain": "3322"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "# NIE ZMIENIA\u0106\nimport requests\nr = requests.get(\"https://jankiewicz.pl/bigdata/metric_functions.py\", allow_redirects=True)\nopen('metric_functions.py', 'wb').write(r.content)\nr = requests.get(\"https://jankiewicz.pl/bigdata/tools_functions.py\", allow_redirects=True)\nopen('tools_functions.py', 'wb').write(r.content)"}, {"cell_type": "code", "execution_count": 6, "id": "0a433894-dc97-46f2-be51-9f40fa36894f", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\n%run metric_functions.py\n%run tools_functions.py"}, {"cell_type": "markdown", "id": "c9d3a9dc-ac3b-4316-abb9-365caa1d7185", "metadata": {}, "source": "Poni\u017csze paragrafy maj\u0105 na celu usun\u0105\u0107 ewentualne pozosta\u0142o\u015bci poprzednich uruchomie\u0144 tego lub innych notatnik\u00f3w"}, {"cell_type": "code", "execution_count": 7, "id": "08091c72-937f-41c2-9afe-d1505862bf1c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Deleted /tmp/output1\nSuccessfully deleted file in HDFS: /tmp/output1\n"}], "source": "# NIE ZMIENIA\u0106\n# usuni\u0119cie miejsca docelowego dla cz\u0119\u015b\u0107 1 (Spark Core - RDD) \ndelete_dir(spark, rdd_result_dir)"}, {"cell_type": "code", "execution_count": 8, "id": "f3e863c0-c824-47bd-b53a-ce3b1fd6d453", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n"}, {"name": "stdout", "output_type": "stream", "text": "The physical location of the table output2 is: hdfs://pbd-cluster-m/user/hive/warehouse/output2\n"}, {"name": "stderr", "output_type": "stream", "text": "rm: `hdfs://pbd-cluster-m/user/hive/warehouse/output2': No such file or directory\n"}, {"name": "stdout", "output_type": "stream", "text": "Error deleting file hdfs://pbd-cluster-m/user/hive/warehouse/output2: Command '['hadoop', 'fs', '-rm', '-r', 'hdfs://pbd-cluster-m/user/hive/warehouse/output2']' returned non-zero exit status 1.\n"}], "source": "# NIE ZMIENIA\u0106\n# usuni\u0119cie miejsca docelowego dla cz\u0119\u015b\u0107 2 (Spark SQL - DataFrame) \ndrop_table(spark, df_result_table)"}, {"cell_type": "code", "execution_count": 9, "id": "72956a1a-da48-4d2b-a07a-e03d56431d6e", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\n# usuni\u0119cie miejsca docelowego dla cz\u0119\u015b\u0107 3 (Pandas API on Spark) \nremove_file(ps_result_file)"}, {"cell_type": "code", "execution_count": 10, "id": "b9e423d4-92b8-4161-98da-1a867f86d780", "metadata": {}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://pbd-cluster-m.europe-west4-c.c.big-data-2024-09-mn.internal:37777\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>FifaPlayers</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f4ea9e6a8d0>"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "# NIE ZMIENIA\u0106\nspark"}, {"cell_type": "markdown", "id": "14faf05b-6c52-4b02-b2e5-2ddb3f38c704", "metadata": {}, "source": "***Uwaga!***\n\nUruchom poni\u017cszy paragraf i sprawd\u017a czy adres, pod kt\u00f3rym dost\u0119pny *Apache Spark Application UI* jest poprawny wywo\u0142uj\u0105c nast\u0119pny testowy paragraf. \n\nW razie potrzeby okre\u015bl samodzielnie poprawny adres, pod kt\u00f3rym dost\u0119pny *Apache Spark Application UI*"}, {"cell_type": "code", "execution_count": 11, "id": "32acf3d2-ec4e-469d-bb0b-5f260c2c8e3b", "metadata": {}, "outputs": [{"data": {"text/plain": "'http://pbd-cluster-m.europe-west4-c.c.big-data-2024-09-mn.internal:37777'"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "# adres URL, pod kt\u00f3rym dost\u0119pny Apache Spark Application UI (REST API)\n# \nspark_ui_address = extract_host_and_port(spark, \"http://localhost:4041\")\nspark_ui_address"}, {"cell_type": "code", "execution_count": 12, "id": "32c2329e-1d7a-465f-a23b-333f95bf7deb", "metadata": {}, "outputs": [{"data": {"text/plain": "{'numTasks': 0,\n 'numActiveTasks': 0,\n 'numCompleteTasks': 0,\n 'numFailedTasks': 0,\n 'numKilledTasks': 0,\n 'numCompletedIndices': 0,\n 'executorDeserializeTime': 0,\n 'executorDeserializeCpuTime': 0,\n 'executorRunTime': 0,\n 'executorCpuTime': 0,\n 'resultSize': 0,\n 'jvmGcTime': 0,\n 'resultSerializationTime': 0,\n 'memoryBytesSpilled': 0,\n 'diskBytesSpilled': 0,\n 'peakExecutionMemory': 0,\n 'inputBytes': 0,\n 'inputRecords': 0,\n 'outputBytes': 0,\n 'outputRecords': 0,\n 'shuffleRemoteBlocksFetched': 0,\n 'shuffleLocalBlocksFetched': 0,\n 'shuffleFetchWaitTime': 0,\n 'shuffleRemoteBytesRead': 0,\n 'shuffleRemoteBytesReadToDisk': 0,\n 'shuffleLocalBytesRead': 0,\n 'shuffleReadBytes': 0,\n 'shuffleReadRecords': 0,\n 'shuffleWriteBytes': 0,\n 'shuffleWriteTime': 0,\n 'shuffleWriteRecords': 0}"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "# testowy paragraf\ntest_metrics = get_current_metrics(spark_ui_address)\ntest_metrics"}, {"cell_type": "markdown", "id": "f5ccca69-c577-440c-aa5c-c9df3a54e127", "metadata": {}, "source": "# Cz\u0119\u015b\u0107 1 - Spark Core (RDD)\n\n## Misje poboczne\n\nW ponizszych paragrafach wprowad\u017a swoje rozwi\u0105zania *misji pobocznych*, o ile **nie** chcesz, aby oceniana by\u0142a *misja g\u0142\u00f3wna*. W przeciwnym przypadku **KONIECZNIE** pozostaw je **puste**.  "}, {"cell_type": "code", "execution_count": null, "id": "f0af3440-983a-4cac-a8e7-4908b010947c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "5fc37879-e0fa-4c4a-bd0d-4c01c3ecf38a", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "d303a72b-4083-470e-b25d-3224360ee94f", "metadata": {}, "source": "## Misja g\u0142\u00f3wna \n\nPoni\u017cszy paragraf zapisuje metryki przed uruchomieniem Twojego rozwi\u0105zania *misji g\u0142\u00f3wnej*. \n\nNie musisz go uruchamia\u0107 podczas implementacji rozwi\u0105zania."}, {"cell_type": "code", "execution_count": 13, "id": "037689d7-f0ee-4165-bef0-83fa7f3e8346", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "{'numTasks': 0,\n 'numActiveTasks': 0,\n 'numCompleteTasks': 0,\n 'numFailedTasks': 0,\n 'numKilledTasks': 0,\n 'numCompletedIndices': 0,\n 'executorDeserializeTime': 0,\n 'executorDeserializeCpuTime': 0,\n 'executorRunTime': 0,\n 'executorCpuTime': 0,\n 'resultSize': 0,\n 'jvmGcTime': 0,\n 'resultSerializationTime': 0,\n 'memoryBytesSpilled': 0,\n 'diskBytesSpilled': 0,\n 'peakExecutionMemory': 0,\n 'inputBytes': 0,\n 'inputRecords': 0,\n 'outputBytes': 0,\n 'outputRecords': 0,\n 'shuffleRemoteBlocksFetched': 0,\n 'shuffleLocalBlocksFetched': 0,\n 'shuffleFetchWaitTime': 0,\n 'shuffleRemoteBytesRead': 0,\n 'shuffleRemoteBytesReadToDisk': 0,\n 'shuffleLocalBytesRead': 0,\n 'shuffleReadBytes': 0,\n 'shuffleReadRecords': 0,\n 'shuffleWriteBytes': 0,\n 'shuffleWriteTime': 0,\n 'shuffleWriteRecords': 0}"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "# NIE ZMIENIA\u0106\nbefore_rdd_metrics = get_current_metrics(spark_ui_address)\nbefore_rdd_metrics"}, {"cell_type": "markdown", "id": "b23971c0-cec7-4ea8-befb-7f063dce863c", "metadata": {}, "source": "W poni\u017cszych paragrafach wprowad\u017a **rozwi\u0105zanie** *misji g\u0142\u00f3wnej* oparte na *RDD API*. \n\nPami\u0119taj o wydajno\u015bci Twojego przetwarzania, *RDD API* tego wymaga. \n\nNie wprowadzaj w poni\u017cszych paragrafach \u017cadnego kodu, w przypadku wykorzystania *misji pobocznych*."}, {"cell_type": "code", "execution_count": 14, "id": "6eda6033-3837-4de0-aed8-0eee16b791f4", "metadata": {}, "outputs": [], "source": "# Funkcja, kt\u00f3ra zamienia warto\u015b\u0107 na liczb\u0119, a w przypadku b\u0142\u0119dnych danych zwraca 0\ndef safe_number(value):\n    try:\n        return float(value) if value is not None else 0\n    except (ValueError, TypeError):\n        return 0  # Zwracamy 0 w przypadku b\u0142\u0119du konwersji\n\n# Funkcja, kt\u00f3ra zamienia warto\u015b\u0107 na list\u0119, a w przypadku b\u0142\u0119dnych danych zwraca pust\u0105 list\u0119\ndef safe_list(value):\n    return value if isinstance(value, list) else []\n\n# Funkcja zaokr\u0105glaj\u0105ca warto\u015bci liczbowe do jednostek\ndef round_value(value):\n    return round(value)  # Zaokr\u0105glanie do najbli\u017cszej liczby ca\u0142kowitej"}, {"cell_type": "code", "execution_count": 15, "id": "4b9ca2de-b62a-41c6-8cef-4db3b6fb47c9", "metadata": {"tags": []}, "outputs": [], "source": "# Za\u0142aduj dane z datasource1\nrdd1 = sc.textFile(datasource1_dir).repartition(os.cpu_count())\ndatasource1_rdd = rdd1.map(lambda line: line.split(\";\")) \\\n    .map(lambda fields: (\n        fields[0],  # player_id (kolumna 0)\n        fields[16],  # league_id (klucz)\n        fields[18],  # club_name\n        fields[17],  # club_team_id\n        fields[10],  # value_eur\n        fields[11],  # wage_eur\n        fields[12],  # age\n        fields[7].split(\", \"),  # player_positions (split po przecinku)\n        fields[25]  # nationality\n    ))\n\n# Za\u0142aduj dane z datasource4\nrdd4 = sc.textFile(datasource4_dir).repartition(os.cpu_count())\ndatasource4_rdd = rdd4.map(lambda line: line.split(\";\")) \\\n    .map(lambda fields: (\n        fields[0],  # league_id (klucz)\n        fields[1]   # league_name\n    ))"}, {"cell_type": "code", "execution_count": 16, "id": "c2ae5e23-29a1-4a25-9f0e-e08682a98157", "metadata": {"tags": []}, "outputs": [], "source": "# Po\u0142\u0105czenie RDD (left join)\nmerged_rdd = datasource1_rdd.map(lambda row: (row[1], row)) \\\n    .leftOuterJoin(datasource4_rdd) \\\n    .map(lambda row: (\n        row[1][0][0],  # player_id\n        row[1][0][2],  # club_name\n        row[1][0][3],  # club_team_id\n        row[1][0][4],  # value_eur\n        row[1][0][5],  # wage_eur \n        row[1][0][6],  # age\n        row[1][0][7],  # player_positions\n        row[1][0][8],  # nationality\n        row[1][1] if row[1][1] else \"Unknown\"  # league_name lub \"Unknown\"\n    ))\n"}, {"cell_type": "code", "execution_count": 17, "id": "a3809056-b332-45bd-affc-5c36db5b1690", "metadata": {"tags": []}, "outputs": [], "source": "# Tworzymy RDD z (league_name, club_name)\nclub_player_rdd = merged_rdd.map(lambda row: (row[8], row[1]))  # (league_name, club_name)\n\n# Zliczanie liczby pi\u0142karzy w ka\u017cdym klubie\nplayers_count_by_club_rdd = club_player_rdd.map(lambda x: ((x[0], x[1]), 1)) \\\n    .reduceByKey(lambda a, b: a + b)  # Zliczanie liczby pi\u0142karzy per (league_name, club_id)\n\n# Filtrujemy kluby, kt\u00f3re maj\u0105 co najmniej 11 pi\u0142karzy\nvalid_clubs_rdd = players_count_by_club_rdd.filter(lambda x: x[1] >= 11)\n\n# Grupowanie wynik\u00f3w po lidze, liczenie liczby klub\u00f3w w danej lidze\nclubs_in_leagues_rdd = valid_clubs_rdd.map(lambda x: (x[0][0], 1))  # Zwracamy tylko league_name, liczba 1 dla ka\u017cdego klubu\nvalid_clubs_in_leagues_rdd = clubs_in_leagues_rdd.reduceByKey(lambda x, y: x + y)  # Zliczanie liczby klub\u00f3w w lidze\n\n# Filtrujemy ligi, w kt\u00f3rych jest przynajmniej 10 klub\u00f3w z co najmniej 11 pi\u0142karzami\nvalid_leagues_rdd = valid_clubs_in_leagues_rdd.filter(lambda x: x[1] >= 10)\n\n# # Debugging: wy\u015bwietlanie wynik\u00f3w\n# print(\"Ligi, kt\u00f3re spe\u0142niaj\u0105 warunek:\")\n# for league, count in valid_leagues_rdd.collect():\n#     print(f\"Liga {league} ma {count} klub\u00f3w z co najmniej 11 pi\u0142karzami\")\n"}, {"cell_type": "code", "execution_count": 18, "id": "cfc11026-ff56-4e88-9799-26070091fb29", "metadata": {"tags": []}, "outputs": [], "source": "# Filtrujemy merged_rdd, aby zawiera\u0142o tylko zawodnik\u00f3w, kt\u00f3rzy graj\u0105 w ligach spe\u0142niaj\u0105cych warunki\nfiltered_merged_rdd = merged_rdd.map(lambda row: (row[8], row)) \\\n    .join(valid_leagues_rdd.map(lambda x: (x[0], None)))  # Join z valid_leagues_rdd, \u017ceby tylko te ligi, kt\u00f3re spe\u0142niaj\u0105 warunki\n\n# Zwracamy tylko same rekordy zawodnik\u00f3w\nfiltered_merged_rdd = filtered_merged_rdd.map(lambda x: x[1][0])"}, {"cell_type": "code", "execution_count": 19, "id": "fa8c51ec-4d6e-4dfd-9c92-49fc9ec86a16", "metadata": {}, "outputs": [], "source": "# Zamiana warto\u015bci null na domy\u015blne (0 dla liczb, pusta lista dla player_positions)\nprocessed_rdd = filtered_merged_rdd.map(lambda row: (\n    row[0],  # player_id\n    row[1],  # club_name\n    row[2],  # club_team_id\n    safe_number(row[3]),  # value_eur (zamiana null na 0)\n    safe_number(row[4]),  # wage_eur (zamiana null na 0)\n    safe_number(row[5]),  # age (zamiana null na 0)\n    safe_list(row[6]),    # player_positions (zamiana null na pust\u0105 list\u0119)\n    row[7],  # nationality\n    row[8] if row[8] else \"Unknown\"  # league_name\n))"}, {"cell_type": "code", "execution_count": 20, "id": "2158b218-a166-4cb5-b323-1858d1ff5f06", "metadata": {}, "outputs": [], "source": "# Funkcja pomocnicza, aby wybra\u0107 top N z RDD\ndef get_top_n(rdd, n):\n    return rdd.sortBy(lambda x: x[3], ascending=False).zipWithIndex().filter(lambda x: x[1] < n).map(lambda x: x[0])"}, {"cell_type": "code", "execution_count": 21, "id": "cdf95507-61b6-43c4-ae66-efcff9b388ed", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Za\u0142aduj dane z processed_rdd (top_nationalities_rdd)\nnationality_stats = processed_rdd.map(lambda row: (\n    row[7],  # nationality\n    (row[4], row[3], row[5], 1)  # wage_eur, value_eur, age, count\n)).reduceByKey(lambda a, b: (\n    a[0] + b[0],  # Suma wage_eur\n    a[1] + b[1],  # Suma value_eur\n    a[2] + b[2],  # Suma wieku\n    a[3] + b[3],  # Liczba graczy\n))\n\n# Obliczanie \u015brednich zarobk\u00f3w, wieku i sumy warto\u015bci\nnationality_avg_stats = nationality_stats.map(lambda x: (\n    'nationality',                   # category\n    x[0],                            # name (nationality)\n    round_value(x[1][1]),            # sum_value_eur (zaokr\u0105glone)\n    round_value(x[1][0] / x[1][3]),  # avg_wage_eur (zaokr\u0105glone)\n    round_value(x[1][2] / x[1][3]),  # avg_age (zaokr\u0105glone)\n    x[1][3],                         # count_players\n))\n\n# Sortowanie po sumie warto\u015bci (value_eur)\ntop_nationalities_rdd = get_top_n(nationality_avg_stats, 3)\n\n# Tworzenie RDD z pozycji narodowo\u015bci\nnationality_positions_rdd = processed_rdd.flatMap(lambda row: [(row[7], position) for position in row[6]])  # (nationality, position)\n\n# Usuwanie duplikat\u00f3w pozycji (distinct) dla ka\u017cdej narodowo\u015bci\nnationality_positions_rdd_distinct = nationality_positions_rdd.distinct()  # Usuwamy duplikaty pozycji\n\n# Grupowanie po narodowo\u015bciach i zbieranie unikalnych pozycji\nnationality_positions_grouped = nationality_positions_rdd_distinct.groupByKey().mapValues(list)\n\n# \u0141\u0105czenie top_nationalities_rdd z nationality_positions_grouped po narodowo\u015bci (left outer join)\nfinal_nationalities_rdd = top_nationalities_rdd.map(lambda x: (\n    x[1],  # 'category', 'name', 'value', 'wage', 'age', 'count'\n    (x[2],  # sum_value_eur\n     x[3],  # avg_wage_eur\n     x[4],  # avg_age\n     x[5],  # count_players\n    )  \n)).leftOuterJoin(nationality_positions_grouped) \\\n  .map(lambda x: (\n      'nationality',    # category\n      x[0],             # name\n      x[1][0][0],       # sum_value_eur\n      x[1][0][1],       # avg_wage_eur\n      x[1][0][2],       # avg_age\n      x[1][0][3],       # count_players\n      x[1][1] if x[1][1] else []  # positions, default to empty list if no positions\n))\n\nfinal_nationalities_rdd = final_nationalities_rdd.sortBy(lambda x: x[2], ascending=False)"}, {"cell_type": "code", "execution_count": 22, "id": "744f5be1-3fb8-41fc-9b27-759c26ffb1ee", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Grupowanie po ligach\nleague_stats = processed_rdd.map(lambda row: (\n    row[8],  # league_name\n    (row[4], row[3], row[5], 1)  # wage_eur, value_eur, age, count\n)).reduceByKey(lambda a, b: (\n    a[0] + b[0],  # Suma wage_eur\n    a[1] + b[1],  # Suma value_eur\n    a[2] + b[2],  # Suma wieku\n    a[3] + b[3]   # Liczba graczy\n))\n\n# Obliczanie \u015brednich zarobk\u00f3w, wieku i sumy warto\u015bci oraz zaokr\u0105glanie dla lig\nleague_avg_stats = league_stats.map(lambda x: (\n    'league',                        # category\n    x[0],                            # name\n    round_value(x[1][1]),            # sum_value_eur (zaokr\u0105glone)\n    round_value(x[1][0] / x[1][3]),  # avg_wage_eur (zaokr\u0105glone)\n    round_value(x[1][2] / x[1][3]),  # avg_age (zaokr\u0105glone)\n    x[1][3]                          # count_players\n))\n\n# Sortowanie po sumie warto\u015bci (value_eur)\ntop_leagues_rdd = get_top_n(league_avg_stats, 3)\n\n# Tworzenie RDD z pozycji lig\nleague_positions_rdd = processed_rdd.flatMap(lambda row: [(row[8], position) for position in row[6]])  # (league_name, position)\n\n# Usuwanie duplikat\u00f3w pozycji (distinct) dla ka\u017cdej ligi\nleague_positions_rdd_distinct = league_positions_rdd.distinct()  # Usuwamy duplikaty pozycji\n\n# Grupowanie po ligach i zbieranie unikalnych pozycji\nleague_positions_grouped = league_positions_rdd_distinct.groupByKey().mapValues(list)\n\n# \u0141\u0105czenie top_leagues_rdd z league_positions_grouped po nazwie ligi (left outer join)\nfinal_leagues_rdd = top_leagues_rdd.map(lambda x: (\n    x[1],  # 'category', 'name', 'value', 'wage', 'age', 'count'\n    (x[2],  # sum_value_eur\n     x[3],  # avg_wage_eur\n     x[4],  # avg_age\n     x[5],  # count_players\n    )  \n)).leftOuterJoin(league_positions_grouped) \\\n  .map(lambda x: (\n      'league',        # category\n      x[0],            # name\n      x[1][0][0],      # sum_value_eur\n      x[1][0][1],      # avg_wage_eur\n      x[1][0][2],      # avg_age\n      x[1][0][3],      # count_players\n      x[1][1] if x[1][1] else []  # positions, default to empty list if no positions\n))\n\n# Sortowanie wynikowego RDD po sum_value_eur malej\u0105co\nfinal_leagues_rdd = final_leagues_rdd.sortBy(lambda x: x[2], ascending=False)"}, {"cell_type": "code", "execution_count": 23, "id": "78624c17-14f5-483f-9c9f-2126f7cb58ac", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Za\u0142aduj dane z processed_rdd (top_clubs_rdd)\nclub_stats = processed_rdd.map(lambda row: (\n    row[1],  # club_name\n    (row[4], row[3], row[5], 1)  # wage_eur, value_eur, age, count\n)).reduceByKey(lambda a, b: (\n    a[0] + b[0],  # Suma wage_eur\n    a[1] + b[1],  # Suma value_eur\n    a[2] + b[2],  # Suma wieku\n    a[3] + b[3],  # Liczba graczy\n))\n\n# Obliczanie \u015brednich zarobk\u00f3w, wieku i sumy warto\u015bci\nclub_avg_stats = club_stats.map(lambda x: (\n    'club',                         # category\n    x[0],                            # name (club_name)\n    round_value(x[1][1]),            # sum_value_eur (zaokr\u0105glone)\n    round_value(x[1][0] / x[1][3]),  # avg_wage_eur (zaokr\u0105glone)\n    round_value(x[1][2] / x[1][3]),  # avg_age (zaokr\u0105glone)\n    x[1][3],                         # count_players\n))\n\n# Sortowanie po sumie warto\u015bci (value_eur)\ntop_clubs_rdd = get_top_n(club_avg_stats, 3)\n\n# Tworzenie RDD z pozycji klub\u00f3w\nclub_positions_rdd = processed_rdd.flatMap(lambda row: [(row[1], position) for position in row[6]])  # (club_name, position)\n\n# Usuwanie duplikat\u00f3w pozycji (distinct) dla ka\u017cdego klubu\nclub_positions_rdd_distinct = club_positions_rdd.distinct()  # Usuwamy duplikaty pozycji\n\n# Grupowanie po klubach i zbieranie unikalnych pozycji\nclub_positions_grouped = club_positions_rdd_distinct.groupByKey().mapValues(list)\n\n# \u0141\u0105czenie top_clubs_rdd z club_positions_grouped po nazwie klubu (left outer join)\nfinal_clubs_rdd = top_clubs_rdd.map(lambda x: (\n    x[1],  # 'category', 'name', 'value', 'wage', 'age', 'count'\n    (x[2],  # sum_value_eur\n     x[3],  # avg_wage_eur\n     x[4],  # avg_age\n     x[5],  # count_players\n    )  \n)).leftOuterJoin(club_positions_grouped) \\\n  .map(lambda x: (\n      'club',          # category\n      x[0],            # name\n      x[1][0][0],      # sum_value_eur\n      x[1][0][1],      # avg_wage_eur\n      x[1][0][2],      # avg_age\n      x[1][0][3],      # count_players\n      x[1][1] if x[1][1] else []  # positions, default to empty list if no positions\n))\n\nfinal_clubs_rdd = final_clubs_rdd.sortBy(lambda x: x[2], ascending=False)"}, {"cell_type": "code", "execution_count": 24, "id": "2c34c9b1-6a6a-457c-a440-0170c44a06f8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "\nFinal Top 9:\n('club', 'Manchester City', 1281910000, 101385, 25, 39, ['ST', 'CF', 'RB', 'CAM', 'RM', 'GK', 'LB', 'RWB', 'CB', 'CM', 'LM', 'LW', 'CDM', 'RW'])\n('club', 'FC Barcelona', 1131875000, 91571, 24, 49, ['RWB', 'CM', 'CB', 'GK', 'ST', 'CF', 'CDM', 'LB', 'RB', 'RW', 'LW', 'LM', 'RM', 'CAM'])\n('club', 'Real Madrid', 1050650000, 118934, 24, 38, ['CM', 'CB', 'RW', 'LW', 'RB', 'CDM', 'CAM', 'RM', 'LB', 'GK', 'ST', 'CF'])\n('league', 'Premier League', 11049435000, 21002, 24, 2295, ['RWB', 'GK', 'RW', 'RB', 'CDM', 'LM', 'LW', 'CM', 'CB', 'LWB', 'LB', 'ST', 'CF', 'RM', 'CAM'])\n('league', 'Serie A', 7729900000, 19340, 26, 1544, ['GK', 'CDM', 'RW', 'LB', 'LWB', 'CAM', 'RM', 'RB', 'RWB', 'LW', 'LM', 'ST', 'CF', 'CB', 'CM'])\n('league', 'La Liga', 7612290000, 21643, 25, 1143, ['RW', 'CAM', 'RM', 'LWB', 'ST', 'CF', 'CM', 'CB', 'LB', 'RWB', 'GK', 'RB', 'LW', 'LM', 'CDM'])\n('nationality', 'Brazil', 7025990000, 13337, 27, 2440, ['LM', 'LW', 'ST', 'CF', 'GK', 'LB', 'RM', 'CAM', 'RB', 'CM', 'CB', 'RWB', 'RW', 'CDM', 'LWB'])\n('nationality', 'Egypt', 195570000, 17681, 26, 47, ['RWB', 'LB', 'RB', 'CDM', 'RW', 'RM', 'CAM', 'CM', 'CB', 'LM', 'LW', 'CF', 'ST'])\n('nationality', 'Dominican Republic', 10030000, 13800, 23, 10, ['LM', 'RB', 'CAM', 'RM', 'RW', 'LB', 'CB', 'CM', 'GK', 'ST'])\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# \u0141\u0105czenie wynik\u00f3w z ka\u017cdej kategorii (top 3 narodowo\u015bci, lig i klub\u00f3w)\nfinal_top_9_rdd = final_clubs_rdd.union(final_leagues_rdd).union(final_nationalities_rdd)\n\n# Wy\u015bwietlenie zawarto\u015bci RDD (ca\u0142o\u015b\u0107 top 9)\nfinal_top_9_list = final_top_9_rdd.collect()  # Pobierz wszystkie dane do lokalnej listy\nprint(\"\\nFinal Top 9:\")\nfor item in final_top_9_list:\n    print(item)\n\n# Zapisanie wyniku\nfinal_top_9_rdd.saveAsPickleFile(rdd_result_dir)"}, {"cell_type": "code", "execution_count": 25, "id": "6eaf8371-ad18-4845-8dc2-905ac99e05af", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'inputBytes': 34499267, 'shuffleReadBytes': 33597143, 'shuffleWriteBytes': 22903187}\n"}], "source": "# testowy paragraf\ntest_metrics = get_current_metrics(spark_ui_address)\n# Wybierz tylko te trzy interesuj\u0105ce parametry\nselected_metrics = {key: value for key, value in test_metrics.items() if key in ['shuffleReadBytes', 'shuffleWriteBytes', 'inputBytes']}\n# Wypisz wynik\nprint(selected_metrics)"}, {"cell_type": "markdown", "id": "42d8b5ec-b799-4177-8e4a-80a583d995e7", "metadata": {}, "source": "Poni\u017cszy paragraf zapisuje metryki po uruchomieniu Twojego rozwi\u0105zania *misji g\u0142\u00f3wnej*. \n\nNie musisz go uruchamia\u0107 podczas implementacji rozwi\u0105zania."}, {"cell_type": "code", "execution_count": 26, "id": "4325d378-b145-4e8f-8d37-80a072b506c3", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\nafter_rdd_metrics = get_current_metrics(spark_ui_address)\n#print(after_rdd_metrics)"}, {"cell_type": "markdown", "id": "28137d3d-6f0d-443f-97b8-38104aaced6d", "metadata": {}, "source": "# Cz\u0119\u015b\u0107 2 - Spark SQL (DataFrame)\n\n## Misje poboczne\n\nW ponizszych paragrafach wprowad\u017a swoje rozwi\u0105zania *misji pobocznych*, o ile **nie** chcesz, aby oceniana by\u0142a *misja g\u0142\u00f3wna*. W przeciwnym przypadku **KONIECZNIE** pozostaw je **puste**.  "}, {"cell_type": "code", "execution_count": null, "id": "6d045dae-5826-4015-8833-564d356db1f8", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "f7738406-c426-4238-b0fb-983f4585bc5a", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "5e7e569f-5f6b-4a98-b177-1b6fb0fc3333", "metadata": {}, "source": "## Misja g\u0142\u00f3wna \n\nPoni\u017cszy paragraf zapisuje metryki przed uruchomieniem Twojego rozwi\u0105zania *misji g\u0142\u00f3wnej*. \n\nNie musisz go uruchamia\u0107 podczas implementacji rozwi\u0105zania."}, {"cell_type": "code", "execution_count": 27, "id": "6329c04b-3e50-41a8-93f1-333ac0ea64ce", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\nbefore_df_metrics = get_current_metrics(spark_ui_address)"}, {"cell_type": "markdown", "id": "4c2cfb0d-51b6-45bb-b173-ab8ac630d4f3", "metadata": {}, "source": "W poni\u017cszych paragrafach wprowad\u017a **rozwi\u0105zanie** *misji g\u0142\u00f3wnej* swojego projektu oparte o *DataFrame API*. \n\nPami\u0119taj o wydajno\u015bci Twojego przetwarzania, *DataFrame API* nie jest w stanie wszystkiego \"naprawi\u0107\". \n\nNie wprowadzaj w poni\u017cszych paragrafach \u017cadnego kodu, w przypadku wykorzystania *misji pobocznych*."}, {"cell_type": "code", "execution_count": 28, "id": "ed13b6da-eb3e-4637-8359-b6149cdbb44a", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import functions as F"}, {"cell_type": "code", "execution_count": 29, "id": "eca6e627-0ce5-4c48-b441-3bcc14e32f36", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Za\u0142aduj dane z datasource1\ndf1 = spark.read.option(\"delimiter\", \";\").csv(datasource1_dir, header=False)\ndf1 = df1.select(\n    df1._c0.alias(\"player_id\"),   # player_id (kolumna 0)\n    df1._c16.alias(\"league_id\"),   # league_id (klucz)\n    df1._c18.alias(\"club_name\"),   # club_name\n    df1._c17.alias(\"club_team_id\"), # club_team_id\n    df1._c10.alias(\"value_eur\"),  # value_eur\n    df1._c11.alias(\"wage_eur\"),   # wage_eur\n    df1._c12.alias(\"age\"),        # age\n    F.split(df1._c7, \", \").alias(\"player_positions\"), # player_positions (split po przecinku)\n    df1._c25.alias(\"nationality\") # nationality\n)\n\n# Za\u0142aduj dane z datasource4\ndf4 = spark.read.option(\"delimiter\", \";\").csv(datasource4_dir, header=False)\ndf4 = df4.select(\n    df4._c0.alias(\"league_id\"),   # league_id (klucz)\n    df4._c1.alias(\"league_name\")  # league_name\n)"}, {"cell_type": "code", "execution_count": 30, "id": "cb1470ff-f428-4774-99b2-68927cb1438d", "metadata": {"tags": []}, "outputs": [], "source": "# Po\u0142\u0105czenie DataFrame (left join) na podstawie 'league_id'\nmerged_df = df1.join(df4, on=\"league_id\", how=\"left\") \\\n    .select(\n        df1.player_id,           # player_id\n        df1.club_name,           # club_name\n        df1.club_team_id,        # club_team_id\n        df1.value_eur,           # value_eur\n        df1.wage_eur,            # wage_eur\n        df1.age,                 # age\n        df1.player_positions,    # player_positions\n        df1.nationality,         # nationality\n        df4.league_name           # league_name (z df4, aby unikn\u0105\u0107 niejednoznaczno\u015bci)\n    )\n\n# Zamieniamy NULL na 'Unknown' w kolumnie 'league_name'\nmerged_df = merged_df.withColumn(\"league_name\", F.coalesce(df4.league_name, F.lit(\"Unknown\")))"}, {"cell_type": "code", "execution_count": 31, "id": "9a51633f-4658-4457-bda1-5570cf32c80f", "metadata": {"tags": []}, "outputs": [], "source": "# Grupowanie danych po lidze i klubie, zliczanie liczby unikalnych pi\u0142karzy w klubie\nclub_player_df = merged_df.select(\n    \"league_name\", \n    \"club_name\", \n    \"player_id\"\n).distinct()  # Upewniamy si\u0119, \u017ce ka\u017cdy pi\u0142karz jest liczone tylko raz\n\n# Liczenie liczby pi\u0142karzy w klubie\nplayers_count_by_club_df = club_player_df.groupBy(\"league_name\", \"club_name\") \\\n    .agg(F.count(\"player_id\").alias(\"players_count\"))\n\n# Filtrujemy kluby, kt\u00f3re maj\u0105 co najmniej 11 pi\u0142karzy\nvalid_clubs_df = players_count_by_club_df.filter(F.col(\"players_count\") >= 11)\n\n# Grupowanie wynik\u00f3w po lidze, zliczanie liczby klub\u00f3w w danej lidze\nclubs_in_leagues_df = valid_clubs_df.groupBy(\"league_name\") \\\n    .agg(F.count(\"club_name\").alias(\"clubs_count\"))\n\n# Filtrujemy ligi, w kt\u00f3rych jest przynajmniej 10 klub\u00f3w z co najmniej 11 pi\u0142karzami\nvalid_leagues_df = clubs_in_leagues_df.filter(F.col(\"clubs_count\") >= 10)\n\n# Zmiana nazwy kolumny \"league_name\" na \"valid_league_name\"\nvalid_leagues_df = valid_leagues_df.withColumnRenamed(\"league_name\", \"valid_league_name\")\n"}, {"cell_type": "code", "execution_count": 32, "id": "1fcec14f-7541-4f34-9862-81c873d7b1f3", "metadata": {"tags": []}, "outputs": [], "source": "# Wykonanie inner join pomi\u0119dzy merged_df a valid_leagues_df na odpowiednich kolumnach\nprocessed_df = merged_df.join(valid_leagues_df, merged_df[\"league_name\"] == valid_leagues_df[\"valid_league_name\"], how=\"inner\") \\\n    .select(\n        merged_df[\"player_id\"],        # player_id\n        merged_df[\"club_name\"],        # club_name\n        merged_df[\"club_team_id\"],     # club_team_id\n        merged_df[\"value_eur\"],        # value_eur\n        merged_df[\"wage_eur\"],         # wage_eur\n        merged_df[\"age\"],              # age\n        merged_df[\"player_positions\"], # player_positions\n        merged_df[\"nationality\"],      # nationality\n        valid_leagues_df[\"valid_league_name\"].alias(\"league_name\") # alias dla kolumny league_name\n    )"}, {"cell_type": "code", "execution_count": 33, "id": "fce8d7a7-d522-40db-95aa-0a1c6bc1a1ab", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tabela z wynikami 3xTop3 (nationality, league_name, club_name):\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 252:============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+------------------+-------------+------------+-------+-------------+----------------------------------------------------------------+\n|category   |name              |sum_value_eur|avg_wage_eur|avg_age|count_players|player_positions                                                |\n+-----------+------------------+-------------+------------+-------+-------------+----------------------------------------------------------------+\n|club_name  |Real Madrid       |1.05065E9    |118934.0    |24.0   |38           |[CDM, CAM, RM, ST, LB, RW, CB, CM, CF, RB, LW, GK]              |\n|club_name  |Manchester City   |1.28191E9    |101385.0    |25.0   |39           |[CDM, LB, GK, RB, LM, CM, ST, RWB, RW, CB, LW, CAM, CF, RM]     |\n|club_name  |FC Barcelona      |1.131875E9   |91571.0     |24.0   |49           |[ST, GK, CM, CDM, RB, CB, CAM, LW, RWB, RM, RW, LM, LB, CF]     |\n|league_name|La Liga           |7.61229E9    |21643.0     |25.0   |1143         |[CM, CAM, ST, LW, CDM, LM, RWB, RB, LWB, GK, CB, CF, LB, RM, RW]|\n|league_name|Premier League    |1.1049435E10 |21002.0     |24.0   |2295         |[CAM, LW, CM, CDM, GK, ST, LB, RM, CB, LM, RW, CF, RB, RWB, LWB]|\n|league_name|Serie A           |7.7299E9     |19340.0     |26.0   |1544         |[GK, CAM, CF, ST, RW, CM, LM, LB, RB, CB, RM, CDM, LW, RWB, LWB]|\n|nationality|Egypt             |1.9557E8     |17681.0     |26.0   |47           |[CF, CAM, RWB, RW, LW, LM, CDM, ST, CM, LB, CB, RM, RB]         |\n|nationality|Dominican Republic|1.003E7      |13800.0     |23.0   |10           |[ST, RM, RW, CB, LB, RB, CAM, CM, LM, GK]                       |\n|nationality|Brazil            |7.02599E9    |13337.0     |27.0   |2440         |[CDM, CF, ST, LM, LB, CAM, RM, LW, CM, RW, LWB, CB, RWB, RB, GK]|\n+-----------+------------------+-------------+------------+-------+-------------+----------------------------------------------------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "def calculate_top3_with_positions(processed_df, group_column, category_name):\n    # Obliczanie sumy dla wszystkich wymaganych kolumn\n    stats_df = processed_df.groupBy(group_column).agg(\n        F.sum(\"value_eur\").alias(\"sum_value_eur\"),\n        F.sum(\"age\").alias(\"sum_age\"),\n        F.sum(\"wage_eur\").alias(\"sum_wage_eur\"),\n        F.count(group_column).alias(\"count_players\")\n    )\n\n    # Obliczanie \u015brednich zarobk\u00f3w (avg_wage_eur) i \u015bredniego wieku (avg_age)\n    avg_stats_df = stats_df.withColumn(\n        \"avg_wage_eur\", F.round(F.col(\"sum_wage_eur\") / F.col(\"count_players\"))\n    ).withColumn(\n        \"avg_age\", F.round(F.col(\"sum_age\") / F.col(\"count_players\"))\n    )\n\n    # Usuwanie zb\u0119dnych kolumn sumy\n    avg_stats_df = avg_stats_df.drop(\"sum_wage_eur\").drop(\"sum_age\")\n\n    # Sortowanie po \u015brednich zarobkach (avg_wage_eur) i wybieranie top 3\n    top3_df = avg_stats_df.orderBy(F.col(\"avg_wage_eur\"), ascending=False).limit(3)\n\n    # Uzyskiwanie unikalnych pozycji dla ka\u017cdej grupy\n    positions_df = processed_df.select(group_column, \"player_positions\") \\\n        .withColumn(\"player_position\", F.explode(\"player_positions\")) \\\n        .dropDuplicates([group_column, \"player_position\"])\n\n    # Grupowanie pozycji zawodnik\u00f3w po grupie\n    positions_grouped_df = positions_df.groupBy(group_column).agg(\n        F.collect_list(\"player_position\").alias(\"positions\")\n    )\n\n    # \u0141\u0105czenie top3_df z positions_grouped_df\n    final_df = top3_df.join(positions_grouped_df, on=group_column, how=\"left\")\n\n    # Dodanie kolumny category\n    final_df = final_df.withColumn(\"category\", F.lit(category_name))\n\n    # Zmiana nazw kolumn\n    final_df = final_df.withColumnRenamed(group_column, \"name\") \\\n        .withColumnRenamed(\"positions\", \"player_positions\")\n\n    # Zaokr\u0105glanie kolumn sum_value_eur, avg_wage_eur i avg_age\n    final_df = final_df.withColumn(\"sum_value_eur\", F.round(F.col(\"sum_value_eur\")))\n\n    # Zmiana kolejno\u015bci kolumn, aby pasowa\u0142a do oczekiwanego wyniku\n    final_df = final_df.select(\n        \"category\", \"name\", \"sum_value_eur\", \"avg_wage_eur\", \"avg_age\", \"count_players\", \"player_positions\"\n    )\n    \n    final_df = final_df.orderBy(F.col(\"avg_wage_eur\"), ascending=False)\n\n    return final_df\n\n# Wyliczenie top3 dla ka\u017cdej kategorii\nfinal_nationalities_df = calculate_top3_with_positions(processed_df, \"nationality\", \"nationality\")\nfinal_leagues_df = calculate_top3_with_positions(processed_df, \"league_name\", \"league_name\")\nfinal_clubs_df = calculate_top3_with_positions(processed_df, \"club_name\", \"club_name\")\n\n# Po\u0142\u0105czenie wynik\u00f3w w jeden DataFrame\nfinal_top3_df = final_clubs_df.union(final_leagues_df).union(final_nationalities_df)\n\n# Wy\u015bwietlenie finalnej tabeli\nprint(\"Tabela z wynikami 3xTop3 (nationality, league_name, club_name):\")\nfinal_top3_df.show(9, truncate=False)"}, {"cell_type": "code", "execution_count": 34, "id": "45165cca-5197-4590-ba69-7541085147f9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/29 15:21:31 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n24/12/29 15:21:47 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"}], "source": "# Zapis wynik\u00f3w jako tabela Delta Lake\nfinal_top3_df.write.mode(\"overwrite\").saveAsTable(df_result_table)"}, {"cell_type": "code", "execution_count": 35, "id": "3dffb70f-f420-45fa-a024-11794ce16c03", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'inputBytes': 517536181, 'shuffleReadBytes': 55935799, 'shuffleWriteBytes': 45241559}\n"}], "source": "# testowy paragraf\ntest_metrics = get_current_metrics(spark_ui_address)\n# Wybierz tylko te trzy interesuj\u0105ce parametry\nselected_metrics = {key: value for key, value in test_metrics.items() if key in ['shuffleReadBytes', 'shuffleWriteBytes', 'inputBytes']}\n# Wypisz wynik\nprint(selected_metrics)"}, {"cell_type": "markdown", "id": "d0797752-450e-4f8f-a1d4-93a890a62c3d", "metadata": {}, "source": "Poni\u017cszy paragraf zapisuje metryki po uruchomieniu Twojego rozwi\u0105zania *misji g\u0142\u00f3wnej*. \n\nNie musisz go uruchamia\u0107 podczas implementacji rozwi\u0105zania."}, {"cell_type": "code", "execution_count": 36, "id": "c3647eae-2801-46ac-b43d-74e5bbfcab52", "metadata": {}, "outputs": [], "source": "# NIE ZMIENIA\u0106\nafter_df_metrics = get_current_metrics(spark_ui_address)"}, {"cell_type": "markdown", "id": "3bed01aa-cc23-427e-84c8-e5b76b9323bb", "metadata": {}, "source": "# Cz\u0119\u015b\u0107 3 - Pandas API on Spark\n\nTa cz\u0119\u015b\u0107 to wyzwanie. W szczeg\u00f3lno\u015bci dla os\u00f3b, kt\u00f3re nie programuj\u0105 na co dzie\u0144 w Pythonie, lub kt\u00f3re nie nie korzysta\u0142y do tej pory z Pandas API.  \n\nPowodzenia!\n\n## Misje poboczne\n\nW ponizszych paragrafach wprowad\u017a swoje rozwi\u0105zania *misji pobocznych*, o ile **nie** chcesz, aby oceniana by\u0142a *misja g\u0142\u00f3wna*. W przeciwnym przypadku **KONIECZNIE** pozostaw je **puste**.  "}, {"cell_type": "code", "execution_count": null, "id": "971a265f-db04-4a26-936d-18ab875ddffa", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "91621654-a24e-4ddb-b2c7-9f149252af13", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "9a5184ce-cf42-4342-aeec-b56c30b66bbd", "metadata": {}, "source": "## Misja g\u0142\u00f3wna \n\nPoni\u017cszy paragraf zapisuje metryki przed uruchomieniem Twojego rozwi\u0105zania *misji g\u0142\u00f3wnej*. \n\nNie musisz go uruchamia\u0107 podczas implementacji rozwi\u0105zania."}, {"cell_type": "code", "execution_count": 37, "id": "63fd8306-87e9-46f2-b622-d60693e3ba6d", "metadata": {}, "outputs": [], "source": "#NIE ZMIENIA\u0106\nbefore_ps_metrics = get_current_metrics(spark_ui_address)"}, {"cell_type": "markdown", "id": "a967f079-7106-4bd7-9d26-98ced2aeb43b", "metadata": {}, "source": "W poni\u017cszych paragrafach wprowad\u017a **rozwi\u0105zanie** swojego projektu oparte o *Pandas API on Spark*. \n\nPami\u0119taj o wydajno\u015bci Twojego przetwarzania, *Pandas API on Spark* nie jest w stanie wszystkiego \"naprawi\u0107\". \n\nNie wprowadzaj w poni\u017cszych paragrafach \u017cadnego kodu, w przypadku wykorzystania *misji pobocznych*."}, {"cell_type": "code", "execution_count": 38, "id": "e2094a69-30b1-4970-825b-2b0624436cd5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n  warnings.warn(\n/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"}], "source": "import pyspark.pandas as ps\n\n# Za\u0142aduj dane z datasource1\ndf1 = ps.read_csv(datasource1_dir, sep=\";\", header=None)\ndf1.columns = [f\"_c{i}\" for i in range(len(df1.columns))]  # Tymczasowe nazwy kolumn\ndf1 = df1[[\"_c0\", \"_c16\", \"_c18\", \"_c17\", \"_c10\", \"_c11\", \"_c12\", \"_c7\", \"_c25\"]]\ndf1.columns = [\n    \"player_id\",         # player_id (kolumna 0)\n    \"league_id\",         # league_id\n    \"club_name\",         # club_name\n    \"club_team_id\",      # club_team_id\n    \"value_eur\",         # value_eur\n    \"wage_eur\",          # wage_eur\n    \"age\",               # age\n    \"player_positions\",  # player_positions\n    \"nationality\"        # nationality\n]\n\n# Rozdzielanie warto\u015bci w \"player_positions\" na list\u0119\ndf1[\"player_positions\"] = df1[\"player_positions\"].apply(\n    lambda x: x.split(\", \") if isinstance(x, str) else []\n)\n\n# Za\u0142aduj dane z datasource4\ndf4 = ps.read_csv(datasource4_dir, sep=\";\", header=None)\ndf4.columns = [f\"_c{i}\" for i in range(len(df4.columns))]  # Tymczasowe nazwy kolumn\ndf4 = df4[[\"_c0\", \"_c1\"]]\ndf4.columns = [\"league_id\", \"league_name\"]"}, {"cell_type": "code", "execution_count": 39, "id": "b02917f4-e1f2-4fb4-8b53-8829fb3f0689", "metadata": {}, "outputs": [], "source": "# Po\u0142\u0105czenie DataFrame (left join) na podstawie 'league_id'\nmerged_df = df1.merge(df4, on=\"league_id\", how=\"left\")\n\n# Wybieranie odpowiednich kolumn\nmerged_df = merged_df[[\n    \"player_id\",           # player_id\n    \"club_name\",           # club_name\n    \"club_team_id\",        # club_team_id\n    \"value_eur\",           # value_eur\n    \"wage_eur\",            # wage_eur\n    \"age\",                 # age\n    \"player_positions\",    # player_positions\n    \"nationality\",         # nationality\n    \"league_name\"          # league_name (z df4)\n]]\n"}, {"cell_type": "code", "execution_count": 40, "id": "f26253ad-ae41-4882-9859-9db4fb34b3dd", "metadata": {"tags": []}, "outputs": [], "source": "# Grupowanie danych po lidze i klubie, liczenie liczby pi\u0142karzy w klubie\nplayers_count_by_club_df = merged_df.groupby([\"league_name\", \"club_name\"]) \\\n    .size().reset_index(name=\"players_count\")\n\n# Filtrujemy kluby, kt\u00f3re maj\u0105 co najmniej 11 pi\u0142karzy\nvalid_clubs_df = players_count_by_club_df[players_count_by_club_df[\"players_count\"] >= 11]\n\n# Grupowanie wynik\u00f3w po lidze, liczenie liczby klub\u00f3w w danej lidze\nclubs_in_leagues_df = valid_clubs_df.groupby(\"league_name\") \\\n    .size().reset_index(name=\"clubs_count\")\n\n# Filtrujemy ligi, w kt\u00f3rych jest przynajmniej 10 klub\u00f3w z co najmniej 11 pi\u0142karzami\nvalid_leagues_df = clubs_in_leagues_df[clubs_in_leagues_df[\"clubs_count\"] >= 10]\n\n# # Debugging: wy\u015bwietlanie wynik\u00f3w\n# print(\"Ligi spe\u0142niaj\u0105ce warunek:\")\n# print(valid_leagues_df.head(50))\n"}, {"cell_type": "code", "execution_count": 41, "id": "838bb888-d51a-46d2-b4f2-2e0d8a4b1141", "metadata": {"tags": []}, "outputs": [], "source": "# Po\u0142\u0105czenie DataFrame (right join) na podstawie 'league_name' w Pandas API on Spark\nprocessed_df = merged_df.merge(valid_leagues_df[[\"league_name\"]], on=\"league_name\", how=\"inner\")\n\n# Wybieramy odpowiednie kolumny\nprocessed_df = processed_df[[\n    \"player_id\",           # player_id\n    \"club_name\",           # club_name\n    \"club_team_id\",        # club_team_id\n    \"value_eur\",           # value_eur\n    \"wage_eur\",            # wage_eur\n    \"age\",                 # age\n    \"player_positions\",    # player_positions\n    \"nationality\",         # nationality\n    \"league_name\"          # league_name\n]]\n"}, {"cell_type": "code", "execution_count": 42, "id": "c1b686e4-a3c2-428a-9508-0dafaa4b202a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `groupby.apply`, it is expensive to infer the data type internally.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n24/12/29 15:22:09 WARN AttachDistributedSequenceExec: clean up cached RDD(384) in AttachDistributedSequenceExec(23138)\n/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `groupby.apply`, it is expensive to infer the data type internally.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n24/12/29 15:22:15 WARN AttachDistributedSequenceExec: clean up cached RDD(426) in AttachDistributedSequenceExec(24178)\n/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `groupby.apply`, it is expensive to infer the data type internally.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n24/12/29 15:22:21 WARN AttachDistributedSequenceExec: clean up cached RDD(464) in AttachDistributedSequenceExec(25178)\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Tabela z wynikami 3xTop3 (nationality, league_name, club_name):\n"}, {"name": "stderr", "output_type": "stream", "text": "24/12/29 15:22:34 WARN AttachDistributedSequenceExec: clean up cached RDD(530) in AttachDistributedSequenceExec(29436)\n24/12/29 15:22:38 WARN AttachDistributedSequenceExec: clean up cached RDD(544) in AttachDistributedSequenceExec(29782)\n[Stage 431:============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "      category                name  sum_value_eur  avg_wage_eur  avg_age  count_players                                                  player_positions\n0    club_name         Real Madrid   1.050650e+09      118934.0     24.0             38                [CAM, CB, CDM, CF, CM, GK, LB, LW, RB, RM, RW, ST]\n1    club_name     Manchester City   1.281910e+09      101385.0     25.0             39       [CAM, CB, CDM, CF, CM, GK, LB, LM, LW, RB, RM, RW, RWB, ST]\n2    club_name        FC Barcelona   1.131875e+09       91571.0     24.0             49       [CAM, CB, CDM, CF, CM, GK, LB, LM, LW, RB, RM, RW, RWB, ST]\n0  league_name             La Liga   7.612290e+09       21643.0     25.0           1143  [CAM, CB, CDM, CF, CM, GK, LB, LM, LW, LWB, RB, RM, RW, RWB, ST]\n1  league_name      Premier League   1.104944e+10       21002.0     24.0           2295  [CAM, CB, CDM, CF, CM, GK, LB, LM, LW, LWB, RB, RM, RW, RWB, ST]\n2  league_name             Serie A   7.729900e+09       19340.0     26.0           1544  [CAM, CB, CDM, CF, CM, GK, LB, LM, LW, LWB, RB, RM, RW, RWB, ST]\n2  nationality               Egypt   1.955700e+08       17681.0     26.0             47           [CAM, CB, CDM, CF, CM, LB, LM, LW, RB, RM, RW, RWB, ST]\n1  nationality  Dominican Republic   1.003000e+07       13800.0     23.0             10                         [CAM, CB, CM, GK, LB, LM, RB, RM, RW, ST]\n0  nationality              Brazil   7.025990e+09       13337.0     27.0           2440  [CAM, CB, CDM, CF, CM, GK, LB, LM, LW, LWB, RB, RM, RW, RWB, ST]\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "def calculate_top3_with_positions_ps(processed_df, group_column, category_name):\n    \n    # Obliczanie sumy dla wszystkich wymaganych kolumn, zachowanie group_column\n    stats_df = processed_df.groupby(group_column).agg(\n        sum_value_eur=(\"value_eur\", \"sum\"),\n        sum_age=(\"age\", \"sum\"),\n        sum_wage_eur=(\"wage_eur\", \"sum\"),\n        count_players=(group_column, \"count\")\n    )\n\n    # Obliczanie \u015brednich zarobk\u00f3w (avg_wage_eur) i \u015bredniego wieku (avg_age)\n    stats_df[\"avg_wage_eur\"] = (stats_df[\"sum_wage_eur\"] / stats_df[\"count_players\"]).round()\n    stats_df[\"avg_age\"] = (stats_df[\"sum_age\"] / stats_df[\"count_players\"]).round()\n\n    # Usuwanie zb\u0119dnych kolumn sumy\n    stats_df = stats_df.drop(columns=[\"sum_wage_eur\", \"sum_age\"])\n\n    # Przywracanie kolumny group_column do stats_df przed sortowaniem\n    stats_df[group_column] = stats_df.index\n\n    # Sortowanie po \u015brednich zarobkach (avg_wage_eur) i wybieranie top 3\n    top3_df = stats_df.sort_values(by=\"avg_wage_eur\", ascending=False).head(3)\n\n    # Uzyskiwanie unikalnych pozycji dla ka\u017cdej grupy (bez u\u017cycia set)\n    positions_df = processed_df[[group_column, \"player_positions\"]] \\\n        .explode(\"player_positions\") \\\n        .drop_duplicates([group_column, \"player_positions\"])\n\n    # Grupowanie pozycji zawodnik\u00f3w po grupie i tworzenie listy pozycji dla ka\u017cdego rekordu\n    positions_grouped_df = positions_df.groupby(group_column)[\"player_positions\"].apply(lambda x: x.drop_duplicates().tolist()).reset_index()\n\n    # \u0141\u0105czenie top3_df z positions_grouped_df\n    final_df = top3_df.merge(positions_grouped_df, on=group_column, how=\"left\")\n\n    # Dodanie kolumny category\n    final_df[\"category\"] = category_name\n\n    # Zmiana nazw kolumn\n    final_df = final_df.rename(columns={group_column: \"name\", \"player_positions\": \"player_positions\"})\n\n    # Zaokr\u0105glanie kolumn sum_value_eur, avg_wage_eur i avg_age\n    final_df[\"sum_value_eur\"] = final_df[\"sum_value_eur\"].round()\n\n    # Zmiana kolejno\u015bci kolumn, aby pasowa\u0142a do oczekiwanego wyniku\n    final_df = final_df[[\"category\", \"name\", \"sum_value_eur\", \"avg_wage_eur\", \"avg_age\", \"count_players\", \"player_positions\"]]\n\n    # Sortowanie wynik\u00f3w po \u015brednich zarobkach\n    final_df = final_df.sort_values(by=\"avg_wage_eur\", ascending=False)\n\n    return final_df\n\n# Wyliczenie top3 dla ka\u017cdej kategorii\nfinal_nationalities_df = calculate_top3_with_positions_ps(processed_df, \"nationality\", \"nationality\")\nfinal_leagues_df = calculate_top3_with_positions_ps(processed_df, \"league_name\", \"league_name\")\nfinal_clubs_df = calculate_top3_with_positions_ps(processed_df, \"club_name\", \"club_name\")\n\n# Po\u0142\u0105czenie wynik\u00f3w w jeden DataFrame przy u\u017cyciu pyspark.pandas.concat\nfinal_top3_df = ps.concat([final_clubs_df, final_leagues_df, final_nationalities_df])\n\n# Wy\u015bwietlenie finalnej tabeli\nprint(\"Tabela z wynikami 3xTop3 (nationality, league_name, club_name):\")\nprint(final_top3_df)"}, {"cell_type": "code", "execution_count": 43, "id": "76e0d7f7-82f3-41d4-8267-cf288f2f6e81", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n24/12/29 15:22:56 WARN AttachDistributedSequenceExec: clean up cached RDD(659) in AttachDistributedSequenceExec(39337)\n24/12/29 15:23:00 WARN AttachDistributedSequenceExec: clean up cached RDD(673) in AttachDistributedSequenceExec(39683)\n                                                                                \r"}], "source": "final_top3_df.to_json(ps_result_file, orient='records')"}, {"cell_type": "code", "execution_count": 44, "id": "daae4fd1-f908-4628-a812-49ee5dd50080", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'inputBytes': 1277186242, 'shuffleReadBytes': 78581281, 'shuffleWriteBytes': 67886491}\n"}], "source": "# testowy paragraf\ntest_metrics = get_current_metrics(spark_ui_address)\n# Wybierz tylko te trzy interesuj\u0105ce parametry\nselected_metrics = {key: value for key, value in test_metrics.items() if key in ['shuffleReadBytes', 'shuffleWriteBytes', 'inputBytes']}\n# Wypisz wynik\nprint(selected_metrics)"}, {"cell_type": "markdown", "id": "298a0ec5-ab13-4e39-a572-e7adf8b8556a", "metadata": {}, "source": "Poni\u017cszy paragraf zapisuje metryki po uruchomieniu Twojego rozwi\u0105zania *misji g\u0142\u00f3wnej*. \n\nNie musisz go uruchamia\u0107 podczas implementacji rozwi\u0105zania."}, {"cell_type": "code", "execution_count": 45, "id": "108bee2a-a847-4625-8e4a-939951ac9201", "metadata": {}, "outputs": [], "source": "#NIE ZMIENIA\u0106\nafter_ps_metrics = get_current_metrics(spark_ui_address)"}, {"cell_type": "markdown", "id": "e32e266b-b5cd-41d0-aeab-c1edc365910d", "metadata": {}, "source": "# Analiza wynik\u00f3w i wydajno\u015bci *misji g\u0142\u00f3wnych*"}, {"cell_type": "markdown", "id": "46b67111-62d0-4657-b158-1ed37db9ed96", "metadata": {}, "source": "## Cz\u0119\u015b\u0107 1 - Spark Core (RDD)"}, {"cell_type": "code", "execution_count": 46, "id": "5cfc9900-7e0c-49ff-adba-e339f83ffe51", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 500:====================================================>  (68 + 3) / 71]\r"}, {"name": "stdout", "output_type": "stream", "text": "('club', 'Manchester City', 1281910000, 101385, 25, 39, ['ST', 'CF', 'RB', 'CAM', 'RM', 'GK', 'LB', 'RWB', 'CB', 'CM', 'LM', 'LW', 'CDM', 'RW'])\n('club', 'FC Barcelona', 1131875000, 91571, 24, 49, ['RWB', 'CM', 'CB', 'GK', 'ST', 'CF', 'CDM', 'LB', 'RB', 'RW', 'LW', 'LM', 'RM', 'CAM'])\n('club', 'Real Madrid', 1050650000, 118934, 24, 38, ['CM', 'CB', 'RW', 'LW', 'RB', 'CDM', 'CAM', 'RM', 'LB', 'GK', 'ST', 'CF'])\n('league', 'Premier League', 11049435000, 21002, 24, 2295, ['RWB', 'GK', 'RW', 'RB', 'CDM', 'LM', 'LW', 'CM', 'CB', 'LWB', 'LB', 'ST', 'CF', 'RM', 'CAM'])\n('league', 'Serie A', 7729900000, 19340, 26, 1544, ['GK', 'CDM', 'RW', 'LB', 'LWB', 'CAM', 'RM', 'RB', 'RWB', 'LW', 'LM', 'ST', 'CF', 'CB', 'CM'])\n('league', 'La Liga', 7612290000, 21643, 25, 1143, ['RW', 'CAM', 'RM', 'LWB', 'ST', 'CF', 'CM', 'CB', 'LB', 'RWB', 'GK', 'RB', 'LW', 'LM', 'CDM'])\n('nationality', 'Brazil', 7025990000, 13337, 27, 2440, ['LM', 'LW', 'ST', 'CF', 'GK', 'LB', 'RM', 'CAM', 'RB', 'CM', 'CB', 'RWB', 'RW', 'CDM', 'LWB'])\n('nationality', 'Egypt', 195570000, 17681, 26, 47, ['RWB', 'LB', 'RB', 'CDM', 'RW', 'RM', 'CAM', 'CM', 'CB', 'LM', 'LW', 'CF', 'ST'])\n('nationality', 'Dominican Republic', 10030000, 13800, 23, 10, ['LM', 'RB', 'CAM', 'RM', 'RW', 'LB', 'CB', 'CM', 'GK', 'ST'])\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Wczytanie wynik\u00f3w z pliku pickle\nword_counts = sc.pickleFile(rdd_result_dir)\n\n# Wy\u015bwietlenie 50 pierwszych element\u00f3w\nresult_sample = word_counts.take(50)\nfor item in result_sample:\n    print(item)"}, {"cell_type": "code", "execution_count": 47, "id": "16edae69-8062-4422-842f-d50bca0af9a7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n  \"numTasks\": 3628,\n  \"numActiveTasks\": 0,\n  \"numCompleteTasks\": 1004,\n  \"numFailedTasks\": 0,\n  \"numKilledTasks\": 0,\n  \"numCompletedIndices\": 1004,\n  \"executorDeserializeTime\": 9001,\n  \"executorDeserializeCpuTime\": 4358148294,\n  \"executorRunTime\": 249222,\n  \"executorCpuTime\": 16483027046,\n  \"resultSize\": 2151644,\n  \"jvmGcTime\": 1594,\n  \"resultSerializationTime\": 1284,\n  \"memoryBytesSpilled\": 0,\n  \"diskBytesSpilled\": 0,\n  \"peakExecutionMemory\": 0,\n  \"inputBytes\": 34499267,\n  \"inputRecords\": 56937,\n  \"outputBytes\": 1746,\n  \"outputRecords\": 9,\n  \"shuffleRemoteBlocksFetched\": 2139,\n  \"shuffleLocalBlocksFetched\": 2631,\n  \"shuffleFetchWaitTime\": 305,\n  \"shuffleRemoteBytesRead\": 14328026,\n  \"shuffleRemoteBytesReadToDisk\": 0,\n  \"shuffleLocalBytesRead\": 19269117,\n  \"shuffleReadBytes\": 33597143,\n  \"shuffleReadRecords\": 12076,\n  \"shuffleWriteBytes\": 22903187,\n  \"shuffleWriteTime\": 1041478711,\n  \"shuffleWriteRecords\": 9972\n}\n"}], "source": "subtract_metrics(after_rdd_metrics, before_rdd_metrics)"}, {"cell_type": "markdown", "id": "efc730f1-4b5e-4a68-8a86-11768918fcf4", "metadata": {}, "source": "## Cz\u0119\u015b\u0107 2 - Spark SQL (DataFrame)"}, {"cell_type": "code", "execution_count": 48, "id": "b950a09d-045e-4143-a3cf-8ecc7c73ac41", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+------------------+-------------+------------+-------+-------------+--------------------+\n|   category|              name|sum_value_eur|avg_wage_eur|avg_age|count_players|    player_positions|\n+-----------+------------------+-------------+------------+-------+-------------+--------------------+\n|  club_name|       Real Madrid|    1.05065E9|    118934.0|   24.0|           38|[CDM, CAM, RM, ST...|\n|  club_name|   Manchester City|    1.28191E9|    101385.0|   25.0|           39|[CDM, LB, GK, RB,...|\n|  club_name|      FC Barcelona|   1.131875E9|     91571.0|   24.0|           49|[ST, GK, CM, CDM,...|\n|league_name|           La Liga|    7.61229E9|     21643.0|   25.0|         1143|[CM, CAM, ST, LW,...|\n|league_name|    Premier League| 1.1049435E10|     21002.0|   24.0|         2295|[CAM, LW, CM, CDM...|\n|league_name|           Serie A|     7.7299E9|     19340.0|   26.0|         1544|[GK, CAM, CF, ST,...|\n|nationality|             Egypt|     1.9557E8|     17681.0|   26.0|           47|[CF, CAM, RWB, RW...|\n|nationality|Dominican Republic|      1.003E7|     13800.0|   23.0|           10|[ST, RM, RW, CB, ...|\n|nationality|            Brazil|    7.02599E9|     13337.0|   27.0|         2440|[CDM, CF, ST, LM,...|\n+-----------+------------------+-------------+------------+-------+-------------+--------------------+\n\n"}], "source": "df = spark.table(df_result_table)\n\n# Wy\u015bwietlenie 50 pierwszych rekord\u00f3w\ndf.show(50)"}, {"cell_type": "code", "execution_count": 49, "id": "3f344ed9-94c1-4d79-b839-1839548d8c67", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n  \"numTasks\": 324,\n  \"numActiveTasks\": 0,\n  \"numCompleteTasks\": 145,\n  \"numFailedTasks\": 0,\n  \"numKilledTasks\": 0,\n  \"numCompletedIndices\": 145,\n  \"executorDeserializeTime\": 7067,\n  \"executorDeserializeCpuTime\": 3047873357,\n  \"executorRunTime\": 119931,\n  \"executorCpuTime\": 30342004680,\n  \"resultSize\": 1155180,\n  \"jvmGcTime\": 4050,\n  \"resultSerializationTime\": 270,\n  \"memoryBytesSpilled\": 0,\n  \"diskBytesSpilled\": 0,\n  \"peakExecutionMemory\": 11906516208,\n  \"inputBytes\": 483036914,\n  \"inputRecords\": 796436,\n  \"outputBytes\": 7432,\n  \"outputRecords\": 9,\n  \"shuffleRemoteBlocksFetched\": 32,\n  \"shuffleLocalBlocksFetched\": 53,\n  \"shuffleFetchWaitTime\": 0,\n  \"shuffleRemoteBytesRead\": 9225228,\n  \"shuffleRemoteBytesReadToDisk\": 0,\n  \"shuffleLocalBytesRead\": 13113428,\n  \"shuffleReadBytes\": 22338656,\n  \"shuffleReadRecords\": 843849,\n  \"shuffleWriteBytes\": 22338372,\n  \"shuffleWriteTime\": 215685499,\n  \"shuffleWriteRecords\": 843846\n}\n"}], "source": "subtract_metrics(after_df_metrics, before_df_metrics)"}, {"cell_type": "markdown", "id": "f063b46c-579d-4775-ba3f-837708279ea2", "metadata": {}, "source": "## Cz\u0119\u015b\u0107 3 - Pandas API on Spark"}, {"cell_type": "code", "execution_count": 50, "id": "ab5e31a2-fd31-40ca-be7b-b20b13dc38a2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_json`, the default index is attached which can cause additional overhead.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"}, {"name": "stdout", "output_type": "stream", "text": "[\n  {\n    \"avg_age\": 25.0,\n    \"avg_wage_eur\": 21643.0,\n    \"category\": \"league_name\",\n    \"count_players\": 1143,\n    \"name\": \"La Liga\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"LWB\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 7612290000.0\n  },\n  {\n    \"avg_age\": 24.0,\n    \"avg_wage_eur\": 21002.0,\n    \"category\": \"league_name\",\n    \"count_players\": 2295,\n    \"name\": \"Premier League\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"LWB\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 11049435000.0\n  },\n  {\n    \"avg_age\": 26.0,\n    \"avg_wage_eur\": 19340.0,\n    \"category\": \"league_name\",\n    \"count_players\": 1544,\n    \"name\": \"Serie A\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"LWB\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 7729900000.0\n  },\n  {\n    \"avg_age\": 24.0,\n    \"avg_wage_eur\": 118934.0,\n    \"category\": \"club_name\",\n    \"count_players\": 38,\n    \"name\": \"Real Madrid\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LW\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 1050650000.0\n  },\n  {\n    \"avg_age\": 25.0,\n    \"avg_wage_eur\": 101385.0,\n    \"category\": \"club_name\",\n    \"count_players\": 39,\n    \"name\": \"Manchester City\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 1281910000.0\n  },\n  {\n    \"avg_age\": 24.0,\n    \"avg_wage_eur\": 91571.0,\n    \"category\": \"club_name\",\n    \"count_players\": 49,\n    \"name\": \"FC Barcelona\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 1131875000.0\n  },\n  {\n    \"avg_age\": 26.0,\n    \"avg_wage_eur\": 17681.0,\n    \"category\": \"nationality\",\n    \"count_players\": 47,\n    \"name\": \"Egypt\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 195570000.0\n  },\n  {\n    \"avg_age\": 23.0,\n    \"avg_wage_eur\": 13800.0,\n    \"category\": \"nationality\",\n    \"count_players\": 10,\n    \"name\": \"Dominican Republic\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 10030000.0\n  },\n  {\n    \"avg_age\": 27.0,\n    \"avg_wage_eur\": 13337.0,\n    \"category\": \"nationality\",\n    \"count_players\": 2440,\n    \"name\": \"Brazil\",\n    \"player_positions\": [\n      \"CAM\",\n      \"CB\",\n      \"CDM\",\n      \"CF\",\n      \"CM\",\n      \"GK\",\n      \"LB\",\n      \"LM\",\n      \"LW\",\n      \"LWB\",\n      \"RB\",\n      \"RM\",\n      \"RW\",\n      \"RWB\",\n      \"ST\"\n    ],\n    \"sum_value_eur\": 7025990000.0\n  }\n]\n"}], "source": "# Odczytaj zawarto\u015b\u0107 pliku JSON przy u\u017cyciu Pandas API on Spark\nread_df = ps.read_json(ps_result_file, lines=True)\n\n# Przekszta\u0142\u0107 dane do formatu s\u0142ownika (listy s\u0142ownik\u00f3w)\nresult_list = read_df.to_dict(orient='records')\n\n# Sformatuj dane jako \u0142adnie sformatowany JSON i wy\u015bwietl je\nimport json\nformatted_result = json.dumps(result_list, indent=2, ensure_ascii=False)\n\n# Wy\u015bwietl zawarto\u015b\u0107\nprint(formatted_result)"}, {"cell_type": "code", "execution_count": 51, "id": "32788c91-3f8e-4fb1-8afc-5eb00938e687", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n  \"numTasks\": 477,\n  \"numActiveTasks\": 0,\n  \"numCompleteTasks\": 226,\n  \"numFailedTasks\": 0,\n  \"numKilledTasks\": 0,\n  \"numCompletedIndices\": 226,\n  \"executorDeserializeTime\": 6715,\n  \"executorDeserializeCpuTime\": 2782501965,\n  \"executorRunTime\": 204486,\n  \"executorCpuTime\": 41719718988,\n  \"resultSize\": 1538619,\n  \"jvmGcTime\": 5825,\n  \"resultSerializationTime\": 418,\n  \"memoryBytesSpilled\": 0,\n  \"diskBytesSpilled\": 0,\n  \"peakExecutionMemory\": 17164003344,\n  \"inputBytes\": 759650061,\n  \"inputRecords\": 1551475,\n  \"outputBytes\": 2011,\n  \"outputRecords\": 9,\n  \"shuffleRemoteBlocksFetched\": 45,\n  \"shuffleLocalBlocksFetched\": 70,\n  \"shuffleFetchWaitTime\": 0,\n  \"shuffleRemoteBytesRead\": 8278599,\n  \"shuffleRemoteBytesReadToDisk\": 0,\n  \"shuffleLocalBytesRead\": 14366883,\n  \"shuffleReadBytes\": 22645482,\n  \"shuffleReadRecords\": 870460,\n  \"shuffleWriteBytes\": 22644932,\n  \"shuffleWriteTime\": 217734453,\n  \"shuffleWriteRecords\": 870454\n}\n"}], "source": "subtract_metrics(after_ps_metrics, before_ps_metrics)"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}