{"cells": [{"cell_type": "markdown", "id": "7ed3b9ae", "metadata": {}, "source": "# Sprawdzenie dost\u0119pno\u015bci bibliotek Delta Lake\n\nNa pocz\u0105tku wykonaj poni\u017csze paragrafy tworz\u0105ce tabel\u0119 Delta Lake, je\u015bli wszystko si\u0119 powiedzie mo\u017cesz przej\u015b\u0107 do sekcji ***Wprowadzenie*** pomin\u0105\u0107 nast\u0119pn\u0105 sekcj\u0119 po\u015bwi\u0119con\u0105 konfiguracji. \nW przeciwnym razie wykonaj polecenia z sekcji ***Konfiguracja***."}, {"cell_type": "code", "execution_count": 1, "id": "b8e117ee-ef0a-4eff-99ff-7bd4b23b69d9", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"}, {"name": "stderr", "output_type": "stream", "text": "Ivy Default Cache set to: /root/.ivy2/cache\nThe jars for the packages stored in: /root/.ivy2/jars\nio.delta#delta-core_2.12 added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-24012c40-b6af-4536-ab15-b049d61f5884;1.0\n\tconfs: [default]\n\tfound io.delta#delta-core_2.12;2.3.0 in central\n\tfound io.delta#delta-storage;2.3.0 in central\n\tfound org.antlr#antlr4-runtime;4.8 in central\n:: resolution report :: resolve 332ms :: artifacts dl 11ms\n\t:: modules in use:\n\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n\tio.delta#delta-storage;2.3.0 from central in [default]\n\torg.antlr#antlr4-runtime;4.8 from central in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n\t---------------------------------------------------------------------\n:: retrieving :: org.apache.spark#spark-submit-parent-24012c40-b6af-4536-ab15-b049d61f5884\n\tconfs: [default]\n\t0 artifacts copied, 3 already retrieved (0kB/9ms)\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/12/26 12:37:10 INFO SparkEnv: Registering MapOutputTracker\n24/12/26 12:37:10 INFO SparkEnv: Registering BlockManagerMaster\n24/12/26 12:37:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n24/12/26 12:37:10 INFO SparkEnv: Registering OutputCommitCoordinator\n24/12/26 12:37:13 WARN Client: Same path resource file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar added multiple times to distributed cache.\n24/12/26 12:37:13 WARN Client: Same path resource file:///root/.ivy2/jars/io.delta_delta-storage-2.3.0.jar added multiple times to distributed cache.\n24/12/26 12:37:13 WARN Client: Same path resource file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar added multiple times to distributed cache.\n"}], "source": "import pyspark\nfrom delta import *\nfrom pyspark.sql.functions import col, explode, array\n\nbuilder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n    .config(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n\nspark = configure_spark_with_delta_pip(builder).getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "fddce442-d423-44cd-b4a6-20d47acdbeb1", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/26 12:37:37 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \r"}], "source": "data = (\n    spark.range(0, 5)\n    .selectExpr(\"id as x\")\n    .withColumn(\"y\", explode(array(col(\"x\"))))\n    .select(\"x\", \"y\")\n)\n\n# Zapis danych do formatu Delta\ndata.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta-table2\")"}, {"cell_type": "markdown", "id": "b1b79625", "metadata": {}, "source": "# Wprowadzenie\n\n## Skonfigurowanie danych \u017ar\u00f3d\u0142owych \n\nZanim zaczniemy korzysta\u0107 i poznawa\u0107 funkcjonalno\u015bci biblioteki Delta Lake skonfigurujmy tabel\u0119 z danymi \u017ar\u00f3d\u0142owymi. \nA nast\u0119pnie uruchom go tworz\u0105c tymczasow\u0105 perspektyw\u0119 na przygotowanych uprzednio danych \u017ar\u00f3d\u0142owych. "}, {"cell_type": "code", "execution_count": 3, "id": "b69c87d5", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- address: string (nullable = true)\n |-- zipcode: string (nullable = true)\n |-- city: string (nullable = true)\n |-- country: string (nullable = true)\n |-- effectiveDate: string (nullable = true)\n\n"}], "source": "source_df = (\n    spark.read\n    .option(\"header\", True)\n    .option(\"quote\", \"\\\"\")\n    .csv(\"/tmp/DeltaLakeSourceData\")\n)\n\n# Wy\u015bwietlenie schematu ramki danych\nsource_df.printSchema()\n\n# Utworzenie tymczasowej tabeli\nsource_df.createOrReplaceTempView(\"source_data\")"}, {"cell_type": "markdown", "id": "1c44f09a", "metadata": {}, "source": " \nNasze dane \u017ar\u00f3d\u0142owe zawieraj\u0105 informacje na temat klient\u00f3w z kolejnych okres\u00f3w czasu.\n\nUruchom poni\u017csze zapytanie wydobywaj\u0105ce wersje danych, kt\u00f3re by\u0142y aktualne na dzie\u0144 `2021-01-01`."}, {"cell_type": "code", "execution_count": 4, "id": "bef11a2b", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"\"\"\nselect id, name, address, zipcode, city, country, effectiveDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate, \n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") < to_date(\"2021-01-01\",\"yyyy-MM-dd\")\n    ) tab\nwhere version = 1\"\"\")"}, {"cell_type": "code", "execution_count": 5, "id": "ee0ee224", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>Jin Terry</td>\n      <td>467-8297 Enim</td>\n      <td>35633573</td>\n      <td>Bal\u0131kesir</td>\n      <td>Nigeria</td>\n      <td>06-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>Harriet Rojas</td>\n      <td>Ap #810-8710 Enim. St.</td>\n      <td>84541</td>\n      <td>Lipetsk</td>\n      <td>Canada</td>\n      <td>21-10-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11</td>\n      <td>Isabelle Stevenson</td>\n      <td>131-4245 Eleifend. Street</td>\n      <td>16142</td>\n      <td>H\u00e0 Giang</td>\n      <td>Russian Federation</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>Leo Mcleod</td>\n      <td>467-8297 Enim</td>\n      <td>39153</td>\n      <td>Bor\u00e5s</td>\n      <td>Germany</td>\n      <td>16-10-2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>Kaitlin Landry</td>\n      <td>623-5682 Augue St.</td>\n      <td>351225</td>\n      <td>Libramont-Chevigny</td>\n      <td>Indonesia</td>\n      <td>29-10-2020</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>19</td>\n      <td>Alden Harper</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>94671-72608</td>\n      <td>Ch\u00e2tellerault</td>\n      <td>Nigeria</td>\n      <td>06-12-2020</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>Brandon Christian</td>\n      <td>476-5064 Suspendisse Rd.</td>\n      <td>93-765</td>\n      <td>Broxburn</td>\n      <td>Russian Federation</td>\n      <td>28-11-2020</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Peru</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>26</td>\n      <td>Ulysses Dillard</td>\n      <td>1318 Tempor Rd.</td>\n      <td>S5J 6Z2</td>\n      <td>Tuscaloosa</td>\n      <td>United States</td>\n      <td>11-10-2020</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>33</td>\n      <td>Alexander Becker</td>\n      <td>Ap #631-7469 Curae St.</td>\n      <td>29941</td>\n      <td>Anseong</td>\n      <td>United States</td>\n      <td>04-11-2020</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4</td>\n      <td>Hall Mayer</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>23072</td>\n      <td>Vetlanda</td>\n      <td>Sweden</td>\n      <td>13-11-2020</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>41</td>\n      <td>Plato Vaughan</td>\n      <td>Ap #502-453 Non Rd.</td>\n      <td>06255-18554</td>\n      <td>Zoerle-Parwijs</td>\n      <td>South Korea</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>42</td>\n      <td>Steel Ruiz</td>\n      <td>747-9558 Dignissim Ave</td>\n      <td>7550</td>\n      <td>Fallo</td>\n      <td>New Zealand</td>\n      <td>18-11-2020</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>49</td>\n      <td>Porter Morrison</td>\n      <td>9797 Ultrices Av.</td>\n      <td>G4K 6J6</td>\n      <td>Serang</td>\n      <td>New Zealand</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>5</td>\n      <td>Sonia Shepherd</td>\n      <td>467-8297 Enim</td>\n      <td>7077 VL</td>\n      <td>Tregaron</td>\n      <td>Colombia</td>\n      <td>31-12-2020</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>50</td>\n      <td>Cruz Schwartz</td>\n      <td>982-9172 Quisque Rd.</td>\n      <td>30810</td>\n      <td>San Rafael</td>\n      <td>Sweden</td>\n      <td>19-10-2020</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>54</td>\n      <td>Mona Chambers</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>24109</td>\n      <td>Baddeck</td>\n      <td>United States</td>\n      <td>19-12-2020</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>56</td>\n      <td>Yolanda Moran</td>\n      <td>Ap #719-6171 Vulputate Avenue</td>\n      <td>88791</td>\n      <td>Norderstedt</td>\n      <td>Mexico</td>\n      <td>11-12-2020</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>59</td>\n      <td>Larissa Frederick</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>56210</td>\n      <td>Mohmand Agency</td>\n      <td>Ireland</td>\n      <td>24-11-2020</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>61</td>\n      <td>Judah Middleton</td>\n      <td>199-113 Euismod Av.</td>\n      <td>866533</td>\n      <td>Fortaleza</td>\n      <td>Germany</td>\n      <td>26-10-2020</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>62</td>\n      <td>Griffin Mooney</td>\n      <td>417-2786 Bibendum Ave</td>\n      <td>2441 YB</td>\n      <td>Ghizer</td>\n      <td>Costa Rica</td>\n      <td>16-10-2020</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>71</td>\n      <td>Gary Avila</td>\n      <td>P.O. Box 221, 1718 Sociis Rd.</td>\n      <td>856505</td>\n      <td>Chambave</td>\n      <td>Canada</td>\n      <td>20-12-2020</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>76</td>\n      <td>Marcia Clark</td>\n      <td>889-1239 Turpis. St.</td>\n      <td>842518</td>\n      <td>Quetta</td>\n      <td>Belgium</td>\n      <td>01-11-2020</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>8</td>\n      <td>Genevieve Leonard</td>\n      <td>776-6460 Nibh. Rd.</td>\n      <td>36007</td>\n      <td>Port Lincoln</td>\n      <td>Vietnam</td>\n      <td>28-12-2020</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>86</td>\n      <td>Ruth Giles</td>\n      <td>Ap #132-6063 Pretium Ave</td>\n      <td>1631</td>\n      <td>Morwell</td>\n      <td>New Zealand</td>\n      <td>12-11-2020</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>87</td>\n      <td>Dustin Cantrell</td>\n      <td>302-5659 Sit St.</td>\n      <td>3196</td>\n      <td>Mount Isa</td>\n      <td>India</td>\n      <td>12-11-2020</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>88</td>\n      <td>Hilel Flowers</td>\n      <td>Ap #132-6063 Pretium Ave</td>\n      <td>11890</td>\n      <td>M\u00e9rida</td>\n      <td>Australia</td>\n      <td>30-12-2020</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>95</td>\n      <td>Timon Munoz</td>\n      <td>Ap #789-3620 Aliquet St.</td>\n      <td>448129</td>\n      <td>Jeonju</td>\n      <td>South Korea</td>\n      <td>05-12-2020</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>96</td>\n      <td>Rafael Lindsey</td>\n      <td>Ap #609-1107 Integer Av.</td>\n      <td>178766</td>\n      <td>Adrano</td>\n      <td>Netherlands</td>\n      <td>27-11-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "     id                name                        address      zipcode  \\\n0    10           Jin Terry                  467-8297 Enim     35633573   \n1   100       Harriet Rojas         Ap #810-8710 Enim. St.        84541   \n2    11  Isabelle Stevenson      131-4245 Eleifend. Street        16142   \n3    14          Leo Mcleod                  467-8297 Enim        39153   \n4    16      Kaitlin Landry             623-5682 Augue St.       351225   \n5    19        Alden Harper        Ap #579-2185 Sed Street  94671-72608   \n6     2   Brandon Christian       476-5064 Suspendisse Rd.       93-765   \n7    20       Kathleen Pugh                  7018 Cras St.         3123   \n8    26     Ulysses Dillard                1318 Tempor Rd.      S5J 6Z2   \n9    28      Shaine Puckett        Ap #579-2185 Sed Street        85629   \n10   33    Alexander Becker         Ap #631-7469 Curae St.        29941   \n11    4          Hall Mayer        Ap #579-2185 Sed Street        23072   \n12   41       Plato Vaughan            Ap #502-453 Non Rd.  06255-18554   \n13   42          Steel Ruiz         747-9558 Dignissim Ave         7550   \n14   49     Porter Morrison              9797 Ultrices Av.      G4K 6J6   \n15    5      Sonia Shepherd                  467-8297 Enim      7077 VL   \n16   50       Cruz Schwartz           982-9172 Quisque Rd.        30810   \n17   54       Mona Chambers        337-6887 Tincidunt, St.        24109   \n18   56       Yolanda Moran  Ap #719-6171 Vulputate Avenue        88791   \n19   59   Larissa Frederick        337-6887 Tincidunt, St.        56210   \n20   61     Judah Middleton            199-113 Euismod Av.       866533   \n21   62      Griffin Mooney          417-2786 Bibendum Ave      2441 YB   \n22   68      Clarke Carlson            2296 Vestibulum St.       163826   \n23   71          Gary Avila  P.O. Box 221, 1718 Sociis Rd.       856505   \n24   74        Vernon Casey             650-5308 Felis Rd.        42987   \n25   76        Marcia Clark           889-1239 Turpis. St.       842518   \n26    8   Genevieve Leonard             776-6460 Nibh. Rd.        36007   \n27   86          Ruth Giles       Ap #132-6063 Pretium Ave         1631   \n28   87     Dustin Cantrell               302-5659 Sit St.         3196   \n29   88       Hilel Flowers       Ap #132-6063 Pretium Ave        11890   \n30   95         Timon Munoz       Ap #789-3620 Aliquet St.       448129   \n31   96      Rafael Lindsey       Ap #609-1107 Integer Av.       178766   \n\n                       city             country effectiveDate  \n0                 Bal\u0131kesir             Nigeria    06-11-2020  \n1                   Lipetsk              Canada    21-10-2020  \n2                  H\u00e0 Giang  Russian Federation    25-11-2020  \n3                     Bor\u00e5s             Germany    16-10-2020  \n4        Libramont-Chevigny           Indonesia    29-10-2020  \n5             Ch\u00e2tellerault             Nigeria    06-12-2020  \n6                  Broxburn  Russian Federation    28-11-2020  \n7   Ostrowiec \u015awi\u0119tokrzyski                Peru    16-11-2020  \n8                Tuscaloosa       United States    11-10-2020  \n9                  Cochrane              Poland    07-12-2020  \n10                  Anseong       United States    04-11-2020  \n11                 Vetlanda              Sweden    13-11-2020  \n12           Zoerle-Parwijs         South Korea    25-11-2020  \n13                    Fallo         New Zealand    18-11-2020  \n14                   Serang         New Zealand    07-12-2020  \n15                 Tregaron            Colombia    31-12-2020  \n16               San Rafael              Sweden    19-10-2020  \n17                  Baddeck       United States    19-12-2020  \n18              Norderstedt              Mexico    11-12-2020  \n19           Mohmand Agency             Ireland    24-11-2020  \n20                Fortaleza             Germany    26-10-2020  \n21                   Ghizer          Costa Rica    16-10-2020  \n22               Logan City              Poland    28-10-2020  \n23                 Chambave              Canada    20-12-2020  \n24                   Mirpur            Pakistan    14-11-2020  \n25                   Quetta             Belgium    01-11-2020  \n26             Port Lincoln             Vietnam    28-12-2020  \n27                  Morwell         New Zealand    12-11-2020  \n28                Mount Isa               India    12-11-2020  \n29                   M\u00e9rida           Australia    30-12-2020  \n30                   Jeonju         South Korea    05-12-2020  \n31                   Adrano         Netherlands    27-11-2020  "}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "f53f3bde", "metadata": {}, "source": "W poni\u017cszych zadaniach mo\u017cesz skorzysta\u0107 zar\u00f3wno z interfejsu w Scali jak i SQL. \n\nWszystko zale\u017cy od Twoich preferencji.\n\nUwaga! W przypadku korzystania z SQL i wskazywania \u015bcie\u017cek, konieczne jest wykorzystywanie schematu `hdfs`.\n\nPrzyk\u0142adowo `hdfs:/tmp/delta-customers`"}, {"cell_type": "markdown", "id": "66901018-5391-4074-b060-9297693285f2", "metadata": {}, "source": "## DDL\n\n### Zadanie 1\n\nUtw\u00f3rz pust\u0105 tabel\u0119 *Delta Lake* o nazwie `customers`, kt\u00f3rej lokalizacj\u0105 b\u0119dzie `/tmp/delta-customers` (lub `hdfs:/tmp/delta-customers`). \n\nKolumny tabeli musz\u0105 odpowiada\u0107 kolumnom danych \u017ar\u00f3d\u0142owych. \nWszystkie kolumny powinny by\u0107 ci\u0105gami znak\u00f3w o d\u0142ugo\u015bci do 200 znak\u00f3w\n\nJe\u015bli uruchamiasz ten notatnik po raz kolejny. Usu\u0144 zawarto\u015b\u0107 katalogu z danymi tabeli Delta Lake wywo\u0142uj\u0105c poni\u017csze polecenie"}, {"cell_type": "code", "execution_count": 6, "id": "092af9a0-d7c1-4628-aab1-08248a096b1f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Deleted /tmp/delta-customers\n"}], "source": "%%sh\nif hadoop fs -test -e /tmp/delta-customers; then\n  hadoop fs -rm -r /tmp/delta-customers\nelse\n  echo \"Directory already removed\"\nfi"}, {"cell_type": "markdown", "id": "5accd0da", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 1"}, {"cell_type": "code", "execution_count": 7, "id": "8c087546", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"DROP TABLE IF EXISTS customers\")"}, {"cell_type": "code", "execution_count": 8, "id": "fa5ae5d8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/26 12:38:43 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `default`.`customers` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n24/12/26 12:38:43 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\nCREATE TABLE customers\n(\n  id   VARCHAR(200),\n  name VARCHAR(200),\n  address VARCHAR(200),\n  zipcode VARCHAR(200),\n  city VARCHAR(200),\n  country VARCHAR(200),\n  effectiveDate VARCHAR(200)\n)\nUSING DELTA\nLOCATION 'hdfs:/tmp/delta-customers';\n\"\"\")\n"}, {"cell_type": "markdown", "id": "bd14cff0", "metadata": {}, "source": "## DML\n\n### Zadanie 2\n\nWprowad\u017a do utworzonej przez Ciebie tabeli dane o naszych klientach obowi\u0105zuj\u0105ce na dzie\u0144 `2021-01-01`."}, {"cell_type": "markdown", "id": "f904f019", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 2"}, {"cell_type": "code", "execution_count": 9, "id": "97949544", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\nINSERT INTO customers\n(id, name, address, zipcode, city, country, effectiveDate)\nSELECT id, name, address, zipcode, city, country, effectiveDate\nFROM (\n    SELECT id, name, address, zipcode, city, country, effectiveDate, \n           rank() OVER (PARTITION BY id ORDER BY to_date(effectiveDate, \"dd-MM-yyyy\") DESC) AS version\n    FROM source_data\n    WHERE to_date(effectiveDate, \"dd-MM-yyyy\") < DATE '2021-01-01'\n)\nWHERE version = 1;\n\"\"\")\n"}, {"cell_type": "markdown", "id": "e1605e1b", "metadata": {}, "source": "### Zadanie 3\n\nZmie\u0144 kraj zamieszkania na warto\u015b\u0107 `Poland` u wszystkich klient\u00f3w posiadaj\u0105cych warto\u015b\u0107 id mniejsz\u0105 ni\u017c 50. \n\nZwr\u00f3\u0107 uwag\u0119, \u017ce obecnie id jest ci\u0105giem znak\u00f3w. U\u017cyj wyra\u017cenia `cast(id as int)` aby wykona\u0107 zadanie prawid\u0142owo."}, {"cell_type": "markdown", "id": "8b3d530e", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 3"}, {"cell_type": "code", "execution_count": 10, "id": "84a37670", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[num_affected_rows: bigint]"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\n    UPDATE customers\n    SET country = 'Poland'\n    WHERE CAST(id AS INT) < 50\n\"\"\")\n"}, {"cell_type": "markdown", "id": "166e098d-0f60-4a00-a4c5-65ff46a5f309", "metadata": {}, "source": "Na chwil\u0119 si\u0119 zatrzymajmy. Utworzenie tabeli to wpis w metadanych. Wprowadzenie nowych danych to utworzenie nowych plik\u00f3w w katalogu tabeli. Czym by\u0142o zmodyfikowanie tych danych? \n\nWykonaj poni\u017csze polecenie, aby przygl\u0105dn\u0105\u0107 si\u0119 zawarto\u015bci katalogu nale\u017c\u0105cego do tabeli `customers`"}, {"cell_type": "code", "execution_count": 11, "id": "4a7b6dc9-8ce9-4a2c-805e-95f35307be90", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 3 items\ndrwxr-xr-x   - root hadoop          0 2024-12-26 12:39 /tmp/delta-customers/_delta_log\n-rw-r--r--   2 root hadoop       4424 2024-12-26 12:39 /tmp/delta-customers/part-00000-39f5e085-51bb-4810-a751-12da3f5987ce-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       4473 2024-12-26 12:38 /tmp/delta-customers/part-00000-8dfc8f44-04d4-4626-9e62-eee53aaa0b43-c000.snappy.parquet\n"}], "source": "%%sh\nhadoop fs -ls /tmp/delta-customers"}, {"cell_type": "markdown", "id": "053e101d", "metadata": {}, "source": "Mamy katalog z logiem transakcyjnym i dwa pliki, kt\u00f3re prawie nie r\u00f3\u017cni\u0105 si\u0119 wielko\u015bci\u0105.\n\nSpr\u00f3bujmy zrozumie\u0107 znaczenie tych plik\u00f3w zagl\u0105daj\u0105c do historii zmian w naszej tabeli. \nKoniecznie przestudiuj kolumn\u0119 `operationMetrics`"}, {"cell_type": "code", "execution_count": 12, "id": "a92d1d45", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.sql(\"describe history customers\")"}, {"cell_type": "code", "execution_count": 13, "id": "51750b32", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>version</th>\n      <th>timestamp</th>\n      <th>userId</th>\n      <th>userName</th>\n      <th>operation</th>\n      <th>operationParameters</th>\n      <th>job</th>\n      <th>notebook</th>\n      <th>clusterId</th>\n      <th>readVersion</th>\n      <th>isolationLevel</th>\n      <th>isBlindAppend</th>\n      <th>operationMetrics</th>\n      <th>userMetadata</th>\n      <th>engineInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2024-12-26 12:39:01.160</td>\n      <td>None</td>\n      <td>None</td>\n      <td>UPDATE</td>\n      <td>{'predicate': '(cast(id#1555 as int) &lt; 50)'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1.0</td>\n      <td>Serializable</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4473', 'numAddedFiles': '...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2024-12-26 12:38:46.954</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WRITE</td>\n      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{'numOutputRows': '32', 'numOutputBytes': '447...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2024-12-26 12:38:35.984</td>\n      <td>None</td>\n      <td>None</td>\n      <td>CREATE TABLE</td>\n      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   version               timestamp userId userName     operation  \\\n0        2 2024-12-26 12:39:01.160   None     None        UPDATE   \n1        1 2024-12-26 12:38:46.954   None     None         WRITE   \n2        0 2024-12-26 12:38:35.984   None     None  CREATE TABLE   \n\n                                 operationParameters   job notebook clusterId  \\\n0       {'predicate': '(cast(id#1555 as int) < 50)'}  None     None      None   \n1            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n2  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n\n   readVersion isolationLevel  isBlindAppend  \\\n0          1.0   Serializable          False   \n1          0.0   Serializable           True   \n2          NaN   Serializable           True   \n\n                                    operationMetrics userMetadata  \\\n0  {'numRemovedBytes': '4473', 'numAddedFiles': '...         None   \n1  {'numOutputRows': '32', 'numOutputBytes': '447...         None   \n2                                                 {}         None   \n\n                            engineInfo  \n0  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n1  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n2  Apache-Spark/3.3.2 Delta-Lake/2.3.0  "}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "da1558b3", "metadata": {}, "source": "Poni\u017csze zapytanie dostarcza danych o klientach, \nkt\u00f3rzy pojawili si\u0119 jako nowi, lub zmienili swoje dane w styczniu 2021."}, {"cell_type": "code", "execution_count": 14, "id": "dd913f5f", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"\"\"\nselect id, name, address, zipcode, city, country, effectiveDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate, \n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") >= date \"2021-01-01\"\n    and    to_date(effectiveDate,\"dd-MM-yyyy\") < date \"2021-02-01\"\n    )\nwhere version = 1\"\"\")"}, {"cell_type": "code", "execution_count": 15, "id": "689138f6", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>Vance Palmer</td>\n      <td>P.O. Box 221, 1718 Sociis Rd.</td>\n      <td>525734</td>\n      <td>Camarones</td>\n      <td>Poland</td>\n      <td>23-01-2021</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14</td>\n      <td>Pearl Ward</td>\n      <td>401-3122 Aliquam Av.</td>\n      <td>4449</td>\n      <td>Elbistan</td>\n      <td>Spain</td>\n      <td>02-01-2021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>Desirae Morin</td>\n      <td>Ap #675-9646 Ridiculus Avenue</td>\n      <td>22382</td>\n      <td>Bergen op Zoom</td>\n      <td>New Zealand</td>\n      <td>30-01-2021</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>Jerome Hines</td>\n      <td>598-974 Convallis Av.</td>\n      <td>10783</td>\n      <td>Tharparkar</td>\n      <td>Colombia</td>\n      <td>15-01-2021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29</td>\n      <td>Darius Cole</td>\n      <td>Ap #412-3424 Eu St.</td>\n      <td>12178</td>\n      <td>Birecik</td>\n      <td>New Zealand</td>\n      <td>30-01-2021</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>Robin Hartman</td>\n      <td>960-7120 Lectus Rd.</td>\n      <td>833082</td>\n      <td>Fundaci\u00f3n</td>\n      <td>Peru</td>\n      <td>26-01-2021</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>44</td>\n      <td>Kasimir Irwin</td>\n      <td>156-1322 Nulla. Road</td>\n      <td>50218</td>\n      <td>H\u1ed3 Ch\u00ed Minh City</td>\n      <td>Canada</td>\n      <td>30-01-2021</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>49</td>\n      <td>Justin Burch</td>\n      <td>806-9586 Quis Rd.</td>\n      <td>83477-576</td>\n      <td>Sokoto</td>\n      <td>Sweden</td>\n      <td>06-01-2021</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>59</td>\n      <td>Coby Blackwell</td>\n      <td>311-203 Ipsum St.</td>\n      <td>249414</td>\n      <td>Belfast</td>\n      <td>Mexico</td>\n      <td>13-01-2021</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6</td>\n      <td>Jaime Dillon</td>\n      <td>8224 Amet Road</td>\n      <td>53604</td>\n      <td>Korneuburg</td>\n      <td>Peru</td>\n      <td>17-01-2021</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>63</td>\n      <td>Ralph Ochoa</td>\n      <td>Ap #132-6063 Pretium Ave</td>\n      <td>68427-120</td>\n      <td>Burin</td>\n      <td>United Kingdom</td>\n      <td>17-01-2021</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>69</td>\n      <td>Chaney Ray</td>\n      <td>4442 Duis Avenue</td>\n      <td>64757</td>\n      <td>Stockholm</td>\n      <td>Nigeria</td>\n      <td>28-01-2021</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>77</td>\n      <td>Iris Emerson</td>\n      <td>Ap #493-1418 Massa. Ave</td>\n      <td>8968</td>\n      <td>Zaragoza</td>\n      <td>Canada</td>\n      <td>19-01-2021</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>8</td>\n      <td>Yoshio Medina</td>\n      <td>Ap #498-478 Adipiscing Road</td>\n      <td>O9 4WK</td>\n      <td>Tewkesbury</td>\n      <td>Mexico</td>\n      <td>29-01-2021</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>84</td>\n      <td>Bevis Mccoy</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>392223</td>\n      <td>Enns</td>\n      <td>Poland</td>\n      <td>06-01-2021</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "     id            name                        address    zipcode  \\\n0   100    Vance Palmer  P.O. Box 221, 1718 Sociis Rd.     525734   \n1    14      Pearl Ward           401-3122 Aliquam Av.       4449   \n2    21   Desirae Morin  Ap #675-9646 Ridiculus Avenue      22382   \n3    27    Jerome Hines          598-974 Convallis Av.      10783   \n4    29     Darius Cole            Ap #412-3424 Eu St.      12178   \n5     4   Robin Hartman            960-7120 Lectus Rd.     833082   \n6    44   Kasimir Irwin           156-1322 Nulla. Road      50218   \n7    49    Justin Burch              806-9586 Quis Rd.  83477-576   \n8    59  Coby Blackwell              311-203 Ipsum St.     249414   \n9     6    Jaime Dillon                 8224 Amet Road      53604   \n10   63     Ralph Ochoa       Ap #132-6063 Pretium Ave  68427-120   \n11   69      Chaney Ray               4442 Duis Avenue      64757   \n12   77    Iris Emerson        Ap #493-1418 Massa. Ave       8968   \n13    8   Yoshio Medina    Ap #498-478 Adipiscing Road     O9 4WK   \n14   84     Bevis Mccoy        337-6887 Tincidunt, St.     392223   \n\n                city         country effectiveDate  \n0          Camarones          Poland    23-01-2021  \n1           Elbistan           Spain    02-01-2021  \n2     Bergen op Zoom     New Zealand    30-01-2021  \n3         Tharparkar        Colombia    15-01-2021  \n4            Birecik     New Zealand    30-01-2021  \n5          Fundaci\u00f3n            Peru    26-01-2021  \n6   H\u1ed3 Ch\u00ed Minh City          Canada    30-01-2021  \n7             Sokoto          Sweden    06-01-2021  \n8            Belfast          Mexico    13-01-2021  \n9         Korneuburg            Peru    17-01-2021  \n10             Burin  United Kingdom    17-01-2021  \n11         Stockholm         Nigeria    28-01-2021  \n12          Zaragoza          Canada    19-01-2021  \n13        Tewkesbury          Mexico    29-01-2021  \n14              Enns          Poland    06-01-2021  "}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "243bc7d5", "metadata": {}, "source": "### Zadanie 4\n\nChcemy zaktualizowa\u0107 dane naszych klient\u00f3w w oparciu o ich styczniowe wersje. Zrobimy to w dw\u00f3ch krokach\n\n1. Usuniemy z tabeli `customers` dane ju\u017c nieaktualne, a nast\u0119pnie \n2. Wstawimy do niej dane zgodne ze styczniowymi zmianami\n\nUsu\u0144 z tabeli `customers` tych klient\u00f3w, kt\u00f3rzy zmienili swoje dane w styczniu 2021. Identyfikacja klient\u00f3w odbywa\u0107 si\u0119 powinna za ka\u017cdym razem w oparciu o atrybut `id`.\n\nJe\u015bli oka\u017ce si\u0119, \u017ce polecenie `DELETE` nie wspiera podzapyta\u0144, skorzystaj z interfejsu w Scali,\nlub za pomoc\u0105 poni\u017cszego kodu, w dodatkowym paragrafie uzyskaj identyfikatory klient\u00f3w do usuni\u0119cia, a nast\u0119pnie wkomponuj uzyskan\u0105 warto\u015b\u0107 w polecenie usuwaj\u0105ce klient\u00f3w.\n\n```python\nusun_ids_df = spark.sql(\"\"\"\n    SELECT id AS usun\n    FROM (\n        SELECT\n            id, name, address, zipcode, city, country, effectiveDate,\n            RANK() OVER (PARTITION BY id ORDER BY to_date(effectiveDate, 'dd-MM-yyyy') DESC) AS version\n        FROM source_data\n        WHERE to_date(effectiveDate, 'dd-MM-yyyy') >= '2021-01-01'\n            AND to_date(effectiveDate, 'dd-MM-yyyy') < '2021-02-01'\n    ) tab\n    WHERE version = 1\n\"\"\")\n\n# Pobranie wynik\u00f3w jako listy\nusun_ids_list = usun_ids_df.select(\"usun\").rdd.flatMap(lambda x: x).collect()\n\n# Konwersja do ci\u0105gu znak\u00f3w\nusun_ids_str = \",\".join(map(str, usun_ids_list))\n```"}, {"cell_type": "markdown", "id": "779d884a", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 4 - dodatkowy paragraf"}, {"cell_type": "code", "execution_count": 16, "id": "48eb2072", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "usun_ids_df = spark.sql(\"\"\"\n    SELECT id AS usun\n    FROM (\n        SELECT\n            id, name, address, zipcode, city, country, effectiveDate,\n            RANK() OVER (PARTITION BY id ORDER BY to_date(effectiveDate, 'dd-MM-yyyy') DESC) AS version\n        FROM source_data\n        WHERE to_date(effectiveDate, 'dd-MM-yyyy') >= '2021-01-01'\n            AND to_date(effectiveDate, 'dd-MM-yyyy') < '2021-02-01'\n    ) tab\n    WHERE version = 1\n\"\"\")\n\n# Pobranie wynik\u00f3w jako listy\nusun_ids_list = usun_ids_df.select(\"usun\").rdd.flatMap(lambda x: x).collect()\n\n# Konwersja do ci\u0105gu znak\u00f3w\nusun_ids_str = \",\".join(map(str, usun_ids_list))"}, {"cell_type": "markdown", "id": "33152a43", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 4"}, {"cell_type": "code", "execution_count": 17, "id": "2197c0e3", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[num_affected_rows: bigint]"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "# Wykonanie zapytania SQL do usuni\u0119cia rekord\u00f3w\nspark.sql(f\"\"\"\n    DELETE FROM customers\n    WHERE id IN ({usun_ids_str})\n\"\"\")"}, {"cell_type": "markdown", "id": "7cb55f32", "metadata": {}, "source": "Za pomoc\u0105 poni\u017cszego polecenia wstaw do tabeli `customers` dane klient\u00f3w, \nkt\u00f3rzy zmienili swoje dane w styczniu 2021."}, {"cell_type": "code", "execution_count": 18, "id": "512e5387", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\nINSERT INTO customers \nselect id, name, address, zipcode, city, country, effectiveDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate, \n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") >= date \"2021-01-01\"\n    and    to_date(effectiveDate,\"dd-MM-yyyy\") < date \"2021-02-01\"\n    )\nwhere version = 1\"\"\")"}, {"cell_type": "markdown", "id": "d1a49484-e04f-4462-9734-98e81ff1f90f", "metadata": {}, "source": "Zanim przejdziemy dalej, ponownie zastan\u00f3wmy si\u0119 nad tym co dzia\u0142o si\u0119 pod spodem. \n\nSpr\u00f3buj odpowiedzie\u0107 na dwa pytania:\n\n1. Ile nowych plik\u00f3w przyby\u0142o po naszych dw\u00f3ch operacjach `delete` i `insert`.\n2. Ile plik\u00f3w b\u0119dzie aktywnych - wykorzystywanych przy zapytaniach?\n\nZnasz odpowiedzi? Sprawd\u017amy czy s\u0105 one prawid\u0142owe.\n\nWykonaj poni\u017csze polecenia"}, {"cell_type": "code", "execution_count": 19, "id": "ad688589-b8b8-45c3-bee0-da8e2b858460", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 5 items\ndrwxr-xr-x   - root hadoop          0 2024-12-26 12:39 /tmp/delta-customers/_delta_log\n-rw-r--r--   2 root hadoop       4433 2024-12-26 12:39 /tmp/delta-customers/part-00000-05b50041-aa6e-467e-bdf5-0cab105d90b3-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       4424 2024-12-26 12:39 /tmp/delta-customers/part-00000-39f5e085-51bb-4810-a751-12da3f5987ce-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       4473 2024-12-26 12:38 /tmp/delta-customers/part-00000-8dfc8f44-04d4-4626-9e62-eee53aaa0b43-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       3218 2024-12-26 12:39 /tmp/delta-customers/part-00000-b4ac768a-b217-4b89-a04d-3b12f37aaa33-c000.snappy.parquet\n"}], "source": "%%sh\nhadoop fs -ls /tmp/delta-customers"}, {"cell_type": "code", "execution_count": 20, "id": "39eb07e9", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.sql(\"describe history customers\")"}, {"cell_type": "code", "execution_count": 21, "id": "2aa8844e", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>version</th>\n      <th>timestamp</th>\n      <th>userId</th>\n      <th>userName</th>\n      <th>operation</th>\n      <th>operationParameters</th>\n      <th>job</th>\n      <th>notebook</th>\n      <th>clusterId</th>\n      <th>readVersion</th>\n      <th>isolationLevel</th>\n      <th>isBlindAppend</th>\n      <th>operationMetrics</th>\n      <th>userMetadata</th>\n      <th>engineInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>2024-12-26 12:39:26.863</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WRITE</td>\n      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3.0</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{'numOutputRows': '15', 'numOutputBytes': '321...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>2024-12-26 12:39:20.851</td>\n      <td>None</td>\n      <td>None</td>\n      <td>DELETE</td>\n      <td>{'predicate': '[\"(spark_catalog.default.custom...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2.0</td>\n      <td>Serializable</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4424', 'numAddedFiles': '...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2024-12-26 12:39:01.160</td>\n      <td>None</td>\n      <td>None</td>\n      <td>UPDATE</td>\n      <td>{'predicate': '(cast(id#1555 as int) &lt; 50)'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1.0</td>\n      <td>Serializable</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4473', 'numAddedFiles': '...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2024-12-26 12:38:46.954</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WRITE</td>\n      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{'numOutputRows': '32', 'numOutputBytes': '447...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2024-12-26 12:38:35.984</td>\n      <td>None</td>\n      <td>None</td>\n      <td>CREATE TABLE</td>\n      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   version               timestamp userId userName     operation  \\\n0        4 2024-12-26 12:39:26.863   None     None         WRITE   \n1        3 2024-12-26 12:39:20.851   None     None        DELETE   \n2        2 2024-12-26 12:39:01.160   None     None        UPDATE   \n3        1 2024-12-26 12:38:46.954   None     None         WRITE   \n4        0 2024-12-26 12:38:35.984   None     None  CREATE TABLE   \n\n                                 operationParameters   job notebook clusterId  \\\n0            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n1  {'predicate': '[\"(spark_catalog.default.custom...  None     None      None   \n2       {'predicate': '(cast(id#1555 as int) < 50)'}  None     None      None   \n3            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n4  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n\n   readVersion isolationLevel  isBlindAppend  \\\n0          3.0   Serializable           True   \n1          2.0   Serializable          False   \n2          1.0   Serializable          False   \n3          0.0   Serializable           True   \n4          NaN   Serializable           True   \n\n                                    operationMetrics userMetadata  \\\n0  {'numOutputRows': '15', 'numOutputBytes': '321...         None   \n1  {'numRemovedBytes': '4424', 'numAddedFiles': '...         None   \n2  {'numRemovedBytes': '4473', 'numAddedFiles': '...         None   \n3  {'numOutputRows': '32', 'numOutputBytes': '447...         None   \n4                                                 {}         None   \n\n                            engineInfo  \n0  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n1  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n2  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n3  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n4  Apache-Spark/3.3.2 Delta-Lake/2.3.0  "}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "c815895f", "metadata": {}, "source": "Powy\u017csza kombinacja polece\u0144 `delete` oraz `insert` w prosty spos\u00f3b \nmo\u017ce zosta\u0107 zast\u0105piona poleceniem `merge`.\n\n### Zadanie 5\n\nKorzystaj\u0105c z jednego polecenia `merge` jednocze\u015bnie\n*   wstaw nowych klient\u00f3w, kt\u00f3rzy pojawili si\u0119 po raz pierwszy w lutym 2021\n*   zaktualizuj dane adresowe oraz `effectiveDate` tych klient\u00f3w, kt\u00f3rzy w tym samym czasie te dane zmienili. \n\nPoni\u017csze polecenie uzyskuje dane z obu grup klient\u00f3w:\n\n```python\nselect id, name, address, zipcode, city, country, effectiveDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate, \n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") >= date \"2021-02-01\"\n    and    to_date(effectiveDate,\"dd-MM-yyyy\") < date \"2021-03-01\"\n    )\nwhere version = 1\n```"}, {"cell_type": "markdown", "id": "752a1e41", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 5"}, {"cell_type": "code", "execution_count": 22, "id": "fe9d4db7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/26 12:39:41 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n24/12/26 12:39:41 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n24/12/26 12:39:41 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build left for full outer join.\n                                                                                \r"}, {"data": {"text/plain": "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\nMERGE INTO customers\nUSING (\n    SELECT id, name, address, zipcode, city, country, effectiveDate\n    FROM (\n        SELECT id, name, address, zipcode, city, country, effectiveDate, \n               RANK() OVER (PARTITION BY id ORDER BY to_date(effectiveDate, 'dd-MM-yyyy') DESC) AS version\n        FROM source_data\n        WHERE to_date(effectiveDate, 'dd-MM-yyyy') >= DATE '2021-02-01'\n          AND to_date(effectiveDate, 'dd-MM-yyyy') < DATE '2021-03-01'\n    ) AS subquery\n    WHERE version = 1\n) new_customers\nON customers.id = new_customers.id\nWHEN MATCHED THEN\n    UPDATE SET \n        customers.address = new_customers.address,\n        customers.zipcode = new_customers.zipcode, \n        customers.city = new_customers.city,\n        customers.country = new_customers.country,\n        customers.effectiveDate = new_customers.effectiveDate\nWHEN NOT MATCHED THEN\n    INSERT (id, name, address, zipcode, city, country, effectiveDate)\n    VALUES (new_customers.id, new_customers.name, new_customers.address, \n            new_customers.zipcode, new_customers.city, new_customers.country, new_customers.effectiveDate)\n\"\"\")\n"}, {"cell_type": "markdown", "id": "ee88bab5", "metadata": {}, "source": "Za pomoc\u0105 poni\u017cszego polecenia sprawd\u017a, z kt\u00f3rych miesi\u0119cy pochodz\u0105 dane naszych klient\u00f3w."}, {"cell_type": "code", "execution_count": 23, "id": "a70f3263", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"\"\"\nselect substr(effectiveDate,4,10) as month,\n       count(*) as how_many\nfrom customers\ngroup by substr(effectiveDate,4,10)\norder by to_date(substr(effectiveDate,4,10),\"MM-yyyy\")\"\"\")"}, {"cell_type": "code", "execution_count": 24, "id": "bba37065", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month</th>\n      <th>how_many</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10-2020</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11-2020</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12-2020</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01-2021</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>02-2021</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "     month  how_many\n0  10-2020         6\n1  11-2020        12\n2  12-2020         7\n3  01-2021        15\n4  02-2021         8"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "29f1588e", "metadata": {}, "source": "## Struktury plik\u00f3w, transakcje\n\nPrzed chwil\u0105 wykonali\u015bmy szereg operacji DML na naszej tabeli *customers*. \nKa\u017cda z nich, z jednej strony by\u0142a oddzieln\u0105 transakcj\u0105 zapisan\u0105 w logach Delta Lake, z drugiej strony ka\u017cda z nich dokona\u0142a pewnych zmian w plikach naszej tabeli.  \n\nZa pomoc\u0105 kilku kolejnych paragraf\u00f3w rozgl\u0105dniemy si\u0119 na pocz\u0105tku po strukturze plik\u00f3w, potem postaramy si\u0119 wydoby\u0107 informacje na temat naszych transakcji."}, {"cell_type": "code", "execution_count": 25, "id": "d32aa147", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# w kolumnie location znajdziesz katalog, w kt\u00f3rym nasza tabela jest przechowywana\ndf = spark.sql(\"describe detail customers\")"}, {"cell_type": "code", "execution_count": 26, "id": "5f1e2aa8", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>format</th>\n      <th>id</th>\n      <th>name</th>\n      <th>description</th>\n      <th>location</th>\n      <th>createdAt</th>\n      <th>lastModified</th>\n      <th>partitionColumns</th>\n      <th>numFiles</th>\n      <th>sizeInBytes</th>\n      <th>properties</th>\n      <th>minReaderVersion</th>\n      <th>minWriterVersion</th>\n      <th>tableFeatures</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>delta</td>\n      <td>a85775b1-c55e-40e4-8859-293d3394fda4</td>\n      <td>default.customers</td>\n      <td>None</td>\n      <td>hdfs://pbd-cluster-m/tmp/delta-customers</td>\n      <td>2024-12-26 12:38:35.873</td>\n      <td>2024-12-26 12:39:42.930</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>7749</td>\n      <td>{}</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[appendOnly, invariants]</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  format                                    id               name description  \\\n0  delta  a85775b1-c55e-40e4-8859-293d3394fda4  default.customers        None   \n\n                                   location               createdAt  \\\n0  hdfs://pbd-cluster-m/tmp/delta-customers 2024-12-26 12:38:35.873   \n\n             lastModified partitionColumns  numFiles  sizeInBytes properties  \\\n0 2024-12-26 12:39:42.930               []         2         7749         {}   \n\n   minReaderVersion  minWriterVersion             tableFeatures  \n0                 1                 2  [appendOnly, invariants]  "}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "d13d1e94-15de-4990-a9d4-4113a21f477e", "metadata": {"autoscroll": "auto"}, "source": "Sprawd\u017a ile plik\u00f3w znajduje si\u0119 w tym katalogu\n\nSprawd\u017a ile plik\u00f3w ma najstarsze daty - powsta\u0142o gdy po raz pierwszy za\u0142adowali\u015bmy do tabeli dane\n\nW tym celu wykonaj poni\u017csze polecenia:"}, {"cell_type": "code", "execution_count": 27, "id": "8860183a-04bb-4f93-bdcf-0d335a84c721", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 6 items\ndrwxr-xr-x   - root hadoop          0 2024-12-26 12:39 /tmp/delta-customers/_delta_log\n-rw-r--r--   2 root hadoop       4531 2024-12-26 12:39 /tmp/delta-customers/part-00000-26ab0244-e89a-4d09-b659-bcea157546f9-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       3218 2024-12-26 12:39 /tmp/delta-customers/part-00000-b4ac768a-b217-4b89-a04d-3b12f37aaa33-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       4433 2024-12-26 12:39 /tmp/delta-customers/part-00000-05b50041-aa6e-467e-bdf5-0cab105d90b3-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       4424 2024-12-26 12:39 /tmp/delta-customers/part-00000-39f5e085-51bb-4810-a751-12da3f5987ce-c000.snappy.parquet\n-rw-r--r--   2 root hadoop       4473 2024-12-26 12:38 /tmp/delta-customers/part-00000-8dfc8f44-04d4-4626-9e62-eee53aaa0b43-c000.snappy.parquet\n"}], "source": "%%sh \nhadoop fs -ls -t /tmp/delta-customers"}, {"cell_type": "code", "execution_count": 28, "id": "51215fa4", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"describe history customers\")"}, {"cell_type": "code", "execution_count": 29, "id": "2d4cf819", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>version</th>\n      <th>timestamp</th>\n      <th>userId</th>\n      <th>userName</th>\n      <th>operation</th>\n      <th>operationParameters</th>\n      <th>job</th>\n      <th>notebook</th>\n      <th>clusterId</th>\n      <th>readVersion</th>\n      <th>isolationLevel</th>\n      <th>isBlindAppend</th>\n      <th>operationMetrics</th>\n      <th>userMetadata</th>\n      <th>engineInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>2024-12-26 12:39:42.930</td>\n      <td>None</td>\n      <td>None</td>\n      <td>MERGE</td>\n      <td>{'matchedPredicates': '[{\"actionType\":\"update\"...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>4.0</td>\n      <td>Serializable</td>\n      <td>False</td>\n      <td>{'numOutputRows': '33', 'numTargetBytesAdded':...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>2024-12-26 12:39:26.863</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WRITE</td>\n      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3.0</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{'numOutputRows': '15', 'numOutputBytes': '321...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2024-12-26 12:39:20.851</td>\n      <td>None</td>\n      <td>None</td>\n      <td>DELETE</td>\n      <td>{'predicate': '[\"(spark_catalog.default.custom...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2.0</td>\n      <td>Serializable</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4424', 'numAddedFiles': '...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2024-12-26 12:39:01.160</td>\n      <td>None</td>\n      <td>None</td>\n      <td>UPDATE</td>\n      <td>{'predicate': '(cast(id#1555 as int) &lt; 50)'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1.0</td>\n      <td>Serializable</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4473', 'numAddedFiles': '...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2024-12-26 12:38:46.954</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WRITE</td>\n      <td>{'mode': 'Append', 'partitionBy': '[]'}</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{'numOutputRows': '32', 'numOutputBytes': '447...</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>2024-12-26 12:38:35.984</td>\n      <td>None</td>\n      <td>None</td>\n      <td>CREATE TABLE</td>\n      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>Serializable</td>\n      <td>True</td>\n      <td>{}</td>\n      <td>None</td>\n      <td>Apache-Spark/3.3.2 Delta-Lake/2.3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   version               timestamp userId userName     operation  \\\n0        5 2024-12-26 12:39:42.930   None     None         MERGE   \n1        4 2024-12-26 12:39:26.863   None     None         WRITE   \n2        3 2024-12-26 12:39:20.851   None     None        DELETE   \n3        2 2024-12-26 12:39:01.160   None     None        UPDATE   \n4        1 2024-12-26 12:38:46.954   None     None         WRITE   \n5        0 2024-12-26 12:38:35.984   None     None  CREATE TABLE   \n\n                                 operationParameters   job notebook clusterId  \\\n0  {'matchedPredicates': '[{\"actionType\":\"update\"...  None     None      None   \n1            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n2  {'predicate': '[\"(spark_catalog.default.custom...  None     None      None   \n3       {'predicate': '(cast(id#1555 as int) < 50)'}  None     None      None   \n4            {'mode': 'Append', 'partitionBy': '[]'}  None     None      None   \n5  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n\n   readVersion isolationLevel  isBlindAppend  \\\n0          4.0   Serializable          False   \n1          3.0   Serializable           True   \n2          2.0   Serializable          False   \n3          1.0   Serializable          False   \n4          0.0   Serializable           True   \n5          NaN   Serializable           True   \n\n                                    operationMetrics userMetadata  \\\n0  {'numOutputRows': '33', 'numTargetBytesAdded':...         None   \n1  {'numOutputRows': '15', 'numOutputBytes': '321...         None   \n2  {'numRemovedBytes': '4424', 'numAddedFiles': '...         None   \n3  {'numRemovedBytes': '4473', 'numAddedFiles': '...         None   \n4  {'numOutputRows': '32', 'numOutputBytes': '447...         None   \n5                                                 {}         None   \n\n                            engineInfo  \n0  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n1  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n2  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n3  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n4  Apache-Spark/3.3.2 Delta-Lake/2.3.0  \n5  Apache-Spark/3.3.2 Delta-Lake/2.3.0  "}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "code", "execution_count": 30, "id": "14bcfcf3", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from delta.tables import DeltaTable\n\n# Inicjalizacja \u015bcie\u017cki do tabeli Delta\ndelta_path = \"/tmp/delta-customers\"\ncust_delta_table = DeltaTable.forPath(spark, delta_path)\n\n# Pobranie pe\u0142nej historii tabeli Delta\nfull_hist_df = cust_delta_table.history().select(\n    \"version\", \"timestamp\", \"operation\", \"isBlindAppend\", \"operationMetrics\"\n)"}, {"cell_type": "code", "execution_count": 31, "id": "2989a050", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>version</th>\n      <th>timestamp</th>\n      <th>operation</th>\n      <th>isBlindAppend</th>\n      <th>operationMetrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>2024-12-26 12:39:42.930</td>\n      <td>MERGE</td>\n      <td>False</td>\n      <td>{'numOutputRows': '33', 'numTargetBytesAdded':...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>2024-12-26 12:39:26.863</td>\n      <td>WRITE</td>\n      <td>True</td>\n      <td>{'numOutputRows': '15', 'numOutputBytes': '321...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2024-12-26 12:39:20.851</td>\n      <td>DELETE</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4424', 'numAddedFiles': '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2024-12-26 12:39:01.160</td>\n      <td>UPDATE</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4473', 'numAddedFiles': '...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2024-12-26 12:38:46.954</td>\n      <td>WRITE</td>\n      <td>True</td>\n      <td>{'numOutputRows': '32', 'numOutputBytes': '447...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>2024-12-26 12:38:35.984</td>\n      <td>CREATE TABLE</td>\n      <td>True</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   version               timestamp     operation  isBlindAppend  \\\n0        5 2024-12-26 12:39:42.930         MERGE          False   \n1        4 2024-12-26 12:39:26.863         WRITE           True   \n2        3 2024-12-26 12:39:20.851        DELETE          False   \n3        2 2024-12-26 12:39:01.160        UPDATE          False   \n4        1 2024-12-26 12:38:46.954         WRITE           True   \n5        0 2024-12-26 12:38:35.984  CREATE TABLE           True   \n\n                                    operationMetrics  \n0  {'numOutputRows': '33', 'numTargetBytesAdded':...  \n1  {'numOutputRows': '15', 'numOutputBytes': '321...  \n2  {'numRemovedBytes': '4424', 'numAddedFiles': '...  \n3  {'numRemovedBytes': '4473', 'numAddedFiles': '...  \n4  {'numOutputRows': '32', 'numOutputBytes': '447...  \n5                                                 {}  "}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": "full_hist_df.toPandas()"}, {"cell_type": "markdown", "id": "2b257d27", "metadata": {}, "source": "**Kilka pyta\u0144**\n\nZwr\u00f3\u0107 uwag\u0119, \u017ce niekt\u00f3re z tych operacji maj\u0105 flag\u0119 `isBlindAppend` zapalon\u0105. **Kt\u00f3re to by\u0142y operacje?**\n\nKa\u017cda zmiana - polecenia: `update`, `delete` czy `merge` \"usuwa\u0142a\" du\u017c\u0105 cz\u0119\u015b\u0107 (by\u0107 mo\u017ce nawet wszystkie) aktywnych plik\u00f3w zast\u0119puj\u0105c je nowymi. \n\nCo mog\u0142oby spowodowa\u0107, \u017ce liczba zast\u0119powanych plik\u00f3w nie obejmowa\u0142aby wszystkich aktywnych plik\u00f3w?"}, {"cell_type": "markdown", "id": "78ed7d85", "metadata": {"tags": []}, "source": "# Podr\u00f3\u017c w czasie\n\nDelta Lake to nie tylko wydajna obs\u0142uga (i mo\u017cliwo\u015b\u0107 wykonania) operacji DML, \nto tak\u017ce \u0142atwo\u015b\u0107 w odzyskiwaniu zniszczonych danych.\n\n## Podstawy - czas i numery wersji\n\nNa pocz\u0105tku troch\u0119 podstaw. \n\nSprawd\u017a czas wykonania Twojej operacji `update`, kt\u00f3ra zmieni\u0142a kraj niekt\u00f3rym klientom na `Poland`."}, {"cell_type": "code", "execution_count": 32, "id": "d5dafc95", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from delta.tables import DeltaTable\nfrom pyspark.sql import functions as F\n\n# Inicjalizacja \u015bcie\u017cki do tabeli Delta\ndelta_path = \"/tmp/delta-customers\"\ndelta_table = DeltaTable.forPath(spark, delta_path)\n\n# Pobranie historii operacji UPDATE\nhistory = delta_table.history().where(F.col(\"operation\") == \"UPDATE\").select(\"timestamp\", \"version\")"}, {"cell_type": "code", "execution_count": 33, "id": "93282779", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>version</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-12-26 12:39:01.160</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                timestamp  version\n0 2024-12-26 12:39:01.160        2"}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": "history.toPandas()"}, {"cell_type": "markdown", "id": "90b2f00d", "metadata": {}, "source": "Skorzystaj teraz z tej daty, aby w poni\u017cszym paragrafie uzyska\u0107 dane jakie obowi\u0105zywa\u0142y przed t\u0105 dat\u0105. "}, {"cell_type": "code", "execution_count": 34, "id": "70c3790a", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "timestamp_value = history.orderBy(F.col(\"timestamp\").desc()).first()[\"timestamp\"]\n\ndf = (\n    spark.read\n    .format(\"delta\")\n    .option(\"timestampAsOf\", timestamp_value)\n    .load(\"/tmp/delta-customers\")\n    .where(col(\"country\").like(\"P%\"))\n)"}, {"cell_type": "code", "execution_count": 35, "id": "a0ac6319", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>Jin Terry</td>\n      <td>467-8297 Enim</td>\n      <td>35633573</td>\n      <td>Bal\u0131kesir</td>\n      <td>Poland</td>\n      <td>06-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>Isabelle Stevenson</td>\n      <td>131-4245 Eleifend. Street</td>\n      <td>16142</td>\n      <td>H\u00e0 Giang</td>\n      <td>Poland</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>Leo Mcleod</td>\n      <td>467-8297 Enim</td>\n      <td>39153</td>\n      <td>Bor\u00e5s</td>\n      <td>Poland</td>\n      <td>16-10-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>Kaitlin Landry</td>\n      <td>623-5682 Augue St.</td>\n      <td>351225</td>\n      <td>Libramont-Chevigny</td>\n      <td>Poland</td>\n      <td>29-10-2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19</td>\n      <td>Alden Harper</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>94671-72608</td>\n      <td>Ch\u00e2tellerault</td>\n      <td>Poland</td>\n      <td>06-12-2020</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>Brandon Christian</td>\n      <td>476-5064 Suspendisse Rd.</td>\n      <td>93-765</td>\n      <td>Broxburn</td>\n      <td>Poland</td>\n      <td>28-11-2020</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Poland</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>26</td>\n      <td>Ulysses Dillard</td>\n      <td>1318 Tempor Rd.</td>\n      <td>S5J 6Z2</td>\n      <td>Tuscaloosa</td>\n      <td>Poland</td>\n      <td>11-10-2020</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>33</td>\n      <td>Alexander Becker</td>\n      <td>Ap #631-7469 Curae St.</td>\n      <td>29941</td>\n      <td>Anseong</td>\n      <td>Poland</td>\n      <td>04-11-2020</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4</td>\n      <td>Hall Mayer</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>23072</td>\n      <td>Vetlanda</td>\n      <td>Poland</td>\n      <td>13-11-2020</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>41</td>\n      <td>Plato Vaughan</td>\n      <td>Ap #502-453 Non Rd.</td>\n      <td>06255-18554</td>\n      <td>Zoerle-Parwijs</td>\n      <td>Poland</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>42</td>\n      <td>Steel Ruiz</td>\n      <td>747-9558 Dignissim Ave</td>\n      <td>7550</td>\n      <td>Fallo</td>\n      <td>Poland</td>\n      <td>18-11-2020</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>49</td>\n      <td>Porter Morrison</td>\n      <td>9797 Ultrices Av.</td>\n      <td>G4K 6J6</td>\n      <td>Serang</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5</td>\n      <td>Sonia Shepherd</td>\n      <td>467-8297 Enim</td>\n      <td>7077 VL</td>\n      <td>Tregaron</td>\n      <td>Poland</td>\n      <td>31-12-2020</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8</td>\n      <td>Genevieve Leonard</td>\n      <td>776-6460 Nibh. Rd.</td>\n      <td>36007</td>\n      <td>Port Lincoln</td>\n      <td>Poland</td>\n      <td>28-12-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    id                name                    address      zipcode  \\\n0   10           Jin Terry              467-8297 Enim     35633573   \n1   11  Isabelle Stevenson  131-4245 Eleifend. Street        16142   \n2   14          Leo Mcleod              467-8297 Enim        39153   \n3   16      Kaitlin Landry         623-5682 Augue St.       351225   \n4   19        Alden Harper    Ap #579-2185 Sed Street  94671-72608   \n5    2   Brandon Christian   476-5064 Suspendisse Rd.       93-765   \n6   20       Kathleen Pugh              7018 Cras St.         3123   \n7   26     Ulysses Dillard            1318 Tempor Rd.      S5J 6Z2   \n8   28      Shaine Puckett    Ap #579-2185 Sed Street        85629   \n9   33    Alexander Becker     Ap #631-7469 Curae St.        29941   \n10   4          Hall Mayer    Ap #579-2185 Sed Street        23072   \n11  41       Plato Vaughan        Ap #502-453 Non Rd.  06255-18554   \n12  42          Steel Ruiz     747-9558 Dignissim Ave         7550   \n13  49     Porter Morrison          9797 Ultrices Av.      G4K 6J6   \n14   5      Sonia Shepherd              467-8297 Enim      7077 VL   \n15  68      Clarke Carlson        2296 Vestibulum St.       163826   \n16  74        Vernon Casey         650-5308 Felis Rd.        42987   \n17   8   Genevieve Leonard         776-6460 Nibh. Rd.        36007   \n\n                       city   country effectiveDate  \n0                 Bal\u0131kesir    Poland    06-11-2020  \n1                  H\u00e0 Giang    Poland    25-11-2020  \n2                     Bor\u00e5s    Poland    16-10-2020  \n3        Libramont-Chevigny    Poland    29-10-2020  \n4             Ch\u00e2tellerault    Poland    06-12-2020  \n5                  Broxburn    Poland    28-11-2020  \n6   Ostrowiec \u015awi\u0119tokrzyski    Poland    16-11-2020  \n7                Tuscaloosa    Poland    11-10-2020  \n8                  Cochrane    Poland    07-12-2020  \n9                   Anseong    Poland    04-11-2020  \n10                 Vetlanda    Poland    13-11-2020  \n11           Zoerle-Parwijs    Poland    25-11-2020  \n12                    Fallo    Poland    18-11-2020  \n13                   Serang    Poland    07-12-2020  \n14                 Tregaron    Poland    31-12-2020  \n15               Logan City    Poland    28-10-2020  \n16                   Mirpur  Pakistan    14-11-2020  \n17             Port Lincoln    Poland    28-12-2020  "}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "code", "execution_count": 36, "id": "cedc9ef8", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "version_value = history.orderBy(F.col(\"version\").desc()).first()[\"version\"] - 1\n\ndf = (\n    spark.read\n    .format(\"delta\")\n    .option(\"versionAsOf\", version_value)\n    .load(\"/tmp/delta-customers\")\n    .where(col(\"country\").like(\"P%\"))\n)"}, {"cell_type": "code", "execution_count": 37, "id": "581e3bf1", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Peru</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   id            name                  address zipcode  \\\n0  20   Kathleen Pugh            7018 Cras St.    3123   \n1  28  Shaine Puckett  Ap #579-2185 Sed Street   85629   \n2  68  Clarke Carlson      2296 Vestibulum St.  163826   \n3  74    Vernon Casey       650-5308 Felis Rd.   42987   \n\n                      city   country effectiveDate  \n0  Ostrowiec \u015awi\u0119tokrzyski      Peru    16-11-2020  \n1                 Cochrane    Poland    07-12-2020  \n2               Logan City    Poland    28-10-2020  \n3                   Mirpur  Pakistan    14-11-2020  "}, "execution_count": 37, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "d5f17805", "metadata": {}, "source": "Skorzystaj z tej daty ponownie w poni\u017cszym paragrafie, \naby tym razem uzyska\u0107 dane jakie obowi\u0105zywa\u0142y po modyfikacji."}, {"cell_type": "code", "execution_count": 38, "id": "a55c81da", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = (\n    spark.read\n    .format(\"delta\")\n    .option(\"timestampAsOf\", timestamp_value)\n    .load(\"/tmp/delta-customers\")\n    .where(col(\"country\").like(\"P%\"))\n)"}, {"cell_type": "code", "execution_count": 39, "id": "56e3f088", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>Jin Terry</td>\n      <td>467-8297 Enim</td>\n      <td>35633573</td>\n      <td>Bal\u0131kesir</td>\n      <td>Poland</td>\n      <td>06-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>Isabelle Stevenson</td>\n      <td>131-4245 Eleifend. Street</td>\n      <td>16142</td>\n      <td>H\u00e0 Giang</td>\n      <td>Poland</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>Leo Mcleod</td>\n      <td>467-8297 Enim</td>\n      <td>39153</td>\n      <td>Bor\u00e5s</td>\n      <td>Poland</td>\n      <td>16-10-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>Kaitlin Landry</td>\n      <td>623-5682 Augue St.</td>\n      <td>351225</td>\n      <td>Libramont-Chevigny</td>\n      <td>Poland</td>\n      <td>29-10-2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19</td>\n      <td>Alden Harper</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>94671-72608</td>\n      <td>Ch\u00e2tellerault</td>\n      <td>Poland</td>\n      <td>06-12-2020</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>Brandon Christian</td>\n      <td>476-5064 Suspendisse Rd.</td>\n      <td>93-765</td>\n      <td>Broxburn</td>\n      <td>Poland</td>\n      <td>28-11-2020</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Poland</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>26</td>\n      <td>Ulysses Dillard</td>\n      <td>1318 Tempor Rd.</td>\n      <td>S5J 6Z2</td>\n      <td>Tuscaloosa</td>\n      <td>Poland</td>\n      <td>11-10-2020</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>33</td>\n      <td>Alexander Becker</td>\n      <td>Ap #631-7469 Curae St.</td>\n      <td>29941</td>\n      <td>Anseong</td>\n      <td>Poland</td>\n      <td>04-11-2020</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4</td>\n      <td>Hall Mayer</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>23072</td>\n      <td>Vetlanda</td>\n      <td>Poland</td>\n      <td>13-11-2020</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>41</td>\n      <td>Plato Vaughan</td>\n      <td>Ap #502-453 Non Rd.</td>\n      <td>06255-18554</td>\n      <td>Zoerle-Parwijs</td>\n      <td>Poland</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>42</td>\n      <td>Steel Ruiz</td>\n      <td>747-9558 Dignissim Ave</td>\n      <td>7550</td>\n      <td>Fallo</td>\n      <td>Poland</td>\n      <td>18-11-2020</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>49</td>\n      <td>Porter Morrison</td>\n      <td>9797 Ultrices Av.</td>\n      <td>G4K 6J6</td>\n      <td>Serang</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5</td>\n      <td>Sonia Shepherd</td>\n      <td>467-8297 Enim</td>\n      <td>7077 VL</td>\n      <td>Tregaron</td>\n      <td>Poland</td>\n      <td>31-12-2020</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8</td>\n      <td>Genevieve Leonard</td>\n      <td>776-6460 Nibh. Rd.</td>\n      <td>36007</td>\n      <td>Port Lincoln</td>\n      <td>Poland</td>\n      <td>28-12-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    id                name                    address      zipcode  \\\n0   10           Jin Terry              467-8297 Enim     35633573   \n1   11  Isabelle Stevenson  131-4245 Eleifend. Street        16142   \n2   14          Leo Mcleod              467-8297 Enim        39153   \n3   16      Kaitlin Landry         623-5682 Augue St.       351225   \n4   19        Alden Harper    Ap #579-2185 Sed Street  94671-72608   \n5    2   Brandon Christian   476-5064 Suspendisse Rd.       93-765   \n6   20       Kathleen Pugh              7018 Cras St.         3123   \n7   26     Ulysses Dillard            1318 Tempor Rd.      S5J 6Z2   \n8   28      Shaine Puckett    Ap #579-2185 Sed Street        85629   \n9   33    Alexander Becker     Ap #631-7469 Curae St.        29941   \n10   4          Hall Mayer    Ap #579-2185 Sed Street        23072   \n11  41       Plato Vaughan        Ap #502-453 Non Rd.  06255-18554   \n12  42          Steel Ruiz     747-9558 Dignissim Ave         7550   \n13  49     Porter Morrison          9797 Ultrices Av.      G4K 6J6   \n14   5      Sonia Shepherd              467-8297 Enim      7077 VL   \n15  68      Clarke Carlson        2296 Vestibulum St.       163826   \n16  74        Vernon Casey         650-5308 Felis Rd.        42987   \n17   8   Genevieve Leonard         776-6460 Nibh. Rd.        36007   \n\n                       city   country effectiveDate  \n0                 Bal\u0131kesir    Poland    06-11-2020  \n1                  H\u00e0 Giang    Poland    25-11-2020  \n2                     Bor\u00e5s    Poland    16-10-2020  \n3        Libramont-Chevigny    Poland    29-10-2020  \n4             Ch\u00e2tellerault    Poland    06-12-2020  \n5                  Broxburn    Poland    28-11-2020  \n6   Ostrowiec \u015awi\u0119tokrzyski    Poland    16-11-2020  \n7                Tuscaloosa    Poland    11-10-2020  \n8                  Cochrane    Poland    07-12-2020  \n9                   Anseong    Poland    04-11-2020  \n10                 Vetlanda    Poland    13-11-2020  \n11           Zoerle-Parwijs    Poland    25-11-2020  \n12                    Fallo    Poland    18-11-2020  \n13                   Serang    Poland    07-12-2020  \n14                 Tregaron    Poland    31-12-2020  \n15               Logan City    Poland    28-10-2020  \n16                   Mirpur  Pakistan    14-11-2020  \n17             Port Lincoln    Poland    28-12-2020  "}, "execution_count": 39, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "code", "execution_count": 40, "id": "ab1de85d", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = (\n    spark.read\n    .format(\"delta\")\n    .option(\"versionAsOf\", version_value)\n    .load(\"/tmp/delta-customers\")\n    .where(col(\"country\").like(\"P%\"))\n)"}, {"cell_type": "code", "execution_count": 41, "id": "ca3c3249", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Peru</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   id            name                  address zipcode  \\\n0  20   Kathleen Pugh            7018 Cras St.    3123   \n1  28  Shaine Puckett  Ap #579-2185 Sed Street   85629   \n2  68  Clarke Carlson      2296 Vestibulum St.  163826   \n3  74    Vernon Casey       650-5308 Felis Rd.   42987   \n\n                      city   country effectiveDate  \n0  Ostrowiec \u015awi\u0119tokrzyski      Peru    16-11-2020  \n1                 Cochrane    Poland    07-12-2020  \n2               Logan City    Poland    28-10-2020  \n3                   Mirpur  Pakistan    14-11-2020  "}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "0be2eb45", "metadata": {}, "source": "## Rollback\n\n### Zadanie 6\n\nWyobra\u017a sobie, \u017ce ta operacja zmiany kraju na warto\u015b\u0107 `Poland` okaza\u0142a si\u0119 by\u0107 b\u0142\u0119dna. \nTwoim zadaniem jest przywr\u00f3ci\u0107 warto\u015bci, kt\u00f3re zosta\u0142y nadpisane przez t\u0105 modifikacj\u0119. \nNie naprawiaj danych je\u015bli pojawi\u0142y si\u0119 p\u00f3\u017aniejsze (po Twoim poleceniu `update`) aktualizacje adresu (skorzystaj z `effectiveDate`).\n\u015awietnie do takiej naprawy mo\u017ce si\u0119 przyda\u0107 operacja `merge`. Tym razem b\u0119dzie ona mia\u0142a tylko sekcj\u0119 `WHEN MATCHED THEN`.\n\nOczywi\u015bcie nie korzystaj z danych \u017ar\u00f3d\u0142owych - ich ju\u017c nie ma. Jest tylko Twoja tabela Delta Lake. \n\nSkorzystaj z DataFrame API."}, {"cell_type": "code", "execution_count": 42, "id": "d3d009ec", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# b\u0142\u0119dne dane nie tylko s\u0105 w historii, one s\u0105 nadal w bie\u017c\u0105cej postaci naszych danych\ndf = spark.sql(\"\"\"\nselect * \nfrom customers \nwhere country like 'P%' \n  and to_date(effectiveDate,'dd-MM-yyyy') < date '2021-01-01'\"\"\")"}, {"cell_type": "code", "execution_count": 43, "id": "7aae60de", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>Jin Terry</td>\n      <td>467-8297 Enim</td>\n      <td>35633573</td>\n      <td>Bal\u0131kesir</td>\n      <td>Poland</td>\n      <td>06-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>Isabelle Stevenson</td>\n      <td>131-4245 Eleifend. Street</td>\n      <td>16142</td>\n      <td>H\u00e0 Giang</td>\n      <td>Poland</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>Kaitlin Landry</td>\n      <td>623-5682 Augue St.</td>\n      <td>351225</td>\n      <td>Libramont-Chevigny</td>\n      <td>Poland</td>\n      <td>29-10-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19</td>\n      <td>Alden Harper</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>94671-72608</td>\n      <td>Ch\u00e2tellerault</td>\n      <td>Poland</td>\n      <td>06-12-2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Brandon Christian</td>\n      <td>476-5064 Suspendisse Rd.</td>\n      <td>93-765</td>\n      <td>Broxburn</td>\n      <td>Poland</td>\n      <td>28-11-2020</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Poland</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>26</td>\n      <td>Ulysses Dillard</td>\n      <td>1318 Tempor Rd.</td>\n      <td>S5J 6Z2</td>\n      <td>Tuscaloosa</td>\n      <td>Poland</td>\n      <td>11-10-2020</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>33</td>\n      <td>Alexander Becker</td>\n      <td>Ap #631-7469 Curae St.</td>\n      <td>29941</td>\n      <td>Anseong</td>\n      <td>Poland</td>\n      <td>04-11-2020</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>Plato Vaughan</td>\n      <td>Ap #502-453 Non Rd.</td>\n      <td>06255-18554</td>\n      <td>Zoerle-Parwijs</td>\n      <td>Poland</td>\n      <td>25-11-2020</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>42</td>\n      <td>Steel Ruiz</td>\n      <td>747-9558 Dignissim Ave</td>\n      <td>7550</td>\n      <td>Fallo</td>\n      <td>Poland</td>\n      <td>18-11-2020</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5</td>\n      <td>Sonia Shepherd</td>\n      <td>467-8297 Enim</td>\n      <td>7077 VL</td>\n      <td>Tregaron</td>\n      <td>Poland</td>\n      <td>31-12-2020</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    id                name                    address      zipcode  \\\n0   10           Jin Terry              467-8297 Enim     35633573   \n1   11  Isabelle Stevenson  131-4245 Eleifend. Street        16142   \n2   16      Kaitlin Landry         623-5682 Augue St.       351225   \n3   19        Alden Harper    Ap #579-2185 Sed Street  94671-72608   \n4    2   Brandon Christian   476-5064 Suspendisse Rd.       93-765   \n5   20       Kathleen Pugh              7018 Cras St.         3123   \n6   26     Ulysses Dillard            1318 Tempor Rd.      S5J 6Z2   \n7   28      Shaine Puckett    Ap #579-2185 Sed Street        85629   \n8   33    Alexander Becker     Ap #631-7469 Curae St.        29941   \n9   41       Plato Vaughan        Ap #502-453 Non Rd.  06255-18554   \n10  42          Steel Ruiz     747-9558 Dignissim Ave         7550   \n11   5      Sonia Shepherd              467-8297 Enim      7077 VL   \n12  68      Clarke Carlson        2296 Vestibulum St.       163826   \n13  74        Vernon Casey         650-5308 Felis Rd.        42987   \n\n                       city   country effectiveDate  \n0                 Bal\u0131kesir    Poland    06-11-2020  \n1                  H\u00e0 Giang    Poland    25-11-2020  \n2        Libramont-Chevigny    Poland    29-10-2020  \n3             Ch\u00e2tellerault    Poland    06-12-2020  \n4                  Broxburn    Poland    28-11-2020  \n5   Ostrowiec \u015awi\u0119tokrzyski    Poland    16-11-2020  \n6                Tuscaloosa    Poland    11-10-2020  \n7                  Cochrane    Poland    07-12-2020  \n8                   Anseong    Poland    04-11-2020  \n9            Zoerle-Parwijs    Poland    25-11-2020  \n10                    Fallo    Poland    18-11-2020  \n11                 Tregaron    Poland    31-12-2020  \n12               Logan City    Poland    28-10-2020  \n13                   Mirpur  Pakistan    14-11-2020  "}, "execution_count": 43, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "d88b007e", "metadata": {}, "source": "### Rozwi\u0105zanie zadania 6"}, {"cell_type": "code", "execution_count": 44, "id": "a238225b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from delta.tables import DeltaTable\n\n# Inicjalizacja \u015bcie\u017cki do tabeli Delta\ndelta_path = \"/tmp/delta-customers\"\ndelta_table = DeltaTable.forPath(spark, delta_path)\n\n# Wczytanie poprawnych danych z tabeli Delta na podstawie numeru wersji\npoprawne_df = (\n    spark.read\n    .format(\"delta\")\n    .option(\"versionAsOf\", version_value)\n    .load(delta_path)\n)\n\n# Wykonanie operacji MERGE na tabeli Delta\ndelta_table.alias(\"old\") \\\n    .merge(\n        poprawne_df.alias(\"new\"), \n        \"old.id = new.id and to_date(old.effectiveDate,'dd-MM-yyyy') < date '2021-01-01'\"\n    ) \\\n    .whenMatchedUpdate(\n        set={\"country\": \"new.country\"}\n    ) \\\n    .execute()"}, {"cell_type": "markdown", "id": "5cf3f09f", "metadata": {}, "source": "Sprawd\u017a czy operacja przywracania poprzedniej wersji danych si\u0119 powiod\u0142a. "}, {"cell_type": "code", "execution_count": 45, "id": "70be52bd", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# b\u0142\u0119dne dane nie tylko s\u0105 w historii, one s\u0105 nadal w bie\u017c\u0105cej postaci naszych danych\ndf = spark.sql(\"\"\"\nselect * \nfrom customers \nwhere country like 'P%' \n  and to_date(effectiveDate,'dd-MM-yyyy') < date '2021-01-01'\"\"\")"}, {"cell_type": "code", "execution_count": 46, "id": "1ed430f0", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>Kathleen Pugh</td>\n      <td>7018 Cras St.</td>\n      <td>3123</td>\n      <td>Ostrowiec \u015awi\u0119tokrzyski</td>\n      <td>Peru</td>\n      <td>16-11-2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>Shaine Puckett</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>85629</td>\n      <td>Cochrane</td>\n      <td>Poland</td>\n      <td>07-12-2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>68</td>\n      <td>Clarke Carlson</td>\n      <td>2296 Vestibulum St.</td>\n      <td>163826</td>\n      <td>Logan City</td>\n      <td>Poland</td>\n      <td>28-10-2020</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>74</td>\n      <td>Vernon Casey</td>\n      <td>650-5308 Felis Rd.</td>\n      <td>42987</td>\n      <td>Mirpur</td>\n      <td>Pakistan</td>\n      <td>14-11-2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   id            name                  address zipcode  \\\n0  20   Kathleen Pugh            7018 Cras St.    3123   \n1  28  Shaine Puckett  Ap #579-2185 Sed Street   85629   \n2  68  Clarke Carlson      2296 Vestibulum St.  163826   \n3  74    Vernon Casey       650-5308 Felis Rd.   42987   \n\n                      city   country effectiveDate  \n0  Ostrowiec \u015awi\u0119tokrzyski      Peru    16-11-2020  \n1                 Cochrane    Poland    07-12-2020  \n2               Logan City    Poland    28-10-2020  \n3                   Mirpur  Pakistan    14-11-2020  "}, "execution_count": 46, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "4205a289", "metadata": {}, "source": "Oczywi\u015bcie nale\u017cy pami\u0119ta\u0107, \u017ce powy\u017csza funkcjonalno\u015b\u0107 to nie podr\u00f3\u017c w czasie w dowolnym zakresie. \n\nNieaktualne pliki s\u0105 sukcesywnie usuwane. \n\nNiemniej, prosta mo\u017cliwo\u015b\u0107 naprawy pope\u0142nionego w\u0142a\u015bnie przed chwil\u0105 b\u0142\u0119du jest nieoceniona w \u015bwiecie Big Data. To dlatego \u015bwiat Big Data z zasady nie pozwala niczego modyfikowa\u0107, a tworzy jedynie nowe na podstawie starego. W przypadku problem\u00f3w stare, mo\u017ce zosta\u0107 wykorzystane. \n\nDok\u0142adnie to dzieje si\u0119 pod mask\u0105 w Delta Lake."}, {"cell_type": "markdown", "id": "684b9c37", "metadata": {}, "source": "# Zmiany schematu\n\nZmiana zawarto\u015bci danych to jedno. Ale \u015bwiat zmienia si\u0119 znacznie bardziej. Wymaga to cz\u0119sto zmian definicji struktur naszych danych. \n\nPrzyk\u0142adowo, nasz atrybut `effectiveDate` jest ci\u0105giem znak\u00f3w, ale od dzi\u015b dobrze aby by\u0142 dat\u0105. \nTo samo dotyczy `id`. Od teraz wolimy, aby by\u0142 liczb\u0105. \n\nTabele Delta Lake s\u0105 przygotowane na takie modyfikacje. Wynika to poniek\u0105d z formatu plik\u00f3w jaki jest wykorzystywany pod spodem. "}, {"cell_type": "markdown", "id": "37da3d89", "metadata": {}, "source": "## Walidacja schematu \n\nPo pierwsze, Delta Lake dokonuje walidacji danych podczas wstawiania nowych danych. "}, {"cell_type": "code", "execution_count": 47, "id": "1f5ca242", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# przed zmianami\ndf = spark.sql(\"describe customers\")"}, {"cell_type": "code", "execution_count": 48, "id": "d6babef1", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_name</th>\n      <th>data_type</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>name</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>address</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>zipcode</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>city</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>country</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>effectiveDate</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td># Partitioning</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Not partitioned</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "          col_name data_type comment\n0               id    string        \n1             name    string        \n2          address    string        \n3          zipcode    string        \n4             city    string        \n5          country    string        \n6    effectiveDate    string        \n7                                   \n8   # Partitioning                  \n9  Not partitioned                  "}, "execution_count": 48, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "61e48ee8", "metadata": {}, "source": "Spr\u00f3buj wstawi\u0107 dane z marca 2021, uzupe\u0142nione o dodatkow\u0105 kolumn\u0119 `endDate`.\n```python\nselect id, \n       name, address, zipcode, city, country, \n       effectiveDate, \n       cast(null as date) as endDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate,\n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") >= date \"2021-03-01\"\n    and    to_date(effectiveDate,\"dd-MM-yyyy\") < date \"2021-04-01\"\n    )\nwhere version = 1\n```"}, {"cell_type": "code", "execution_count": 49, "id": "7f014589", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\nINSERT INTO customers\nselect id, \n       name, address, zipcode, city, country, \n       effectiveDate, \n       cast(null as date) as endDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate,\n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") >= date \"2021-03-01\"\n    and    to_date(effectiveDate,\"dd-MM-yyyy\") < date \"2021-04-01\"\n    )\nwhere version = 1\"\"\")"}, {"cell_type": "markdown", "id": "472ac5e4", "metadata": {}, "source": "Dzi\u0119ki parametrowi `spark.databricks.delta.schema.autoMerge.enabled=true` dosz\u0142o do automatycznej integracji schematu docelowej tabeli z postaci\u0105 danych, kt\u00f3re by\u0142y do niej wstawiane. \n\nKolumna `endDate` jest nam potrzebna i b\u0119dzie wykorzystywana w nast\u0119pnym zadaniu. \n\nW wersjach Delta Lake 2.2 i wcze\u015bniejszych nale\u017ca\u0142o wykorzysta\u0107 poni\u017csze rozwi\u0105zanie do uzyskania takiej integracji\n\n```python\n# Wyb\u00f3r danych z okresu od '2021-03-01' do '2021-04-01'\ndata_032021 = (\n    source_data\n    .filter((to_date(\"effectiveDate\", \"dd-MM-yyyy\") >= '2021-03-01') & (to_date(\"effectiveDate\", \"dd-MM-yyyy\") < '2021-04-01'))\n    .withColumn(\"version\", row_number().over(Window.partitionBy(\"id\").orderBy(col(\"effectiveDate\").desc())))\n    .filter(\"version = 1\")\n    .withColumn(\"endDate\", lit(None).cast(\"date\"))\n    .select(\"id\", \"name\", \"address\", \"zipcode\", \"city\", \"country\", \"effectiveDate\", \"endDate\")\n)\n\n# Zapis danych do tabeli Delta\ndata_032021.write.option(\"mergeSchema\", \"true\").format(\"delta\").mode(\"append\").saveAsTable(\"customers\")\n```\n"}, {"cell_type": "markdown", "id": "e6af096d", "metadata": {"autoscroll": "auto"}, "source": "Sprawd\u017a jak wygl\u0105da schemat Twojej tabeli po zmianach "}, {"cell_type": "code", "execution_count": 50, "id": "fc232a0d", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"describe customers\")"}, {"cell_type": "code", "execution_count": 51, "id": "8ecd2fed", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_name</th>\n      <th>data_type</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>name</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>address</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>zipcode</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>city</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>country</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>effectiveDate</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>endDate</td>\n      <td>date</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td># Partitioning</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Not partitioned</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "           col_name data_type comment\n0                id    string        \n1              name    string        \n2           address    string        \n3           zipcode    string        \n4              city    string        \n5           country    string        \n6     effectiveDate    string        \n7           endDate      date        \n8                                    \n9    # Partitioning                  \n10  Not partitioned                  "}, "execution_count": 51, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "43e1057f", "metadata": {}, "source": " \nNiekt\u00f3re zmiany schematu wymagaj\u0105 nadpisania ca\u0142ej zawarto\u015bci tabeli \n\n`.mode(\"overwrite\").option(\"overwriteSchema\", \"true\")`. \n\n\u0179r\u00f3d\u0142em danych mo\u017ce by\u0107 oczywi\u015bcie ta sama tabela, w tym r\u00f3wnie\u017c jej poprzednia wersja."}, {"cell_type": "markdown", "id": "6abd55b5", "metadata": {}, "source": "## Zadanie 7\n\nKorzystaj\u0105c z tego mechanizmu zmie\u0144 typy kolumn, o kt\u00f3rych wspominali\u015bmy.\nPrzy okazji wycofaj ostatni\u0105 aktualizacj\u0119. Nie by\u0142a przemy\u015blana - dodali\u015bmy nowe dane (`append`) a powinni\u015bmy uwzgl\u0119dni\u0107 fakt, \u017ce nie wszyscy klienci w nowym zestawie danych byli nowi, cz\u0119\u015b\u0107 z nich wymaga\u0142a aktualizacji. W rezultacie pojawi\u0142y si\u0119 duplikaty w naszych danych. \n\nSprawd\u017a, kt\u00f3rej wersji danych potrzebujesz."}, {"cell_type": "code", "execution_count": 52, "id": "8fb2b585", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from delta.tables import DeltaTable\n\n# Inicjalizacja \u015bcie\u017cki do tabeli Delta\ndelta_path = \"/tmp/delta-customers\"\ncust_delta_table = DeltaTable.forPath(spark, delta_path)\n\n# Pobranie pe\u0142nej historii tabeli Delta\nfull_hist_df = cust_delta_table.history().select(\n    \"version\", \"timestamp\", \"operation\", \"isBlindAppend\", \"operationMetrics\"\n)"}, {"cell_type": "code", "execution_count": 53, "id": "1c0772d5", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>version</th>\n      <th>timestamp</th>\n      <th>operation</th>\n      <th>isBlindAppend</th>\n      <th>operationMetrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>2024-12-26 12:40:29.086</td>\n      <td>WRITE</td>\n      <td>True</td>\n      <td>{'numOutputRows': '15', 'numOutputBytes': '343...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>2024-12-26 12:40:22.596</td>\n      <td>MERGE</td>\n      <td>False</td>\n      <td>{'numOutputRows': '33', 'numTargetBytesAdded':...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>2024-12-26 12:39:42.930</td>\n      <td>MERGE</td>\n      <td>False</td>\n      <td>{'numOutputRows': '33', 'numTargetBytesAdded':...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2024-12-26 12:39:26.863</td>\n      <td>WRITE</td>\n      <td>True</td>\n      <td>{'numOutputRows': '15', 'numOutputBytes': '321...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>2024-12-26 12:39:20.851</td>\n      <td>DELETE</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4424', 'numAddedFiles': '...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>2024-12-26 12:39:01.160</td>\n      <td>UPDATE</td>\n      <td>False</td>\n      <td>{'numRemovedBytes': '4473', 'numAddedFiles': '...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>2024-12-26 12:38:46.954</td>\n      <td>WRITE</td>\n      <td>True</td>\n      <td>{'numOutputRows': '32', 'numOutputBytes': '447...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>2024-12-26 12:38:35.984</td>\n      <td>CREATE TABLE</td>\n      <td>True</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   version               timestamp     operation  isBlindAppend  \\\n0        7 2024-12-26 12:40:29.086         WRITE           True   \n1        6 2024-12-26 12:40:22.596         MERGE          False   \n2        5 2024-12-26 12:39:42.930         MERGE          False   \n3        4 2024-12-26 12:39:26.863         WRITE           True   \n4        3 2024-12-26 12:39:20.851        DELETE          False   \n5        2 2024-12-26 12:39:01.160        UPDATE          False   \n6        1 2024-12-26 12:38:46.954         WRITE           True   \n7        0 2024-12-26 12:38:35.984  CREATE TABLE           True   \n\n                                    operationMetrics  \n0  {'numOutputRows': '15', 'numOutputBytes': '343...  \n1  {'numOutputRows': '33', 'numTargetBytesAdded':...  \n2  {'numOutputRows': '33', 'numTargetBytesAdded':...  \n3  {'numOutputRows': '15', 'numOutputBytes': '321...  \n4  {'numRemovedBytes': '4424', 'numAddedFiles': '...  \n5  {'numRemovedBytes': '4473', 'numAddedFiles': '...  \n6  {'numOutputRows': '32', 'numOutputBytes': '447...  \n7                                                 {}  "}, "execution_count": 53, "metadata": {}, "output_type": "execute_result"}], "source": "full_hist_df.toPandas()"}, {"cell_type": "markdown", "id": "2ccdc84a", "metadata": {"autoscroll": "auto"}, "source": "### Rozwi\u0105zanie zadania 7"}, {"cell_type": "code", "execution_count": 54, "id": "28d6e71b", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql.functions import to_date, col, lit\n\nversion_value = full_hist_df.orderBy(col(\"version\").desc()).first()[\"version\"] - 1\n\n# Za\u0142aduj dane z wersji przed ostatni\u0105 aktualizacj\u0105 (na podstawie numeru wersji)\ncustomers_df = (\n  spark.read.format(\"delta\")\n  .option(\"versionAsOf\", version_value)\n  .table(\"customers\")\n  .withColumn(\"effectiveDate\", to_date(col(\"effectiveDate\"), \"dd-MM-yyyy\"))  # Konwersja kolumny effectiveDate na date\n  .withColumn(\"zipcode\", col(\"zipcode\").cast(\"int\"))  # Zmiana typu kolumny zipcode na int\n  .withColumn(\"endDate\", lit(None).cast(\"date\"))  # Dodanie kolumny endDate z warto\u015bci\u0105 null\n)\n\n# Nadpisanie tabeli Delta z nowymi danymi\n(customers_df.write.format(\"delta\")\n  .mode(\"overwrite\")  # U\u017cycie trybu overwrite\n  .option(\"overwriteSchema\", \"true\")  # Nadpisanie schematu\n  .saveAsTable(\"customers\")\n)\n"}, {"cell_type": "code", "execution_count": 55, "id": "494944ba", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "# odczekaj chwil\u0119 aby zmiany dosz\u0142y do skutku\ndf = spark.sql(\"describe customers\")"}, {"cell_type": "code", "execution_count": 56, "id": "88c996b0", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_name</th>\n      <th>data_type</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>name</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>address</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>zipcode</td>\n      <td>int</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>city</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>country</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>effectiveDate</td>\n      <td>date</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>endDate</td>\n      <td>date</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td># Partitioning</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Not partitioned</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "           col_name data_type comment\n0                id    string        \n1              name    string        \n2           address    string        \n3           zipcode       int        \n4              city    string        \n5           country    string        \n6     effectiveDate      date        \n7           endDate      date        \n8                                    \n9    # Partitioning                  \n10  Not partitioned                  "}, "execution_count": 56, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "81d68d22", "metadata": {}, "source": "Zmiany mo\u017cna tak\u017ce wymusi\u0107 r\u0119cznie. \nDodaj jeszcze jedn\u0105 kolumn\u0119 za pomoc\u0105 poni\u017cszego paragrafu."}, {"cell_type": "code", "execution_count": 57, "id": "abd64b54", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 57, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"\"\"\nALTER TABLE customers ADD COLUMNS (current boolean COMMENT 'if current data' AFTER country)\n\"\"\")"}, {"cell_type": "code", "execution_count": 58, "id": "00fc73e1", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"describe customers\")"}, {"cell_type": "code", "execution_count": 59, "id": "ada1428a", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col_name</th>\n      <th>data_type</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>name</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>address</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>zipcode</td>\n      <td>int</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>city</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>country</td>\n      <td>string</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>current</td>\n      <td>boolean</td>\n      <td>if current data</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>effectiveDate</td>\n      <td>date</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>endDate</td>\n      <td>date</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td># Partitioning</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Not partitioned</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "           col_name data_type          comment\n0                id    string                 \n1              name    string                 \n2           address    string                 \n3           zipcode       int                 \n4              city    string                 \n5           country    string                 \n6           current   boolean  if current data\n7     effectiveDate      date                 \n8           endDate      date                 \n9                                             \n10   # Partitioning                           \n11  Not partitioned                           "}, "execution_count": 59, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "e52defbb", "metadata": {}, "source": "# Fina\u0142 \n\nNa zako\u0144czenie zaimplementujemy spos\u00f3b utrzymywania tabel wymiar\u00f3w jaki cz\u0119sto wykorzystywany jest w hurtowniach danych.\n\n## Slowly changing data (SCD) Type 2\n\nNasza tabela `customers` jest ju\u017c na to gotowa. \nKolumna `current` powinna by\u0107 zapalona tylko dla najnowszych wersji danych. \nKolumna `endDate` powinna mie\u0107 warto\u015b\u0107 zako\u0144czenia obowi\u0105zywania danej wersji danych je\u015bli pojawi si\u0119 nowy wiersz z now\u0105 wersj\u0105 danych. \n\n"}, {"cell_type": "markdown", "id": "b586b36e", "metadata": {}, "source": "## Zadanie 8\n\n**Zaimplementuj** funkcj\u0119 `updateCustomers`, kt\u00f3ra na podstawie danych \u017ar\u00f3d\u0142owych z kolejnego *miesi\u0105ca* (parametr funkcji) b\u0119dzie aktualizowa\u0142a zawarto\u015b\u0107 tabeli `customers` zgodnie a regu\u0142ami ***SCD Type 2***.  \n\nPo zako\u0144czonej implementacji **sprawd\u017a jej dzia\u0142anie**. \n\nJe\u015bli uwa\u017casz, \u017ce obecne dane w tabeli customers powinny zosta\u0107 poprawione, **dokonaj wcze\u015bniej stosownych korekt**. \n\nJe\u015bli chcesz skorzystaj ze strony:\nhttps://docs.delta.io/latest/delta-update.html#-merge-in-scd-type-2\n\n"}, {"cell_type": "markdown", "id": "db327c91", "metadata": {"autoscroll": "auto"}, "source": "## Rozwi\u0105zanie zadania 8"}, {"cell_type": "code", "execution_count": 60, "id": "2d0ca73d", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "def updateCustomers(new_data_df):\n    delta_path = \"/tmp/delta-customers\"\n    cust_delta_table = DeltaTable.forPath(spark, delta_path)\n    \n    # Sprawdzamy typ kolumny 'zipcode' w customers\n    customer_df = spark.table(\"customers\")\n    zipcode_type = customer_df.schema[\"zipcode\"].dataType\n    \n    # Ujednolicenie typu kolumny 'zipcode'\n    if zipcode_type == \"IntegerType\":\n        new_data_df = new_data_df.withColumn(\"zipcode\", col(\"zipcode\").cast(\"integer\"))\n    elif zipcode_type == \"StringType\":\n        new_data_df = new_data_df.withColumn(\"zipcode\", col(\"zipcode\").cast(\"string\"))\n\n    return\n    \n    new_data_df = new_data_df.withColumn(\"current\", lit(True)) \\\n        .withColumn(\"endDate\", lit(None).cast(\"date\"))\n    \n    # Merge z tabel\u0105 customers, aktualizacja danych\n    cust_delta_table.alias(\"customers\") \\\n        .merge(\n            new_data_df.alias(\"new_data\"),\n            \"customers.id = new_data.id AND customers.current = TRUE\"\n        ) \\\n        .whenMatchedUpdate(\n            condition=\"customers.effectiveDate != new_data.effectiveDate\",\n            set={\n                \"customers.endDate\": to_date(lit(\"current_date()\")),\n                \"customers.current\": lit(False)\n            }\n        ) \\\n        .execute()\n\n    # Dopisanie nowych danych\n    new_data_df.write.format(\"delta\") \\\n        .mode(\"append\") \\\n        .saveAsTable(\"customers\")"}, {"cell_type": "markdown", "id": "e88760c0", "metadata": {}, "source": "Masz to? \n\nJe\u015bli tak, to przyjmij gratulacje. Sprawd\u017amy jak to dzia\u0142a dla danych z marca, kt\u00f3re wycofali\u015bmy. \n\nNa pocz\u0105tku zobaczmy jakie to b\u0119d\u0105 dane."}, {"cell_type": "code", "execution_count": 61, "id": "014cb291", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "data_032021 = spark.sql(\"\"\"\nselect id, \n       name, address, zipcode, city, country, \n       effectiveDate, \n       cast(null as date) as endDate\nfrom  (\n    select id, name, address, zipcode, city, country, effectiveDate,\n           rank() over (partition by id order by to_date(effectiveDate,\"dd-MM-yyyy\") desc) as version\n    from   source_data\n    where  to_date(effectiveDate,\"dd-MM-yyyy\") >= date \"2021-03-01\"\n    and    to_date(effectiveDate,\"dd-MM-yyyy\") < date \"2021-04-01\"\n    )\nwhere version = 1\"\"\")"}, {"cell_type": "code", "execution_count": 62, "id": "98feb678", "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>effectiveDate</th>\n      <th>endDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>Tucker Russo</td>\n      <td>Ap #579-2185 Sed Street</td>\n      <td>5488 CT</td>\n      <td>Matar\u00f3</td>\n      <td>United Kingdom</td>\n      <td>17-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>Florence Landry</td>\n      <td>Ap #457-3976 Turpis. St.</td>\n      <td>725475</td>\n      <td>Pohang</td>\n      <td>Australia</td>\n      <td>27-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>Olga Ramsey</td>\n      <td>467-8297 Enim</td>\n      <td>O1N 1T2</td>\n      <td>Bandar Lampung</td>\n      <td>United Kingdom</td>\n      <td>21-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>Cody Alvarado</td>\n      <td>503-3360 Mattis St.</td>\n      <td>66750</td>\n      <td>Campina Grande</td>\n      <td>Turkey</td>\n      <td>22-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34</td>\n      <td>Rae Walter</td>\n      <td>656-9008 Felis. Avenue</td>\n      <td>52946</td>\n      <td>Poza Rica</td>\n      <td>India</td>\n      <td>06-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>53</td>\n      <td>Kieran Preston</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>40825</td>\n      <td>Townsville</td>\n      <td>Nigeria</td>\n      <td>02-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>55</td>\n      <td>Phoebe Craft</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>6338 CW</td>\n      <td>Rachecourt</td>\n      <td>Spain</td>\n      <td>20-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>60</td>\n      <td>Thane Mcfarland</td>\n      <td>2050 Augue. Avenue</td>\n      <td>538383</td>\n      <td>Dublin</td>\n      <td>Belgium</td>\n      <td>27-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>62</td>\n      <td>Arthur Castro</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>644923</td>\n      <td>Dublin</td>\n      <td>Germany</td>\n      <td>10-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>66</td>\n      <td>Violet Harding</td>\n      <td>P.O. Box 221, 1718 Sociis Rd.</td>\n      <td>3353</td>\n      <td>Nashik</td>\n      <td>Brazil</td>\n      <td>03-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>69</td>\n      <td>Tiger Sparks</td>\n      <td>Ap #183-5661 Cras Rd.</td>\n      <td>1555 GY</td>\n      <td>Orenburg</td>\n      <td>Spain</td>\n      <td>16-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>72</td>\n      <td>Otto Berry</td>\n      <td>6717 Pellentesque Av.</td>\n      <td>26754</td>\n      <td>Aguazul</td>\n      <td>Italy</td>\n      <td>06-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>81</td>\n      <td>Raphael Stark</td>\n      <td>337-6887 Tincidunt, St.</td>\n      <td>58177</td>\n      <td>Mamuju</td>\n      <td>New Zealand</td>\n      <td>22-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>9</td>\n      <td>Rahim Delacruz</td>\n      <td>840-6247 Pellentesque Road</td>\n      <td>712935</td>\n      <td>Ilesa</td>\n      <td>New Zealand</td>\n      <td>04-03-2021</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>91</td>\n      <td>Amber Guerrero</td>\n      <td>7303 Aliquam Street</td>\n      <td>4686</td>\n      <td>Bromyard</td>\n      <td>Colombia</td>\n      <td>23-03-2021</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    id             name                        address  zipcode  \\\n0   12     Tucker Russo        Ap #579-2185 Sed Street  5488 CT   \n1   24  Florence Landry       Ap #457-3976 Turpis. St.   725475   \n2   31      Olga Ramsey                  467-8297 Enim  O1N 1T2   \n3   33    Cody Alvarado            503-3360 Mattis St.    66750   \n4   34       Rae Walter         656-9008 Felis. Avenue    52946   \n5   53   Kieran Preston        337-6887 Tincidunt, St.    40825   \n6   55     Phoebe Craft        337-6887 Tincidunt, St.  6338 CW   \n7   60  Thane Mcfarland             2050 Augue. Avenue   538383   \n8   62    Arthur Castro        337-6887 Tincidunt, St.   644923   \n9   66   Violet Harding  P.O. Box 221, 1718 Sociis Rd.     3353   \n10  69     Tiger Sparks          Ap #183-5661 Cras Rd.  1555 GY   \n11  72       Otto Berry          6717 Pellentesque Av.    26754   \n12  81    Raphael Stark        337-6887 Tincidunt, St.    58177   \n13   9   Rahim Delacruz     840-6247 Pellentesque Road   712935   \n14  91   Amber Guerrero            7303 Aliquam Street     4686   \n\n              city         country effectiveDate endDate  \n0           Matar\u00f3  United Kingdom    17-03-2021    None  \n1           Pohang       Australia    27-03-2021    None  \n2   Bandar Lampung  United Kingdom    21-03-2021    None  \n3   Campina Grande          Turkey    22-03-2021    None  \n4        Poza Rica           India    06-03-2021    None  \n5       Townsville         Nigeria    02-03-2021    None  \n6       Rachecourt           Spain    20-03-2021    None  \n7           Dublin         Belgium    27-03-2021    None  \n8           Dublin         Germany    10-03-2021    None  \n9           Nashik          Brazil    03-03-2021    None  \n10        Orenburg           Spain    16-03-2021    None  \n11         Aguazul           Italy    06-03-2021    None  \n12          Mamuju     New Zealand    22-03-2021    None  \n13           Ilesa     New Zealand    04-03-2021    None  \n14        Bromyard        Colombia    23-03-2021    None  "}, "execution_count": 62, "metadata": {}, "output_type": "execute_result"}], "source": "data_032021.toPandas()"}, {"cell_type": "markdown", "id": "f54c2821", "metadata": {}, "source": "Zobaczmy ile z tych nowych wersji klient\u00f3w istnieje ju\u017c w naszych danych"}, {"cell_type": "code", "execution_count": 63, "id": "dd8ac953", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.sql.functions import col\n\n# Wyb\u00f3r identyfikator\u00f3w z ramki danych data_032021\nnew_ids = data_032021.select(\"id\").collect()\nnew_ids_list = [str(row.id) for row in new_ids]\nnew_ids_str = \",\".join(new_ids_list)\n\n# Wyb\u00f3r danych z tabeli customers, gdzie id znajduje si\u0119 w new_ids_str\ndf = spark.sql(f\"\"\"\n    SELECT *\n    FROM customers\n    WHERE id IN ({new_ids_str})\n\"\"\")"}, {"cell_type": "code", "execution_count": 64, "id": "ed4f43bd", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>current</th>\n      <th>effectiveDate</th>\n      <th>endDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33</td>\n      <td>Alexander Becker</td>\n      <td>Ap #631-7469 Curae St.</td>\n      <td>29941.0</td>\n      <td>Anseong</td>\n      <td>United States</td>\n      <td>None</td>\n      <td>2020-11-04</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62</td>\n      <td>Griffin Mooney</td>\n      <td>417-2786 Bibendum Ave</td>\n      <td>NaN</td>\n      <td>Ghizer</td>\n      <td>Costa Rica</td>\n      <td>None</td>\n      <td>2020-10-16</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>69</td>\n      <td>Chaney Ray</td>\n      <td>4442 Duis Avenue</td>\n      <td>64757.0</td>\n      <td>Stockholm</td>\n      <td>Nigeria</td>\n      <td>None</td>\n      <td>2021-01-28</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   id              name                 address  zipcode       city  \\\n0  33  Alexander Becker  Ap #631-7469 Curae St.  29941.0    Anseong   \n1  62    Griffin Mooney   417-2786 Bibendum Ave      NaN     Ghizer   \n2  69        Chaney Ray        4442 Duis Avenue  64757.0  Stockholm   \n\n         country current effectiveDate endDate  \n0  United States    None    2020-11-04    None  \n1     Costa Rica    None    2020-10-16    None  \n2        Nigeria    None    2021-01-28    None  "}, "execution_count": 64, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "7d3dc829", "metadata": {}, "source": "Uruchom swoj\u0105 funkcj\u0119"}, {"cell_type": "code", "execution_count": 65, "id": "5ea26573", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "updateCustomers(data_032021)"}, {"cell_type": "markdown", "id": "52dd92d0", "metadata": {}, "source": "Sprawd\u017amy jak wygl\u0105daj\u0105 stara i nowa wersja jednego ze zaktualizowanych klient\u00f3w."}, {"cell_type": "code", "execution_count": 66, "id": "9d477b66", "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "df = spark.sql(\"\"\"\nselect * from customers\nwhere id = 33 \"\"\")"}, {"cell_type": "code", "execution_count": 67, "id": "e65748c3", "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>address</th>\n      <th>zipcode</th>\n      <th>city</th>\n      <th>country</th>\n      <th>current</th>\n      <th>effectiveDate</th>\n      <th>endDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33</td>\n      <td>Alexander Becker</td>\n      <td>Ap #631-7469 Curae St.</td>\n      <td>29941</td>\n      <td>Anseong</td>\n      <td>United States</td>\n      <td>None</td>\n      <td>2020-11-04</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   id              name                 address  zipcode     city  \\\n0  33  Alexander Becker  Ap #631-7469 Curae St.    29941  Anseong   \n\n         country current effectiveDate endDate  \n0  United States    None    2020-11-04    None  "}, "execution_count": 67, "metadata": {}, "output_type": "execute_result"}], "source": "df.toPandas()"}, {"cell_type": "markdown", "id": "acddcfe8", "metadata": {}, "source": "Je\u015bli poprzednia wersja zosta\u0142a zamkni\u0119ta z odpowiedni\u0105 dat\u0105 a nowa z t\u0105 sam\u0105 dat\u0105 utworzona... \n\nto osi\u0105gneli\u015bmy to o co nam chodzi\u0142o... Delta Lake."}, {"cell_type": "markdown", "id": "5bf4c5d4", "metadata": {}, "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 5}