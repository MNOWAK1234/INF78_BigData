{"cells": [{"cell_type": "markdown", "id": "5f4571f9-9ecb-47a9-80cc-dfa10e34f79d", "metadata": {}, "source": "# Wprowadzenie \nNasze wyzwanie jest z jednej strony proste, z drugiej strony do\u015b\u0107 ambitne. \n\nJedno z klasycznych \"Hello World\" \u015bwiata Big Data polega na zliczaniu wyst\u0105pienia s\u0142\u00f3w. Dane wej\u015bciowe - plik tekstowy lub strumie\u0144 tekstu. Dane wynikowe - liczba wyst\u0105pie\u0144 ka\u017cdego ze s\u0142\u00f3w. Klasyka. \n\nMy zrobimy to samo, jednak naszymi danymi wej\u015bciowymi b\u0119d\u0105... opowiadania Artura Conan Doyla (czyli standard), ale nie w plikach tekstowych, a w formacie PDF (i to ju\u017c standard nie jest). \n\nTrudne? Nic bardziej mylnego. Python to mnogo\u015b\u0107 bibliotek o niezliczonej funkcjonalno\u015bci. \n\nProsty przyk\u0142ad...\n\nPobierz nasze dane wej\u015bciowe"}, {"cell_type": "code", "execution_count": 1, "id": "df35a83a-8a0b-4fa7-984e-529ab3653a42", "metadata": {}, "outputs": [{"data": {"text/plain": "7830123"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "import requests\nr = requests.get(\"https://jankiewicz.pl/bigdata/bigdata-sp/cano-pdf.zip\", allow_redirects=True)\nopen('cano-pdf.zip', 'wb').write(r.content)"}, {"cell_type": "markdown", "id": "05426d19-d5c6-40b0-b988-7963199385fb", "metadata": {}, "source": "Rozpakuj nasz plik"}, {"cell_type": "code", "execution_count": 2, "id": "858b95c6-e308-4c6b-a22d-a54da542dd28", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Archive:  cano-pdf.zip\n  inflating: cano-pdf/3gab.pdf       \n  inflating: cano-pdf/3gar.pdf       \n  inflating: cano-pdf/3stu.pdf       \n  inflating: cano-pdf/abbe.pdf       \n  inflating: cano-pdf/bery.pdf       \n  inflating: cano-pdf/blac.pdf       \n  inflating: cano-pdf/blan.pdf       \n  inflating: cano-pdf/blue.pdf       \n  inflating: cano-pdf/bosc.pdf       \n  inflating: cano-pdf/bruc.pdf       \n  inflating: cano-pdf/card.pdf       \n  inflating: cano-pdf/chas.pdf       \n  inflating: cano-pdf/copp.pdf       \n  inflating: cano-pdf/cree.pdf       \n  inflating: cano-pdf/croo.pdf       \n  inflating: cano-pdf/danc.pdf       \n  inflating: cano-pdf/devi.pdf       \n  inflating: cano-pdf/dyin.pdf       \n  inflating: cano-pdf/empt.pdf       \n  inflating: cano-pdf/engr.pdf       \n  inflating: cano-pdf/fina.pdf       \n  inflating: cano-pdf/five.pdf       \n  inflating: cano-pdf/glor.pdf       \n  inflating: cano-pdf/gold.pdf       \n  inflating: cano-pdf/gree.pdf       \n  inflating: cano-pdf/houn.pdf       \n  inflating: cano-pdf/iden.pdf       \n  inflating: cano-pdf/illu.pdf       \n  inflating: cano-pdf/lady.pdf       \n  inflating: cano-pdf/last.pdf       \n  inflating: cano-pdf/lion.pdf       \n  inflating: cano-pdf/maza.pdf       \n  inflating: cano-pdf/miss.pdf       \n  inflating: cano-pdf/musg.pdf       \n  inflating: cano-pdf/nava.pdf       \n  inflating: cano-pdf/nobl.pdf       \n  inflating: cano-pdf/norw.pdf       \n  inflating: cano-pdf/prio.pdf       \n  inflating: cano-pdf/redc.pdf       \n  inflating: cano-pdf/redh.pdf       \n  inflating: cano-pdf/reig.pdf       \n  inflating: cano-pdf/resi.pdf       \n  inflating: cano-pdf/reti.pdf       \n  inflating: cano-pdf/scan.pdf       \n  inflating: cano-pdf/seco.pdf       \n  inflating: cano-pdf/shos.pdf       \n  inflating: cano-pdf/sign.pdf       \n  inflating: cano-pdf/silv.pdf       \n  inflating: cano-pdf/sixn.pdf       \n  inflating: cano-pdf/soli.pdf       \n  inflating: cano-pdf/spec.pdf       \n  inflating: cano-pdf/stoc.pdf       \n  inflating: cano-pdf/stud.pdf       \n  inflating: cano-pdf/suss.pdf       \n  inflating: cano-pdf/thor.pdf       \n  inflating: cano-pdf/twis.pdf       \n  inflating: cano-pdf/vall.pdf       \n  inflating: cano-pdf/veil.pdf       \n  inflating: cano-pdf/wist.pdf       \n  inflating: cano-pdf/yell.pdf       \n"}], "source": "%%sh\nunzip -o cano-pdf.zip"}, {"cell_type": "markdown", "id": "101379f2-153d-4dc0-93cc-87076cafe39a", "metadata": {}, "source": "Sprawd\u017a czy mamy zainstalowany potrzebny modu\u0142"}, {"cell_type": "markdown", "id": "b952b16c-623b-4ecf-a467-8730ef53e46c", "metadata": {}, "source": "# PyPDF2"}, {"cell_type": "code", "execution_count": 3, "id": "f76b6b8e-e402-4630-95c1-ebe94559e6d4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "PyPDF2==3.0.1\n"}], "source": "%%sh\npip freeze | grep PyPDF2"}, {"cell_type": "code", "execution_count": 4, "id": "6de31298-a69d-4aaf-b1ed-92ff1c4f868f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "10\n"}], "source": "import PyPDF2 \n    \n# Utw\u00f3rz obiekt odnosz\u0105cy si\u0119 do przyk\u0142adowego pliku\npdfFileObj = open('cano-pdf/3gab.pdf', 'rb') \n    \n# Utw\u00f3rz obiekt PdfFileReader \npdfReader = PyPDF2.PdfReader(pdfFileObj) \n    \n# To wszystko \n# Zobacz ile ten plik ma stron \nprint(len(pdfReader.pages))"}, {"cell_type": "code", "execution_count": 5, "id": "dac0b79f-a329-46b0-b5f7-a89b14510b1a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The Adventure of the Three Gables\nArthur Conan Doyle\n"}], "source": "# Pobierz pierwsz\u0105 ze stron\npageObj = pdfReader.pages[0]\n    \n# Dokonaj esktrakcji tekstu, kt\u00f3ry si\u0119 na niej znajduje \nprint(pageObj.extract_text()) "}, {"cell_type": "code", "execution_count": 6, "id": "e462d76a-135c-4efa-b5fb-7f9d93aea88d", "metadata": {}, "outputs": [], "source": "# Nie zapomnij zamkn\u0105\u0107 nasz obiekt pliku\npdfFileObj.close() "}, {"cell_type": "markdown", "id": "c5db0993-26d0-47f6-a84d-a27c5a795487", "metadata": {}, "source": "Proste prawda? \n\nNo to do roboty. W pierwszej kolejno\u015bci za\u0142adujmy dane tam, gdzie b\u0119d\u0105 one mog\u0142y by\u0107 wydajnie odczytywane przez wiele w\u0119z\u0142\u00f3w klastra"}, {"cell_type": "markdown", "id": "528e10fb-c6ff-408b-9a85-ce1ecd68c40e", "metadata": {}, "source": "# Przygotowanie danych"}, {"cell_type": "code", "execution_count": 7, "id": "76d816c2-f589-45a6-bbb0-ccb108a8fcf7", "metadata": {}, "outputs": [], "source": "%%sh\nhadoop fs -mkdir -p cano-pdf"}, {"cell_type": "code", "execution_count": 8, "id": "d1342456-64b1-4f6c-86b4-a406ee46f059", "metadata": {}, "outputs": [], "source": "%%sh\nhadoop fs -put -f cano-pdf/* cano-pdf/"}, {"cell_type": "code", "execution_count": 9, "id": "f449e47f-37a7-434d-80a4-537b00a9dae7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 60 items\n-rw-r--r--   2 root hadoop      92929 2024-12-01 21:11 cano-pdf/3gab.pdf\n-rw-r--r--   2 root hadoop      85278 2024-12-01 21:11 cano-pdf/3gar.pdf\n-rw-r--r--   2 root hadoop      82246 2024-12-01 21:11 cano-pdf/3stu.pdf\n-rw-r--r--   2 root hadoop     105053 2024-12-01 21:11 cano-pdf/abbe.pdf\n-rw-r--r--   2 root hadoop     105315 2024-12-01 21:11 cano-pdf/bery.pdf\n-rw-r--r--   2 root hadoop      94016 2024-12-01 21:11 cano-pdf/blac.pdf\n-rw-r--r--   2 root hadoop      94094 2024-12-01 21:11 cano-pdf/blan.pdf\n-rw-r--r--   2 root hadoop     103941 2024-12-01 21:11 cano-pdf/blue.pdf\n-rw-r--r--   2 root hadoop     115124 2024-12-01 21:11 cano-pdf/bosc.pdf\n-rw-r--r--   2 root hadoop     115501 2024-12-01 21:11 cano-pdf/bruc.pdf\n-rw-r--r--   2 root hadoop     106359 2024-12-01 21:11 cano-pdf/card.pdf\n-rw-r--r--   2 root hadoop      89194 2024-12-01 21:11 cano-pdf/chas.pdf\n-rw-r--r--   2 root hadoop     111383 2024-12-01 21:11 cano-pdf/copp.pdf\n-rw-r--r--   2 root hadoop      87831 2024-12-01 21:11 cano-pdf/cree.pdf\n-rw-r--r--   2 root hadoop      78558 2024-12-01 21:11 cano-pdf/croo.pdf\n-rw-r--r--   2 root hadoop     289443 2024-12-01 21:11 cano-pdf/danc.pdf\n-rw-r--r--   2 root hadoop     103336 2024-12-01 21:11 cano-pdf/devi.pdf\n-rw-r--r--   2 root hadoop      80189 2024-12-01 21:11 cano-pdf/dyin.pdf\n-rw-r--r--   2 root hadoop     102150 2024-12-01 21:11 cano-pdf/empt.pdf\n-rw-r--r--   2 root hadoop     101328 2024-12-01 21:11 cano-pdf/engr.pdf\n-rw-r--r--   2 root hadoop      92842 2024-12-01 21:11 cano-pdf/fina.pdf\n-rw-r--r--   2 root hadoop     103239 2024-12-01 21:11 cano-pdf/five.pdf\n-rw-r--r--   2 root hadoop     101743 2024-12-01 21:11 cano-pdf/glor.pdf\n-rw-r--r--   2 root hadoop     235338 2024-12-01 21:11 cano-pdf/gold.pdf\n-rw-r--r--   2 root hadoop      99901 2024-12-01 21:11 cano-pdf/gree.pdf\n-rw-r--r--   2 root hadoop     428821 2024-12-01 21:11 cano-pdf/houn.pdf\n-rw-r--r--   2 root hadoop      89917 2024-12-01 21:11 cano-pdf/iden.pdf\n-rw-r--r--   2 root hadoop     113311 2024-12-01 21:11 cano-pdf/illu.pdf\n-rw-r--r--   2 root hadoop      95089 2024-12-01 21:11 cano-pdf/lady.pdf\n-rw-r--r--   2 root hadoop      88002 2024-12-01 21:11 cano-pdf/last.pdf\n-rw-r--r--   2 root hadoop      94999 2024-12-01 21:11 cano-pdf/lion.pdf\n-rw-r--r--   2 root hadoop      78598 2024-12-01 21:11 cano-pdf/maza.pdf\n-rw-r--r--   2 root hadoop     142274 2024-12-01 21:11 cano-pdf/miss.pdf\n-rw-r--r--   2 root hadoop      88564 2024-12-01 21:11 cano-pdf/musg.pdf\n-rw-r--r--   2 root hadoop     251235 2024-12-01 21:11 cano-pdf/nava.pdf\n-rw-r--r--   2 root hadoop     107197 2024-12-01 21:11 cano-pdf/nobl.pdf\n-rw-r--r--   2 root hadoop     113865 2024-12-01 21:11 cano-pdf/norw.pdf\n-rw-r--r--   2 root hadoop     288676 2024-12-01 21:11 cano-pdf/prio.pdf\n-rw-r--r--   2 root hadoop     106230 2024-12-01 21:11 cano-pdf/redc.pdf\n-rw-r--r--   2 root hadoop     110971 2024-12-01 21:11 cano-pdf/redh.pdf\n-rw-r--r--   2 root hadoop     278830 2024-12-01 21:11 cano-pdf/reig.pdf\n-rw-r--r--   2 root hadoop      86744 2024-12-01 21:11 cano-pdf/resi.pdf\n-rw-r--r--   2 root hadoop      86580 2024-12-01 21:11 cano-pdf/reti.pdf\n-rw-r--r--   2 root hadoop     110035 2024-12-01 21:11 cano-pdf/scan.pdf\n-rw-r--r--   2 root hadoop     116305 2024-12-01 21:11 cano-pdf/seco.pdf\n-rw-r--r--   2 root hadoop      75111 2024-12-01 21:11 cano-pdf/shos.pdf\n-rw-r--r--   2 root hadoop     332570 2024-12-01 21:11 cano-pdf/sign.pdf\n-rw-r--r--   2 root hadoop     103086 2024-12-01 21:11 cano-pdf/silv.pdf\n-rw-r--r--   2 root hadoop     102480 2024-12-01 21:11 cano-pdf/sixn.pdf\n-rw-r--r--   2 root hadoop      96460 2024-12-01 21:11 cano-pdf/soli.pdf\n-rw-r--r--   2 root hadoop     102616 2024-12-01 21:11 cano-pdf/spec.pdf\n-rw-r--r--   2 root hadoop      97570 2024-12-01 21:11 cano-pdf/stoc.pdf\n-rw-r--r--   2 root hadoop     341888 2024-12-01 21:11 cano-pdf/stud.pdf\n-rw-r--r--   2 root hadoop      84823 2024-12-01 21:11 cano-pdf/suss.pdf\n-rw-r--r--   2 root hadoop     107724 2024-12-01 21:11 cano-pdf/thor.pdf\n-rw-r--r--   2 root hadoop     100493 2024-12-01 21:11 cano-pdf/twis.pdf\n-rw-r--r--   2 root hadoop     423146 2024-12-01 21:11 cano-pdf/vall.pdf\n-rw-r--r--   2 root hadoop      64287 2024-12-01 21:11 cano-pdf/veil.pdf\n-rw-r--r--   2 root hadoop     136764 2024-12-01 21:11 cano-pdf/wist.pdf\n-rw-r--r--   2 root hadoop      82517 2024-12-01 21:11 cano-pdf/yell.pdf\n"}], "source": "%%sh\nhadoop fs -ls cano-pdf"}, {"cell_type": "markdown", "id": "572fa9f6-961c-4e5f-a5ce-89ffb853d518", "metadata": {}, "source": "Utw\u00f3rzmy teraz nasz obiekt konteksu (o ile jeszcze nie istnieje)"}, {"cell_type": "markdown", "id": "b5181207-51cd-4dab-88cb-b8e7b099307c", "metadata": {}, "source": "# Utworzenie obiektu kontekstu"}, {"cell_type": "code", "execution_count": 10, "id": "4309310c-8d6f-4a0b-9c23-c58a429bbc1f", "metadata": {}, "outputs": [], "source": "# To nie dzia\u0142a, dlatego ca\u0142a kom\u00f3rka zosta\u0142a zakomentowana\n\n# # w przypadku korzystania z kernela Python\n# from pyspark import SparkContext, SparkConf\n# # w przypadku korzystania z kernela Python\n# conf = SparkConf().setAppName(\"Spark - RDD - warsztaty\").setMaster(\"yarn\")\n# sc = SparkContext(conf=conf)"}, {"cell_type": "markdown", "id": "9b935a51-a15d-47a8-b1b2-92000e959b04", "metadata": {}, "source": "Do tej pory sz\u0142o g\u0142adko. Teraz mamy ma\u0142y problem. <br> \nW jaki spos\u00f3b zaczyta\u0107 nasze pliki? \n\nNie s\u0105 to pliki tekstowe, wi\u0119c `textFile` prowadzaj\u0105cy dane linia po linii do naszych dokument\u00f3w nie jest tu przydatny.<br>\nZagl\u0105dnij na https://spark.apache.org/docs/latest/rdd-programming-guide.html#external-datasets\n\nW\u0142a\u015bciwie, \u017cadna z metod nie jest tu odpowiednia. \n\nZrobimy zatem tak, naszymi danymi wej\u015bciowymi nie b\u0119d\u0105 pliki. B\u0119d\u0105 ich nazwy, a Spark na podstawie tych nazw b\u0119dzie je odczytywa\u0142 i ... "}, {"cell_type": "markdown", "id": "d982113f-449e-47a1-8683-c4a5c564673c", "metadata": {}, "source": "# Przygotowanie metadanych wej\u015bciowych"}, {"cell_type": "code", "execution_count": 11, "id": "475f5203-8800-4a13-a028-34d9a0fa3cbd", "metadata": {}, "outputs": [{"data": {"text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://pbd-cluster-m.europe-west4-b.c.big-data-2024-09-mn.internal:42679\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        ", "text/plain": "<SparkContext master=yarn appName=PySparkShell>"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "sc"}, {"cell_type": "code", "execution_count": 12, "id": "2f3b8f04-4e23-4010-8251-7dd4e33c89c7", "metadata": {}, "outputs": [], "source": "%%sh\nhadoop fs -ls cano-pdf > files.txt"}, {"cell_type": "code", "execution_count": 13, "id": "1d1dc76f-816c-45d5-a26d-e6007504742b", "metadata": {}, "outputs": [], "source": "%%sh\nhadoop fs -copyFromLocal -f files.txt"}, {"cell_type": "code", "execution_count": 14, "id": "41cdb297-e0ea-470b-99b0-b28dc669b9fe", "metadata": {}, "outputs": [], "source": "rawFiles = sc.textFile(\"files.txt\")"}, {"cell_type": "code", "execution_count": 15, "id": "7ad6455f-aa69-4b55-9290-3bff03afbe64", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "['Found 60 items',\n '-rw-r--r--   2 root hadoop      92929 2024-12-01 21:11 cano-pdf/3gab.pdf',\n '-rw-r--r--   2 root hadoop      85278 2024-12-01 21:11 cano-pdf/3gar.pdf',\n '-rw-r--r--   2 root hadoop      82246 2024-12-01 21:11 cano-pdf/3stu.pdf',\n '-rw-r--r--   2 root hadoop     105053 2024-12-01 21:11 cano-pdf/abbe.pdf',\n '-rw-r--r--   2 root hadoop     105315 2024-12-01 21:11 cano-pdf/bery.pdf',\n '-rw-r--r--   2 root hadoop      94016 2024-12-01 21:11 cano-pdf/blac.pdf',\n '-rw-r--r--   2 root hadoop      94094 2024-12-01 21:11 cano-pdf/blan.pdf',\n '-rw-r--r--   2 root hadoop     103941 2024-12-01 21:11 cano-pdf/blue.pdf',\n '-rw-r--r--   2 root hadoop     115124 2024-12-01 21:11 cano-pdf/bosc.pdf',\n '-rw-r--r--   2 root hadoop     115501 2024-12-01 21:11 cano-pdf/bruc.pdf',\n '-rw-r--r--   2 root hadoop     106359 2024-12-01 21:11 cano-pdf/card.pdf',\n '-rw-r--r--   2 root hadoop      89194 2024-12-01 21:11 cano-pdf/chas.pdf',\n '-rw-r--r--   2 root hadoop     111383 2024-12-01 21:11 cano-pdf/copp.pdf',\n '-rw-r--r--   2 root hadoop      87831 2024-12-01 21:11 cano-pdf/cree.pdf',\n '-rw-r--r--   2 root hadoop      78558 2024-12-01 21:11 cano-pdf/croo.pdf',\n '-rw-r--r--   2 root hadoop     289443 2024-12-01 21:11 cano-pdf/danc.pdf',\n '-rw-r--r--   2 root hadoop     103336 2024-12-01 21:11 cano-pdf/devi.pdf',\n '-rw-r--r--   2 root hadoop      80189 2024-12-01 21:11 cano-pdf/dyin.pdf',\n '-rw-r--r--   2 root hadoop     102150 2024-12-01 21:11 cano-pdf/empt.pdf',\n '-rw-r--r--   2 root hadoop     101328 2024-12-01 21:11 cano-pdf/engr.pdf',\n '-rw-r--r--   2 root hadoop      92842 2024-12-01 21:11 cano-pdf/fina.pdf',\n '-rw-r--r--   2 root hadoop     103239 2024-12-01 21:11 cano-pdf/five.pdf',\n '-rw-r--r--   2 root hadoop     101743 2024-12-01 21:11 cano-pdf/glor.pdf',\n '-rw-r--r--   2 root hadoop     235338 2024-12-01 21:11 cano-pdf/gold.pdf',\n '-rw-r--r--   2 root hadoop      99901 2024-12-01 21:11 cano-pdf/gree.pdf',\n '-rw-r--r--   2 root hadoop     428821 2024-12-01 21:11 cano-pdf/houn.pdf',\n '-rw-r--r--   2 root hadoop      89917 2024-12-01 21:11 cano-pdf/iden.pdf',\n '-rw-r--r--   2 root hadoop     113311 2024-12-01 21:11 cano-pdf/illu.pdf',\n '-rw-r--r--   2 root hadoop      95089 2024-12-01 21:11 cano-pdf/lady.pdf',\n '-rw-r--r--   2 root hadoop      88002 2024-12-01 21:11 cano-pdf/last.pdf',\n '-rw-r--r--   2 root hadoop      94999 2024-12-01 21:11 cano-pdf/lion.pdf',\n '-rw-r--r--   2 root hadoop      78598 2024-12-01 21:11 cano-pdf/maza.pdf',\n '-rw-r--r--   2 root hadoop     142274 2024-12-01 21:11 cano-pdf/miss.pdf',\n '-rw-r--r--   2 root hadoop      88564 2024-12-01 21:11 cano-pdf/musg.pdf',\n '-rw-r--r--   2 root hadoop     251235 2024-12-01 21:11 cano-pdf/nava.pdf',\n '-rw-r--r--   2 root hadoop     107197 2024-12-01 21:11 cano-pdf/nobl.pdf',\n '-rw-r--r--   2 root hadoop     113865 2024-12-01 21:11 cano-pdf/norw.pdf',\n '-rw-r--r--   2 root hadoop     288676 2024-12-01 21:11 cano-pdf/prio.pdf',\n '-rw-r--r--   2 root hadoop     106230 2024-12-01 21:11 cano-pdf/redc.pdf',\n '-rw-r--r--   2 root hadoop     110971 2024-12-01 21:11 cano-pdf/redh.pdf',\n '-rw-r--r--   2 root hadoop     278830 2024-12-01 21:11 cano-pdf/reig.pdf',\n '-rw-r--r--   2 root hadoop      86744 2024-12-01 21:11 cano-pdf/resi.pdf',\n '-rw-r--r--   2 root hadoop      86580 2024-12-01 21:11 cano-pdf/reti.pdf',\n '-rw-r--r--   2 root hadoop     110035 2024-12-01 21:11 cano-pdf/scan.pdf',\n '-rw-r--r--   2 root hadoop     116305 2024-12-01 21:11 cano-pdf/seco.pdf',\n '-rw-r--r--   2 root hadoop      75111 2024-12-01 21:11 cano-pdf/shos.pdf',\n '-rw-r--r--   2 root hadoop     332570 2024-12-01 21:11 cano-pdf/sign.pdf',\n '-rw-r--r--   2 root hadoop     103086 2024-12-01 21:11 cano-pdf/silv.pdf',\n '-rw-r--r--   2 root hadoop     102480 2024-12-01 21:11 cano-pdf/sixn.pdf',\n '-rw-r--r--   2 root hadoop      96460 2024-12-01 21:11 cano-pdf/soli.pdf',\n '-rw-r--r--   2 root hadoop     102616 2024-12-01 21:11 cano-pdf/spec.pdf',\n '-rw-r--r--   2 root hadoop      97570 2024-12-01 21:11 cano-pdf/stoc.pdf',\n '-rw-r--r--   2 root hadoop     341888 2024-12-01 21:11 cano-pdf/stud.pdf',\n '-rw-r--r--   2 root hadoop      84823 2024-12-01 21:11 cano-pdf/suss.pdf',\n '-rw-r--r--   2 root hadoop     107724 2024-12-01 21:11 cano-pdf/thor.pdf',\n '-rw-r--r--   2 root hadoop     100493 2024-12-01 21:11 cano-pdf/twis.pdf',\n '-rw-r--r--   2 root hadoop     423146 2024-12-01 21:11 cano-pdf/vall.pdf',\n '-rw-r--r--   2 root hadoop      64287 2024-12-01 21:11 cano-pdf/veil.pdf',\n '-rw-r--r--   2 root hadoop     136764 2024-12-01 21:11 cano-pdf/wist.pdf',\n '-rw-r--r--   2 root hadoop      82517 2024-12-01 21:11 cano-pdf/yell.pdf']"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "rawFiles.collect()"}, {"cell_type": "markdown", "id": "656f2c12-6d2c-4f31-918f-899def8029f2", "metadata": {}, "source": "Jeste\u015bmy zainteresowani tylko nazwami plik\u00f3w, a zatem..."}, {"cell_type": "code", "execution_count": 16, "id": "7bc7b745-bf7f-4b3c-b0e1-8f1d29e9db42", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "['cano-pdf/3gab.pdf',\n 'cano-pdf/3gar.pdf',\n 'cano-pdf/3stu.pdf',\n 'cano-pdf/abbe.pdf',\n 'cano-pdf/bery.pdf',\n 'cano-pdf/blac.pdf',\n 'cano-pdf/blan.pdf',\n 'cano-pdf/blue.pdf',\n 'cano-pdf/bosc.pdf',\n 'cano-pdf/bruc.pdf',\n 'cano-pdf/card.pdf',\n 'cano-pdf/chas.pdf',\n 'cano-pdf/copp.pdf',\n 'cano-pdf/cree.pdf',\n 'cano-pdf/croo.pdf',\n 'cano-pdf/danc.pdf',\n 'cano-pdf/devi.pdf',\n 'cano-pdf/dyin.pdf',\n 'cano-pdf/empt.pdf',\n 'cano-pdf/engr.pdf',\n 'cano-pdf/fina.pdf',\n 'cano-pdf/five.pdf',\n 'cano-pdf/glor.pdf',\n 'cano-pdf/gold.pdf',\n 'cano-pdf/gree.pdf',\n 'cano-pdf/houn.pdf',\n 'cano-pdf/iden.pdf',\n 'cano-pdf/illu.pdf',\n 'cano-pdf/lady.pdf',\n 'cano-pdf/last.pdf',\n 'cano-pdf/lion.pdf',\n 'cano-pdf/maza.pdf',\n 'cano-pdf/miss.pdf',\n 'cano-pdf/musg.pdf',\n 'cano-pdf/nava.pdf',\n 'cano-pdf/nobl.pdf',\n 'cano-pdf/norw.pdf',\n 'cano-pdf/prio.pdf',\n 'cano-pdf/redc.pdf',\n 'cano-pdf/redh.pdf',\n 'cano-pdf/reig.pdf',\n 'cano-pdf/resi.pdf',\n 'cano-pdf/reti.pdf',\n 'cano-pdf/scan.pdf',\n 'cano-pdf/seco.pdf',\n 'cano-pdf/shos.pdf',\n 'cano-pdf/sign.pdf',\n 'cano-pdf/silv.pdf',\n 'cano-pdf/sixn.pdf',\n 'cano-pdf/soli.pdf',\n 'cano-pdf/spec.pdf',\n 'cano-pdf/stoc.pdf',\n 'cano-pdf/stud.pdf',\n 'cano-pdf/suss.pdf',\n 'cano-pdf/thor.pdf',\n 'cano-pdf/twis.pdf',\n 'cano-pdf/vall.pdf',\n 'cano-pdf/veil.pdf',\n 'cano-pdf/wist.pdf',\n 'cano-pdf/yell.pdf']"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "import re\nrawFiles.filter(lambda s: \"cano\" in s).map(lambda s: re.search(\".* (\\S*)$\",s).group(1)).collect()"}, {"cell_type": "code", "execution_count": 17, "id": "b6920061-6985-4c9b-ae21-2b5a8c61b2f7", "metadata": {}, "outputs": [], "source": "fileNames = rawFiles.filter(lambda s: \"cano\" in s).map(lambda s: re.search(\".* (\\S*)$\",s).group(1))"}, {"cell_type": "markdown", "id": "633f987a-7898-41b8-a1e8-16eb3873f151", "metadata": {}, "source": "Nie chcemy aby ca\u0142\u0105 ekstrakcj\u0119 danych tekstowych z plik\u00f3w PDF wykonywa\u0142 jeden w\u0119ze\u0142. Sprawd\u017amy ile mamy partycji naszego RDD. \n\nJe\u015bli b\u0119dzie ich zbyt ma\u0142o, mo\u017cemy zmieni\u0107 ich liczb\u0119 za pomoca metody `repartition(liczba_partycji)`.\n\nPrzeanalizuj to ile zasob\u00f3w ma nasz klaster, w szczeg\u00f3lno\u015bci zwr\u00f3\u0107 uwag\u0119 na liczb\u0119 procesor\u00f3w we wszystkich maszynach.\n\nStosuj\u0105c *regu\u0142\u0119 kciuka* ustaw liczb\u0119 partycji na tak\u0105, kt\u00f3ra jest r\u00f3wna liczbie procesor\u00f3w. Wprowad\u017a zmiany w powy\u017cszej linii, tak aby poni\u017csza potwierdzi\u0142a oczekiwan\u0105 liczb\u0119 partycji. "}, {"cell_type": "code", "execution_count": 18, "id": "fa4e1588-3eb6-4112-9c06-8e25941ea4fc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Liczba procesor\u00f3w: 4\nPrzed ustawieniem liczby partycji: 2\nPo ustawieniu liczby partycji: 4\n"}], "source": "import os\n\n# Sprawdzenie liczby dost\u0119pnych procesor\u00f3w\nnum_processors = os.cpu_count()\nprint(f\"Liczba procesor\u00f3w: {num_processors}\")\n\n# Sprawdzanie liczby partycji przed zmian\u0105\nprint(f\"Przed ustawieniem liczby partycji: {fileNames.getNumPartitions()}\")\n\n# Ustawienie liczby partycji na liczb\u0119 procesor\u00f3w\nfileNames = fileNames.repartition(num_processors)\n\n# Sprawdzanie liczby partycji po zmianie\nprint(f\"Po ustawieniu liczby partycji: {fileNames.getNumPartitions()}\")"}, {"cell_type": "markdown", "id": "72c1faa2-45fb-47a7-aa07-0950f8d7c041", "metadata": {}, "source": "# Konwersja metadanych na dane \n\nJe\u015bli liczba partycji jest ju\u017c w porz\u0105dku, to czas na kluczowy moment. <br>\nChcemy, aby ka\u017cdy z element\u00f3w naszego RDD zamieni\u0142 si\u0119 z nazwy pliku, na szereg element\u00f3w odnosz\u0105cych si\u0119 do poszczeg\u00f3lnych linii zawartych w tym pliku. \n\nPotrzebujemy zatem funkcji, kt\u00f3ra:\n* odczyta plik o podanej nazwie \n* dokona ekstracji jego zawarto\u015bci\n* utworzy list\u0119 zawieraj\u0105c\u0105 poszczeg\u00f3lne linie\n\nFunkcj\u0119 t\u0105 wykorzystamy nast\u0119pnie w metodzie `flatMap` na naszym `RDD`. <br>\nReszta b\u0119dzie *easy peasy*. \n\n**Uwaga!** <br>\nPlik nie b\u0119dzie znajdowa\u0142 si\u0119 w lokalnym systemie plik\u00f3w w\u0119z\u0142a roboczego... b\u0119dzie znajdowa\u0142 si\u0119 w systemie plik\u00f3w HDFS!\n\nAby sobie z tym poradzi\u0107, sprawd\u017amy czy mamy dost\u0119pn\u0105 jeszcze jedn\u0105 bibliotek\u0119."}, {"cell_type": "code", "execution_count": 19, "id": "9076d4aa-6bdc-45b4-98fb-184ec99ee84b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "pydoop==2.0.0\n"}], "source": "%%sh\npip freeze | grep pydoop"}, {"cell_type": "code", "execution_count": 20, "id": "16bb0a52-15a8-477e-9e9e-1abab4b81fdd", "metadata": {}, "outputs": [], "source": "def pdf2txt(fileName):\n    \n    import PyPDF2\n    import pydoop.hdfs as hdfs\n\n    # Utw\u00f3rz obiekt odnosz\u0105cy si\u0119 do przyk\u0142adowego pliku\n    pdfFileObj = hdfs.open(fileName, \"rb\") \n    \n    # Utw\u00f3rz obiekt PdfFileReader \n    pdfReader = PyPDF2.PdfReader(pdfFileObj) \n    \n    lines = []\n    \n    for page in range(len(pdfReader.pages)): \n        pageObj = pdfReader.pages[page] \n        content = pageObj.extract_text() \n        lines.extend(content.splitlines())\n    pdfFileObj.close()\n    \n    return lines"}, {"cell_type": "markdown", "id": "22aa4855-4d78-45e0-913d-dc718fe80953", "metadata": {}, "source": "Sprawd\u017amy j\u0105. Tym razem b\u0119dzie to odczyt z systemu plik\u00f3w HDFS."}, {"cell_type": "code", "execution_count": 21, "id": "6e78789e-551e-4c6e-9fed-0c124abcb791", "metadata": {}, "outputs": [], "source": "lines_3gab = pdf2txt(\"cano-pdf/3gab.pdf\")"}, {"cell_type": "code", "execution_count": 22, "id": "7d22e0a4-50af-4742-9973-bb38c8b4ee68", "metadata": {}, "outputs": [{"data": {"text/plain": "['The Adventure of the Three Gables',\n 'Arthur Conan Doyle',\n 'This text is provided to you \u201cas-is\u201d without any warranty. No warranties of any kind, expressed or implied, are made to you as to the']"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "lines_3gab[:3]"}, {"cell_type": "markdown", "id": "74654209-4bde-4733-92c5-2024a160a03b", "metadata": {}, "source": "Pozosta\u0142o nam z niej skorzysta\u0107."}, {"cell_type": "code", "execution_count": 23, "id": "1aa9be85-d883-442a-a984-7f31aaf73877", "metadata": {}, "outputs": [], "source": "lines = fileNames.flatMap(lambda fn: pdf2txt(fn))"}, {"cell_type": "markdown", "id": "5527f274-d2bc-4d7b-9146-7af247785bd2", "metadata": {}, "source": "Pr\u00f3ba generalna"}, {"cell_type": "code", "execution_count": 24, "id": "c48bcb71-e31a-4be4-9125-2f6e386127d8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "['The Adventure of the Cardboard Box', 'Arthur Conan Doyle']"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "lines.take(2)"}, {"cell_type": "markdown", "id": "f9bffa89-34a8-4ffa-9939-b90aff4249aa", "metadata": {}, "source": "# Zadania \n\nTeraz ju\u017c z g\u00f3rki. Reszta nale\u017cy do Ciebie. \n\n**Uwaga!** Na wynikowym RDD, kt\u00f3ry powinien zawiera\u0107 dla ka\u017cdego s\u0142owa liczb\u0119 jego wyst\u0105pie\u0144, b\u0119dziemy wykonywali wiele operacji. <br>\nZadbaj o to, aby ka\u017cdorazowe u\u017cycie tego wynikowego RDD nie powodowa\u0142o odczytywania plik\u00f3w PDF.\n\n## Zadanie 1\n\nUtw\u00f3rz obiekt RDD `wordCounts`, kt\u00f3ry dla ka\u017cdego s\u0142owa liczb\u0119 jego wyst\u0105pie\u0144."}, {"cell_type": "code", "execution_count": 25, "id": "8bf30829-61ca-45a7-872e-184ce15d9dcf", "metadata": {}, "outputs": [], "source": "import re\n# RDD words powinien by\u0107 RDD zawieraj\u0105cym s\u0142owa ze \u017ar\u00f3d\u0142owych dokument\u00f3w\nwords = lines.flatMap(lambda line: re.split(r'\\W+', line.lower()))\n\n# RDD wordCounts powinien by\u0107 RDD par zawieraj\u0105cym dla ka\u017cdego s\u0142owa liczb\u0119 jego wyst\u0105pie\u0144\nwordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)"}, {"cell_type": "code", "execution_count": 26, "id": "ade0971a-5c7b-4ed5-85a4-5d39b9c2f89c", "metadata": {}, "outputs": [{"data": {"text/plain": "PythonRDD[13] at RDD at PythonRDD.scala:53"}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": "wordCounts"}, {"cell_type": "markdown", "id": "3f4dcca2-544d-434c-8ed4-ee37120df3a1", "metadata": {}, "source": "## Zadanie 2\n\nZnajd\u017a 10 najcz\u0119\u015bciej wykorzystywanych s\u0142\u00f3w."}, {"cell_type": "code", "execution_count": 27, "id": "5255c1e5-f4a2-4d0c-99ff-5276fb55d755", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "[('', 42232),\n ('the', 36104),\n ('and', 17645),\n ('i', 17290),\n ('of', 16846),\n ('to', 16230),\n ('a', 15839),\n ('that', 11453),\n ('it', 11198),\n ('in', 10876)]"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "wordCounts.sortBy(lambda pair: pair[1], ascending=False).take(10)"}, {"cell_type": "markdown", "id": "98f9e916-9b64-4bb1-b869-daa2bed3db76", "metadata": {}, "source": "## Zadanie 3\n\nZnajd\u017a 10 najcz\u0119\u015bciej wykorzystywanych s\u0142\u00f3w, kt\u00f3re sk\u0142adaj\u0105 si\u0119 z co najmniej 5 liter. "}, {"cell_type": "code", "execution_count": 28, "id": "9e67118d-ea7c-4cad-bce3-919449b4456e", "metadata": {}, "outputs": [{"data": {"text/plain": "[('which', 4264),\n ('there', 3386),\n ('holmes', 3044),\n ('would', 2192),\n ('could', 1885),\n ('should', 1244),\n ('about', 1134),\n ('before', 1045),\n ('little', 1020),\n ('watson', 984)]"}, "execution_count": 28, "metadata": {}, "output_type": "execute_result"}], "source": "wordCounts.filter(lambda pair: len(pair[0]) >= 5).sortBy(lambda pair: pair[1], ascending=False).take(10)"}, {"cell_type": "markdown", "id": "f87cd2f6-bc5d-4ad7-801c-8f04a99d03a8", "metadata": {}, "source": "## Zadanie 4\n\nIle razy pojawi\u0142o si\u0119 s\u0142owo \"Watson\"?"}, {"cell_type": "code", "execution_count": 29, "id": "fc241de2-a77c-423d-8b44-9794662c033e", "metadata": {}, "outputs": [{"data": {"text/plain": "[('watson', 984)]"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "wordCounts.filter(lambda pair: pair[0] == \"watson\").collect()"}, {"cell_type": "markdown", "id": "5d8908e8-2b48-42b9-bdbb-59fc70e5080c", "metadata": {}, "source": "## Zadanie 5\n\nA ile razy pojawi\u0142o si\u0119 s\u0142owo \"Moriarty\"?"}, {"cell_type": "code", "execution_count": 30, "id": "73038949-9869-4a94-9b1e-554e7b998f88", "metadata": {}, "outputs": [{"data": {"text/plain": "[('moriarty', 49)]"}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": "wordCounts.filter(lambda pair: pair[0] == \"moriarty\").collect()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}